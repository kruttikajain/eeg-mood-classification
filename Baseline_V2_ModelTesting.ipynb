{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": ".ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMTblFDJISuPSrb8ycP6NDE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omkarpat/eeg-mood-classification/blob/master/Baseline_V2_ModelTesting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUwcHH9_PIFi",
        "colab_type": "code",
        "outputId": "a68347fb-ef57-451c-d355-708857c50d9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Colab settings/mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/My\\ Drive/CSE\\ 240/Project/Data/spectrogram_images/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/CSE 240/Project/Data/spectrogram_images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNwtoMU5TaWs",
        "colab_type": "code",
        "outputId": "b9110f3d-b328-44eb-cca2-fccc403bcba8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Convolution2D, Conv2D, MaxPooling2D, Lambda, GlobalMaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Activation, AveragePooling2D, Concatenate, SeparableConv2D, MaxPooling3D, Conv3D, DepthwiseConv2D\n",
        "from tensorflow.keras.models import model_from_json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HCukdDgTalg",
        "colab_type": "code",
        "outputId": "c86757d3-9ce2-4805-e1c0-b0320ac08256",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "base_path = \".\"\n",
        "concentration_data_array = None\n",
        "relaxed_data_array = None\n",
        "print(\"loading data from .npy files...\")\n",
        "for filename in os.listdir(base_path):\n",
        "  if \"concentration_array_updated_spectrograms\" in filename and \"final\" not in filename:\n",
        "    print(filename)\n",
        "    concentration_data_array = np.concatenate((concentration_data_array, np.load(filename))) if concentration_data_array is not None else np.load(filename)\n",
        "  if \"relaxed_array_updated_spectrograms\" in filename:\n",
        "    print(filename)\n",
        "    relaxed_data_array = np.concatenate((relaxed_data_array, np.load(filename))) if relaxed_data_array is not None else np.load(filename)\n",
        "print(concentration_data_array.shape, relaxed_data_array.shape)\n",
        "print(len(concentration_data_array), len(relaxed_data_array))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading data from .npy files...\n",
            "concentration_array_updated_spectrograms_1.npy\n",
            "concentration_array_updated_spectrograms_2.npy\n",
            "concentration_array_updated_spectrograms_3.npy\n",
            "concentration_array_updated_spectrograms_4.npy\n",
            "concentration_array_updated_spectrograms_5.npy\n",
            "concentration_array_updated_spectrograms_6.npy\n",
            "relaxed_array_updated_spectrograms_1.npy\n",
            "relaxed_array_updated_spectrograms_2.npy\n",
            "relaxed_array_updated_spectrograms_3.npy\n",
            "relaxed_array_updated_spectrograms_4.npy\n",
            "relaxed_array_updated_spectrograms_5.npy\n",
            "relaxed_array_updated_spectrograms_final.npy\n",
            "(2160, 29, 43, 42) (2124, 29, 43, 42)\n",
            "2160 2124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzhdNgnXTa6k",
        "colab_type": "code",
        "outputId": "e5ddb84f-16c6-48a5-eb9b-5bed90b3f4b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = np.concatenate((relaxed_data_array, concentration_data_array))\n",
        "Y = np.concatenate((np.zeros((len(relaxed_data_array),1)),np.ones((len(concentration_data_array),1))))\n",
        "print(X.shape, Y.shape)\n",
        "relaxed_data_array, concentration_data_array = None, None"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4284, 29, 43, 42) (4284, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3BLxBSiTa5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
        "X, Y = None, None\n",
        "folds = list(StratifiedKFold(n_splits=10, shuffle=True, random_state=1).split(X_train, y_train))\n",
        "#X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.15, random_state=42)\n",
        "#print(X_train.shape, X_test.shape, X_valid.shape, y_train.shape, y_test.shape, y_valid.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBhsZ703Ta4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = \"Proper_AlexNet\"\n",
        "def get_model():\n",
        "  model = Sequential()\n",
        "  \n",
        "  #model.add(Conv2D(64, kernel_size=5, strides=(1,1), padding='valid', activation='relu', input_shape = (29, 43, 42)))\n",
        "  model.add(Conv2D(input_shape=(29,43,42),filters=64,kernel_size=(11,11),padding=\"same\", activation=\"relu\", data_format='channels_first'))\n",
        "  model.add(MaxPooling2D(pool_size=(3,3),strides=(3,3)))\n",
        "  #model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "  \n",
        "  #model.add(Dropout(0.3))\n",
        "  #model.add(Conv2D(128, kernel_size=3,strides=(1,1), padding='valid', activation='relu'))\n",
        "  #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  #model.add(Dropout(0.3))\n",
        "  model.add(Conv2D(filters=128, kernel_size=(5,5), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(3,3),strides=(3,3)))\n",
        "\n",
        "  #model.add(Conv2D(256, kernel_size=3, strides=(1,1), padding='valid', activation='relu'))\n",
        "  #model.add(Conv2D(512, kernel_size=2, activation='relu'))\n",
        "  #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(3,3),strides=(3,3)))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  #model.add(Dense(100, activation='relu'))\n",
        "  #model.add(Dropout(0.3))\n",
        "  #model.add(Dense(100, activation='relu'))\n",
        "  #model.add(Dropout(0.3))\n",
        "  #model.add(Dense(1, activation='sigmoid'))\n",
        "  model.add(Dense(units=4096,activation=\"relu\"))\n",
        "  model.add(Dense(units=4096,activation=\"relu\"))\n",
        "  model.add(Dense(units=2, activation=\"softmax\"))   \n",
        "  \n",
        "  sgd = optimizers.SGD(lr=0.000001, momentum=0.5, decay=1e-6)\n",
        "  model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oICZG28uTa21",
        "colab_type": "code",
        "outputId": "b24b310a-6028-4bc5-c7ae-f0f7cfdb3748",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "filepath= model_name + \"-weights-improvement-{epoch:02d}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "model2 = get_model()\n",
        "for j, (train_idx, val_idx) in enumerate(folds):\n",
        "  print('\\nFold ',j)\n",
        "  X_train_cv = X_train[train_idx]\n",
        "  y_train_cv = y_train[train_idx]\n",
        "  X_valid_cv = X_train[val_idx]\n",
        "  y_valid_cv= y_train[val_idx]\n",
        "  # checkpoint\n",
        "  model2.fit(X_train_cv, y_train_cv, validation_data=(X_valid_cv, y_valid_cv), epochs=10, batch_size=32, callbacks=callbacks_list, shuffle=True)\n",
        "score = model2.evaluate(X_test,y_test)\n",
        "print(\"Test set metrics: %s: %.2f%%\" % (model2.metrics_names[1], score[1]*100))\n",
        "model2_json = model2.to_json()\n",
        "with open(model_name + \".json\", \"w\") as json_file:\n",
        "    json_file.write(model2_json)\n",
        "# serialize weights to HDF5\n",
        "model2.save_weights(model_name + \".h5\")\n",
        "print(\"Saved model %s to disk\" % (model_name))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold  0\n",
            "Train on 1820 samples, validate on 1821 samples\n",
            "Epoch 1/10\n",
            "1760/1820 [============================>.] - ETA: 0s - loss: 1.2021 - accuracy: 0.4847\n",
            "Epoch 00001: accuracy improved from -inf to 0.48956, saving model to Proper_AlexNet-weights-improvement-01.hdf5\n",
            "1820/1820 [==============================] - 10s 6ms/sample - loss: 1.1898 - accuracy: 0.4896 - val_loss: 0.9986 - val_accuracy: 0.5096\n",
            "Epoch 2/10\n",
            "1760/1820 [============================>.] - ETA: 0s - loss: 0.9473 - accuracy: 0.5148\n",
            "Epoch 00002: accuracy improved from 0.48956 to 0.51538, saving model to Proper_AlexNet-weights-improvement-02.hdf5\n",
            "1820/1820 [==============================] - 3s 2ms/sample - loss: 0.9476 - accuracy: 0.5154 - val_loss: 1.0092 - val_accuracy: 0.5146\n",
            "Epoch 3/10\n",
            "1760/1820 [============================>.] - ETA: 0s - loss: 0.8942 - accuracy: 0.5420\n",
            "Epoch 00003: accuracy improved from 0.51538 to 0.53846, saving model to Proper_AlexNet-weights-improvement-03.hdf5\n",
            "1820/1820 [==============================] - 3s 2ms/sample - loss: 0.9003 - accuracy: 0.5385 - val_loss: 0.9478 - val_accuracy: 0.5162\n",
            "Epoch 4/10\n",
            "1760/1820 [============================>.] - ETA: 0s - loss: 0.8615 - accuracy: 0.5540\n",
            "Epoch 00004: accuracy improved from 0.53846 to 0.55275, saving model to Proper_AlexNet-weights-improvement-04.hdf5\n",
            "1820/1820 [==============================] - 3s 2ms/sample - loss: 0.8632 - accuracy: 0.5527 - val_loss: 0.9200 - val_accuracy: 0.5288\n",
            "Epoch 5/10\n",
            "1760/1820 [============================>.] - ETA: 0s - loss: 0.8400 - accuracy: 0.5614\n",
            "Epoch 00005: accuracy improved from 0.55275 to 0.56154, saving model to Proper_AlexNet-weights-improvement-05.hdf5\n",
            "1820/1820 [==============================] - 3s 2ms/sample - loss: 0.8427 - accuracy: 0.5615 - val_loss: 0.9241 - val_accuracy: 0.5283\n",
            "Epoch 6/10\n",
            "1760/1820 [============================>.] - ETA: 0s - loss: 0.8291 - accuracy: 0.5591\n",
            "Epoch 00006: accuracy did not improve from 0.56154\n",
            "1820/1820 [==============================] - 3s 1ms/sample - loss: 0.8317 - accuracy: 0.5582 - val_loss: 0.9128 - val_accuracy: 0.5189\n",
            "Epoch 7/10\n",
            "1760/1820 [============================>.] - ETA: 0s - loss: 0.8054 - accuracy: 0.5670\n",
            "Epoch 00007: accuracy improved from 0.56154 to 0.56703, saving model to Proper_AlexNet-weights-improvement-07.hdf5\n",
            "1820/1820 [==============================] - 3s 2ms/sample - loss: 0.8060 - accuracy: 0.5670 - val_loss: 0.9072 - val_accuracy: 0.5211\n",
            "Epoch 8/10\n",
            "1760/1820 [============================>.] - ETA: 0s - loss: 0.7997 - accuracy: 0.5693\n",
            "Epoch 00008: accuracy improved from 0.56703 to 0.57088, saving model to Proper_AlexNet-weights-improvement-08.hdf5\n",
            "1820/1820 [==============================] - 3s 2ms/sample - loss: 0.7962 - accuracy: 0.5709 - val_loss: 0.8914 - val_accuracy: 0.5310\n",
            "Epoch 9/10\n",
            "1760/1820 [============================>.] - ETA: 0s - loss: 0.7789 - accuracy: 0.5761\n",
            "Epoch 00009: accuracy improved from 0.57088 to 0.57637, saving model to Proper_AlexNet-weights-improvement-09.hdf5\n",
            "1820/1820 [==============================] - 3s 2ms/sample - loss: 0.7806 - accuracy: 0.5764 - val_loss: 0.8838 - val_accuracy: 0.5272\n",
            "Epoch 10/10\n",
            "1760/1820 [============================>.] - ETA: 0s - loss: 0.7681 - accuracy: 0.5875\n",
            "Epoch 00010: accuracy improved from 0.57637 to 0.58462, saving model to Proper_AlexNet-weights-improvement-10.hdf5\n",
            "1820/1820 [==============================] - 3s 2ms/sample - loss: 0.7720 - accuracy: 0.5846 - val_loss: 0.8803 - val_accuracy: 0.5349\n",
            "\n",
            "Fold  1\n",
            "Train on 1821 samples, validate on 1820 samples\n",
            "Epoch 1/10\n",
            "1760/1821 [===========================>..] - ETA: 0s - loss: 0.8857 - accuracy: 0.5222\n",
            "Epoch 00001: accuracy did not improve from 0.58462\n",
            "1821/1821 [==============================] - 3s 2ms/sample - loss: 0.8879 - accuracy: 0.5222 - val_loss: 0.7693 - val_accuracy: 0.5791\n",
            "Epoch 2/10\n",
            "1760/1821 [===========================>..] - ETA: 0s - loss: 0.8723 - accuracy: 0.5244\n",
            "Epoch 00002: accuracy did not improve from 0.58462\n",
            "1821/1821 [==============================] - 3s 2ms/sample - loss: 0.8721 - accuracy: 0.5244 - val_loss: 0.8319 - val_accuracy: 0.5577\n",
            "Epoch 3/10\n",
            "1760/1821 [===========================>..] - ETA: 0s - loss: 0.8622 - accuracy: 0.5335\n",
            "Epoch 00003: accuracy did not improve from 0.58462\n",
            "1821/1821 [==============================] - 3s 1ms/sample - loss: 0.8578 - accuracy: 0.5354 - val_loss: 0.7642 - val_accuracy: 0.5747\n",
            "Epoch 4/10\n",
            "1760/1821 [===========================>..] - ETA: 0s - loss: 0.8329 - accuracy: 0.5477\n",
            "Epoch 00004: accuracy did not improve from 0.58462\n",
            "1821/1821 [==============================] - 3s 1ms/sample - loss: 0.8339 - accuracy: 0.5470 - val_loss: 0.7644 - val_accuracy: 0.5780\n",
            "Epoch 5/10\n",
            "1760/1821 [===========================>..] - ETA: 0s - loss: 0.8145 - accuracy: 0.5443\n",
            "Epoch 00005: accuracy did not improve from 0.58462\n",
            "1821/1821 [==============================] - 3s 1ms/sample - loss: 0.8139 - accuracy: 0.5426 - val_loss: 0.7479 - val_accuracy: 0.5753\n",
            "Epoch 6/10\n",
            "1760/1821 [===========================>..] - ETA: 0s - loss: 0.8109 - accuracy: 0.5449\n",
            "Epoch 00006: accuracy did not improve from 0.58462\n",
            "1821/1821 [==============================] - 3s 1ms/sample - loss: 0.8128 - accuracy: 0.5437 - val_loss: 0.7524 - val_accuracy: 0.5703\n",
            "Epoch 7/10\n",
            "1760/1821 [===========================>..] - ETA: 0s - loss: 0.7948 - accuracy: 0.5580\n",
            "Epoch 00007: accuracy did not improve from 0.58462\n",
            "1821/1821 [==============================] - 3s 1ms/sample - loss: 0.7934 - accuracy: 0.5574 - val_loss: 0.7472 - val_accuracy: 0.5659\n",
            "Epoch 8/10\n",
            "1760/1821 [===========================>..] - ETA: 0s - loss: 0.7806 - accuracy: 0.5705\n",
            "Epoch 00008: accuracy did not improve from 0.58462\n",
            "1821/1821 [==============================] - 3s 1ms/sample - loss: 0.7814 - accuracy: 0.5678 - val_loss: 0.7681 - val_accuracy: 0.5687\n",
            "Epoch 9/10\n",
            "1760/1821 [===========================>..] - ETA: 0s - loss: 0.7889 - accuracy: 0.5614\n",
            "Epoch 00009: accuracy did not improve from 0.58462\n",
            "1821/1821 [==============================] - 3s 1ms/sample - loss: 0.7869 - accuracy: 0.5629 - val_loss: 0.7560 - val_accuracy: 0.5665\n",
            "Epoch 10/10\n",
            "1760/1821 [===========================>..] - ETA: 0s - loss: 0.7691 - accuracy: 0.5744\n",
            "Epoch 00010: accuracy did not improve from 0.58462\n",
            "1821/1821 [==============================] - 3s 1ms/sample - loss: 0.7653 - accuracy: 0.5755 - val_loss: 0.7563 - val_accuracy: 0.5676\n",
            "643/643 [==============================] - 0s 564us/sample - loss: 0.8224 - accuracy: 0.5521\n",
            "Test set metrics: accuracy: 55.21%\n",
            "Saved model Proper_AlexNet to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd_kRUDaTaxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TJu_4vQTatU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a2HKyYnTaqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rzdn49dwTaor",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}