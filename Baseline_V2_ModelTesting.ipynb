{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": ".ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPETLkoCWFyCaZqWzN7jkF8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omkarpat/eeg-mood-classification/blob/master/Baseline_V2_ModelTesting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUwcHH9_PIFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "795cb939-fed1-42cd-f211-92c2a5e5d3e9"
      },
      "source": [
        "# Colab settings/mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/My\\ Drive/CSE\\ 240/Project/Data/spectrogram_images/"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: 'gdrive/My Drive/CSE 240/Project/Data/spectrogram_images/'\n",
            "/content/gdrive/My Drive/CSE 240/Project/Data/spectrogram_images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNwtoMU5TaWs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc939c50-4c78-4de2-fed1-a02107925bbd"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Convolution2D, Conv2D, MaxPooling2D, Lambda, GlobalMaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Activation, AveragePooling2D, Concatenate, SeparableConv2D, MaxPooling3D, Conv3D, DepthwiseConv2D\n",
        "from tensorflow.keras.models import model_from_json"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HCukdDgTalg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "78e2ea01-0b44-4a24-b186-d636c70ca643"
      },
      "source": [
        "base_path = \".\"\n",
        "concentration_data_array = None\n",
        "relaxed_data_array = None\n",
        "print(\"loading data from .npy files...\")\n",
        "for filename in os.listdir(base_path):\n",
        "  if \"concentration_array_updated_spectrograms\" in filename and \"final\" not in filename:\n",
        "    print(filename)\n",
        "    concentration_data_array = np.concatenate((concentration_data_array, np.load(filename))) if concentration_data_array is not None else np.load(filename)\n",
        "  if \"relaxed_array_updated_spectrograms\" in filename:\n",
        "    print(filename)\n",
        "    relaxed_data_array = np.concatenate((relaxed_data_array, np.load(filename))) if relaxed_data_array is not None else np.load(filename)\n",
        "print(concentration_data_array.shape, relaxed_data_array.shape)\n",
        "print(len(concentration_data_array), len(relaxed_data_array))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading data from .npy files...\n",
            "concentration_array_updated_spectrograms_1.npy\n",
            "concentration_array_updated_spectrograms_2.npy\n",
            "concentration_array_updated_spectrograms_3.npy\n",
            "concentration_array_updated_spectrograms_4.npy\n",
            "concentration_array_updated_spectrograms_5.npy\n",
            "concentration_array_updated_spectrograms_6.npy\n",
            "relaxed_array_updated_spectrograms_1.npy\n",
            "relaxed_array_updated_spectrograms_2.npy\n",
            "relaxed_array_updated_spectrograms_3.npy\n",
            "relaxed_array_updated_spectrograms_4.npy\n",
            "relaxed_array_updated_spectrograms_5.npy\n",
            "relaxed_array_updated_spectrograms_final.npy\n",
            "(2160, 29, 43, 42) (2124, 29, 43, 42)\n",
            "2160 2124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzhdNgnXTa6k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75571cd0-bb03-4383-a498-c80ae23b4c98"
      },
      "source": [
        "X = np.concatenate((relaxed_data_array, concentration_data_array))\n",
        "Y = np.concatenate((np.zeros((len(relaxed_data_array),1)),np.ones((len(concentration_data_array),1))))\n",
        "print(X.shape, Y.shape)\n",
        "relaxed_data_array, concentration_data_array = None, None"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4284, 29, 43, 42) (4284, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3BLxBSiTa5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
        "X, Y = None, None\n",
        "folds = list(StratifiedKFold(n_splits=10, shuffle=True, random_state=1).split(X_train, y_train))\n",
        "#X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.15, random_state=42)\n",
        "#print(X_train.shape, X_test.shape, X_valid.shape, y_train.shape, y_test.shape, y_valid.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBhsZ703Ta4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = \"Small_AlexNet_with_Dropout\"\n",
        "def get_model():\n",
        "  model = Sequential()\n",
        "  \n",
        "  model.add(Conv2D(64, kernel_size=5, strides=(1,1), padding='valid', activation='relu', input_shape = (29, 43, 42)))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Conv2D(128, kernel_size=3,strides=(1,1), padding='valid', activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Conv2D(256, kernel_size=3, strides=(1,1), padding='valid', activation='relu'))\n",
        "  model.add(Conv2D(512, kernel_size=2, activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  \n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(100, activation='relu'))\n",
        "  model.add(Dense(100, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  \n",
        "  sgd = optimizers.SGD(lr=0.000001, momentum=0.7, decay=1e-6)\n",
        "  model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oICZG28uTa21",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "125c3ded-c005-40b0-b16f-4a9178110582"
      },
      "source": [
        "filepath= model_name + \"-weights-improvement-{epoch:02d}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "model2 = get_model()\n",
        "for j, (train_idx, val_idx) in enumerate(folds):\n",
        "  print('\\nFold ',j)\n",
        "  X_train_cv = X_train[train_idx]\n",
        "  y_train_cv = y_train[train_idx]\n",
        "  X_valid_cv = X_train[val_idx]\n",
        "  y_valid_cv= y_train[val_idx]\n",
        "  # checkpoint\n",
        "  model2.fit(X_train_cv, y_train_cv, validation_data=(X_valid_cv, y_valid_cv), epochs=10, batch_size=32, callbacks=callbacks_list, shuffle=True)\n",
        "score = model2.evaluate(X_test,y_test)\n",
        "print(\"Test set metrics: %s: %.2f%%\" % (model2.metrics_names[1], score[1]*100))\n",
        "model2_json = model2.to_json()\n",
        "with open(model_name + \".json\", \"w\") as json_file:\n",
        "    json_file.write(model2_json)\n",
        "# serialize weights to HDF5\n",
        "model2.save_weights(model_name + \".h5\")\n",
        "print(\"Saved model %s to disk\" % (model_name))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold  0\n",
            "Train on 3276 samples, validate on 365 samples\n",
            "Epoch 1/10\n",
            "3200/3276 [============================>.] - ETA: 0s - loss: 8.1214 - accuracy: 0.4822\n",
            "Epoch 00001: accuracy improved from -inf to 0.48291, saving model to Small_AlexNet_with_Dropout-weights-improvement-01.hdf5\n",
            "3276/3276 [==============================] - 3s 1ms/sample - loss: 8.0845 - accuracy: 0.4829 - val_loss: 2.0249 - val_accuracy: 0.4795\n",
            "Epoch 2/10\n",
            "3200/3276 [============================>.] - ETA: 0s - loss: 6.2561 - accuracy: 0.5022\n",
            "Epoch 00002: accuracy improved from 0.48291 to 0.50214, saving model to Small_AlexNet_with_Dropout-weights-improvement-02.hdf5\n",
            "3276/3276 [==============================] - 3s 838us/sample - loss: 6.2487 - accuracy: 0.5021 - val_loss: 1.7334 - val_accuracy: 0.4877\n",
            "Epoch 3/10\n",
            "3200/3276 [============================>.] - ETA: 0s - loss: 4.8211 - accuracy: 0.5191\n",
            "Epoch 00003: accuracy improved from 0.50214 to 0.51862, saving model to Small_AlexNet_with_Dropout-weights-improvement-03.hdf5\n",
            "3276/3276 [==============================] - 3s 818us/sample - loss: 4.8214 - accuracy: 0.5186 - val_loss: 1.6139 - val_accuracy: 0.5068\n",
            "Epoch 4/10\n",
            "3200/3276 [============================>.] - ETA: 0s - loss: 4.3280 - accuracy: 0.5166\n",
            "Epoch 00004: accuracy did not improve from 0.51862\n",
            "3276/3276 [==============================] - 2s 639us/sample - loss: 4.3185 - accuracy: 0.5165 - val_loss: 1.4883 - val_accuracy: 0.5014\n",
            "Epoch 5/10\n",
            "3200/3276 [============================>.] - ETA: 0s - loss: 4.0285 - accuracy: 0.5038\n",
            "Epoch 00005: accuracy did not improve from 0.51862\n",
            "3276/3276 [==============================] - 2s 636us/sample - loss: 4.0445 - accuracy: 0.5040 - val_loss: 1.3976 - val_accuracy: 0.4932\n",
            "Epoch 6/10\n",
            "3200/3276 [============================>.] - ETA: 0s - loss: 3.6803 - accuracy: 0.5044\n",
            "Epoch 00006: accuracy did not improve from 0.51862\n",
            "3276/3276 [==============================] - 2s 635us/sample - loss: 3.6795 - accuracy: 0.5058 - val_loss: 1.5012 - val_accuracy: 0.4932\n",
            "Epoch 7/10\n",
            "3200/3276 [============================>.] - ETA: 0s - loss: 3.4731 - accuracy: 0.5000\n",
            "Epoch 00007: accuracy did not improve from 0.51862\n",
            "3276/3276 [==============================] - 2s 627us/sample - loss: 3.4539 - accuracy: 0.5021 - val_loss: 1.2914 - val_accuracy: 0.4822\n",
            "Epoch 8/10\n",
            "3200/3276 [============================>.] - ETA: 0s - loss: 3.2822 - accuracy: 0.4909\n",
            "Epoch 00008: accuracy did not improve from 0.51862\n",
            "3276/3276 [==============================] - 2s 629us/sample - loss: 3.2822 - accuracy: 0.4918 - val_loss: 1.3540 - val_accuracy: 0.4904\n",
            "Epoch 9/10\n",
            "3200/3276 [============================>.] - ETA: 0s - loss: 3.0023 - accuracy: 0.5016\n",
            "Epoch 00009: accuracy did not improve from 0.51862\n",
            "3276/3276 [==============================] - 2s 630us/sample - loss: 3.0139 - accuracy: 0.5003 - val_loss: 1.0549 - val_accuracy: 0.4740\n",
            "Epoch 10/10\n",
            "3200/3276 [============================>.] - ETA: 0s - loss: 2.7326 - accuracy: 0.5131\n",
            "Epoch 00010: accuracy did not improve from 0.51862\n",
            "3276/3276 [==============================] - 2s 638us/sample - loss: 2.7384 - accuracy: 0.5116 - val_loss: 1.0038 - val_accuracy: 0.5041\n",
            "\n",
            "Fold  1\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "Epoch 1/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 2.5245 - accuracy: 0.4953\n",
            "Epoch 00001: accuracy did not improve from 0.51862\n",
            "3277/3277 [==============================] - 2s 634us/sample - loss: 2.5078 - accuracy: 0.4983 - val_loss: 0.9774 - val_accuracy: 0.4808\n",
            "Epoch 2/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 2.3679 - accuracy: 0.5044\n",
            "Epoch 00002: accuracy did not improve from 0.51862\n",
            "3277/3277 [==============================] - 2s 635us/sample - loss: 2.3584 - accuracy: 0.5056 - val_loss: 0.9526 - val_accuracy: 0.4698\n",
            "Epoch 3/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 2.1357 - accuracy: 0.5025\n",
            "Epoch 00003: accuracy did not improve from 0.51862\n",
            "3277/3277 [==============================] - 2s 640us/sample - loss: 2.1297 - accuracy: 0.5023 - val_loss: 0.9182 - val_accuracy: 0.4396\n",
            "Epoch 4/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 2.0911 - accuracy: 0.4891\n",
            "Epoch 00004: accuracy did not improve from 0.51862\n",
            "3277/3277 [==============================] - 2s 635us/sample - loss: 2.0902 - accuracy: 0.4907 - val_loss: 0.9172 - val_accuracy: 0.4423\n",
            "Epoch 5/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 2.0507 - accuracy: 0.4894\n",
            "Epoch 00005: accuracy did not improve from 0.51862\n",
            "3277/3277 [==============================] - 2s 641us/sample - loss: 2.0595 - accuracy: 0.4883 - val_loss: 0.8882 - val_accuracy: 0.4698\n",
            "Epoch 6/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.7768 - accuracy: 0.5078\n",
            "Epoch 00006: accuracy did not improve from 0.51862\n",
            "3277/3277 [==============================] - 2s 638us/sample - loss: 1.7810 - accuracy: 0.5090 - val_loss: 0.8999 - val_accuracy: 0.4973\n",
            "Epoch 7/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.7943 - accuracy: 0.5063\n",
            "Epoch 00007: accuracy did not improve from 0.51862\n",
            "3277/3277 [==============================] - 2s 642us/sample - loss: 1.7906 - accuracy: 0.5063 - val_loss: 0.8718 - val_accuracy: 0.4505\n",
            "Epoch 8/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.7592 - accuracy: 0.4922\n",
            "Epoch 00008: accuracy did not improve from 0.51862\n",
            "3277/3277 [==============================] - 2s 641us/sample - loss: 1.7580 - accuracy: 0.4916 - val_loss: 0.8664 - val_accuracy: 0.4615\n",
            "Epoch 9/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.5954 - accuracy: 0.5003\n",
            "Epoch 00009: accuracy did not improve from 0.51862\n",
            "3277/3277 [==============================] - 2s 636us/sample - loss: 1.5980 - accuracy: 0.5011 - val_loss: 0.8572 - val_accuracy: 0.4478\n",
            "Epoch 10/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.6036 - accuracy: 0.5047\n",
            "Epoch 00010: accuracy did not improve from 0.51862\n",
            "3277/3277 [==============================] - 2s 641us/sample - loss: 1.5979 - accuracy: 0.5078 - val_loss: 0.8522 - val_accuracy: 0.4808\n",
            "\n",
            "Fold  2\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "Epoch 1/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.5362 - accuracy: 0.5059\n",
            "Epoch 00001: accuracy did not improve from 0.51862\n",
            "3277/3277 [==============================] - 2s 633us/sample - loss: 1.5393 - accuracy: 0.5063 - val_loss: 0.8036 - val_accuracy: 0.5192\n",
            "Epoch 2/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.5188 - accuracy: 0.5050\n",
            "Epoch 00002: accuracy did not improve from 0.51862\n",
            "3277/3277 [==============================] - 2s 632us/sample - loss: 1.5230 - accuracy: 0.5038 - val_loss: 0.7962 - val_accuracy: 0.5247\n",
            "Epoch 3/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.4449 - accuracy: 0.5188\n",
            "Epoch 00003: accuracy improved from 0.51862 to 0.52090, saving model to Small_AlexNet_with_Dropout-weights-improvement-03.hdf5\n",
            "3277/3277 [==============================] - 2s 751us/sample - loss: 1.4446 - accuracy: 0.5209 - val_loss: 0.7950 - val_accuracy: 0.5110\n",
            "Epoch 4/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.4387 - accuracy: 0.5044\n",
            "Epoch 00004: accuracy did not improve from 0.52090\n",
            "3277/3277 [==============================] - 2s 632us/sample - loss: 1.4363 - accuracy: 0.5041 - val_loss: 0.7810 - val_accuracy: 0.5330\n",
            "Epoch 5/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.3610 - accuracy: 0.5216\n",
            "Epoch 00005: accuracy did not improve from 0.52090\n",
            "3277/3277 [==============================] - 2s 622us/sample - loss: 1.3642 - accuracy: 0.5206 - val_loss: 0.7757 - val_accuracy: 0.5385\n",
            "Epoch 6/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.3748 - accuracy: 0.5016\n",
            "Epoch 00006: accuracy did not improve from 0.52090\n",
            "3277/3277 [==============================] - 2s 626us/sample - loss: 1.3669 - accuracy: 0.5038 - val_loss: 0.7682 - val_accuracy: 0.5302\n",
            "Epoch 7/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.3301 - accuracy: 0.5097\n",
            "Epoch 00007: accuracy did not improve from 0.52090\n",
            "3277/3277 [==============================] - 2s 626us/sample - loss: 1.3321 - accuracy: 0.5102 - val_loss: 0.7625 - val_accuracy: 0.5302\n",
            "Epoch 8/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.3137 - accuracy: 0.5131\n",
            "Epoch 00008: accuracy did not improve from 0.52090\n",
            "3277/3277 [==============================] - 2s 629us/sample - loss: 1.3069 - accuracy: 0.5151 - val_loss: 0.7590 - val_accuracy: 0.5330\n",
            "Epoch 9/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.3299 - accuracy: 0.4966\n",
            "Epoch 00009: accuracy did not improve from 0.52090\n",
            "3277/3277 [==============================] - 2s 623us/sample - loss: 1.3352 - accuracy: 0.4956 - val_loss: 0.7554 - val_accuracy: 0.5330\n",
            "Epoch 10/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.2750 - accuracy: 0.5031\n",
            "Epoch 00010: accuracy did not improve from 0.52090\n",
            "3277/3277 [==============================] - 2s 625us/sample - loss: 1.2764 - accuracy: 0.5005 - val_loss: 0.7427 - val_accuracy: 0.5385\n",
            "\n",
            "Fold  3\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "Epoch 1/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.2514 - accuracy: 0.5041\n",
            "Epoch 00001: accuracy did not improve from 0.52090\n",
            "3277/3277 [==============================] - 2s 640us/sample - loss: 1.2513 - accuracy: 0.5044 - val_loss: 0.7284 - val_accuracy: 0.5604\n",
            "Epoch 2/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.1921 - accuracy: 0.5100\n",
            "Epoch 00002: accuracy did not improve from 0.52090\n",
            "3277/3277 [==============================] - 2s 637us/sample - loss: 1.1917 - accuracy: 0.5102 - val_loss: 0.7267 - val_accuracy: 0.5659\n",
            "Epoch 3/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.2357 - accuracy: 0.5009\n",
            "Epoch 00003: accuracy did not improve from 0.52090\n",
            "3277/3277 [==============================] - 2s 621us/sample - loss: 1.2342 - accuracy: 0.5026 - val_loss: 0.7246 - val_accuracy: 0.5604\n",
            "Epoch 4/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.2143 - accuracy: 0.4956\n",
            "Epoch 00004: accuracy did not improve from 0.52090\n",
            "3277/3277 [==============================] - 2s 628us/sample - loss: 1.2125 - accuracy: 0.4980 - val_loss: 0.7235 - val_accuracy: 0.5604\n",
            "Epoch 5/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.1871 - accuracy: 0.5028\n",
            "Epoch 00005: accuracy did not improve from 0.52090\n",
            "3277/3277 [==============================] - 2s 617us/sample - loss: 1.1974 - accuracy: 0.4995 - val_loss: 0.7227 - val_accuracy: 0.5522\n",
            "Epoch 6/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.1192 - accuracy: 0.5216\n",
            "Epoch 00006: accuracy improved from 0.52090 to 0.52151, saving model to Small_AlexNet_with_Dropout-weights-improvement-06.hdf5\n",
            "3277/3277 [==============================] - 3s 766us/sample - loss: 1.1162 - accuracy: 0.5215 - val_loss: 0.7217 - val_accuracy: 0.5495\n",
            "Epoch 7/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.1666 - accuracy: 0.5022\n",
            "Epoch 00007: accuracy did not improve from 0.52151\n",
            "3277/3277 [==============================] - 2s 621us/sample - loss: 1.1652 - accuracy: 0.5029 - val_loss: 0.7205 - val_accuracy: 0.5549\n",
            "Epoch 8/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.1392 - accuracy: 0.5028\n",
            "Epoch 00008: accuracy did not improve from 0.52151\n",
            "3277/3277 [==============================] - 2s 636us/sample - loss: 1.1396 - accuracy: 0.5032 - val_loss: 0.7167 - val_accuracy: 0.5495\n",
            "Epoch 9/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.1278 - accuracy: 0.4981\n",
            "Epoch 00009: accuracy did not improve from 0.52151\n",
            "3277/3277 [==============================] - 2s 638us/sample - loss: 1.1277 - accuracy: 0.4974 - val_loss: 0.7167 - val_accuracy: 0.5577\n",
            "Epoch 10/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.0784 - accuracy: 0.5072\n",
            "Epoch 00010: accuracy did not improve from 0.52151\n",
            "3277/3277 [==============================] - 2s 640us/sample - loss: 1.0740 - accuracy: 0.5102 - val_loss: 0.7154 - val_accuracy: 0.5330\n",
            "\n",
            "Fold  4\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "Epoch 1/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.1017 - accuracy: 0.4944\n",
            "Epoch 00001: accuracy did not improve from 0.52151\n",
            "3277/3277 [==============================] - 2s 647us/sample - loss: 1.0971 - accuracy: 0.4977 - val_loss: 0.7485 - val_accuracy: 0.5165\n",
            "Epoch 2/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.1148 - accuracy: 0.4966\n",
            "Epoch 00002: accuracy did not improve from 0.52151\n",
            "3277/3277 [==============================] - 2s 640us/sample - loss: 1.1115 - accuracy: 0.4977 - val_loss: 0.7538 - val_accuracy: 0.5110\n",
            "Epoch 3/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.0574 - accuracy: 0.4938\n",
            "Epoch 00003: accuracy did not improve from 0.52151\n",
            "3277/3277 [==============================] - 2s 646us/sample - loss: 1.0612 - accuracy: 0.4928 - val_loss: 0.7465 - val_accuracy: 0.5137\n",
            "Epoch 4/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.0303 - accuracy: 0.5203\n",
            "Epoch 00004: accuracy did not improve from 0.52151\n",
            "3277/3277 [==============================] - 2s 631us/sample - loss: 1.0286 - accuracy: 0.5203 - val_loss: 0.7463 - val_accuracy: 0.5110\n",
            "Epoch 5/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.0170 - accuracy: 0.5106\n",
            "Epoch 00005: accuracy did not improve from 0.52151\n",
            "3277/3277 [==============================] - 2s 646us/sample - loss: 1.0170 - accuracy: 0.5127 - val_loss: 0.7426 - val_accuracy: 0.5220\n",
            "Epoch 6/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.0057 - accuracy: 0.5178\n",
            "Epoch 00006: accuracy did not improve from 0.52151\n",
            "3277/3277 [==============================] - 2s 646us/sample - loss: 1.0107 - accuracy: 0.5160 - val_loss: 0.7424 - val_accuracy: 0.5165\n",
            "Epoch 7/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.0086 - accuracy: 0.5081\n",
            "Epoch 00007: accuracy did not improve from 0.52151\n",
            "3277/3277 [==============================] - 2s 634us/sample - loss: 1.0081 - accuracy: 0.5099 - val_loss: 0.7376 - val_accuracy: 0.5137\n",
            "Epoch 8/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 1.0098 - accuracy: 0.4966\n",
            "Epoch 00008: accuracy did not improve from 0.52151\n",
            "3277/3277 [==============================] - 2s 629us/sample - loss: 1.0109 - accuracy: 0.4956 - val_loss: 0.7378 - val_accuracy: 0.5137\n",
            "Epoch 9/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.9886 - accuracy: 0.5138\n",
            "Epoch 00009: accuracy did not improve from 0.52151\n",
            "3277/3277 [==============================] - 2s 636us/sample - loss: 0.9861 - accuracy: 0.5157 - val_loss: 0.7381 - val_accuracy: 0.4973\n",
            "Epoch 10/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.9896 - accuracy: 0.5125\n",
            "Epoch 00010: accuracy did not improve from 0.52151\n",
            "3277/3277 [==============================] - 2s 649us/sample - loss: 0.9882 - accuracy: 0.5136 - val_loss: 0.7344 - val_accuracy: 0.5165\n",
            "\n",
            "Fold  5\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "Epoch 1/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.9830 - accuracy: 0.4997\n",
            "Epoch 00001: accuracy did not improve from 0.52151\n",
            "3277/3277 [==============================] - 2s 638us/sample - loss: 0.9837 - accuracy: 0.4980 - val_loss: 0.7413 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.9708 - accuracy: 0.5084\n",
            "Epoch 00002: accuracy did not improve from 0.52151\n",
            "3277/3277 [==============================] - 2s 635us/sample - loss: 0.9736 - accuracy: 0.5069 - val_loss: 0.7380 - val_accuracy: 0.4945\n",
            "Epoch 3/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.9428 - accuracy: 0.5047\n",
            "Epoch 00003: accuracy did not improve from 0.52151\n",
            "3277/3277 [==============================] - 2s 637us/sample - loss: 0.9424 - accuracy: 0.5053 - val_loss: 0.7356 - val_accuracy: 0.4973\n",
            "Epoch 4/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.9341 - accuracy: 0.5159\n",
            "Epoch 00004: accuracy did not improve from 0.52151\n",
            "3277/3277 [==============================] - 2s 644us/sample - loss: 0.9347 - accuracy: 0.5148 - val_loss: 0.7342 - val_accuracy: 0.4973\n",
            "Epoch 5/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.9403 - accuracy: 0.5119\n",
            "Epoch 00005: accuracy did not improve from 0.52151\n",
            "3277/3277 [==============================] - 2s 636us/sample - loss: 0.9410 - accuracy: 0.5121 - val_loss: 0.7397 - val_accuracy: 0.5137\n",
            "Epoch 6/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.9386 - accuracy: 0.5163\n",
            "Epoch 00006: accuracy did not improve from 0.52151\n",
            "3277/3277 [==============================] - 2s 630us/sample - loss: 0.9382 - accuracy: 0.5163 - val_loss: 0.7344 - val_accuracy: 0.5082\n",
            "Epoch 7/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.9152 - accuracy: 0.5147\n",
            "Epoch 00007: accuracy did not improve from 0.52151\n",
            "3277/3277 [==============================] - 2s 641us/sample - loss: 0.9170 - accuracy: 0.5139 - val_loss: 0.7333 - val_accuracy: 0.5165\n",
            "Epoch 8/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.9189 - accuracy: 0.5259\n",
            "Epoch 00008: accuracy improved from 0.52151 to 0.52487, saving model to Small_AlexNet_with_Dropout-weights-improvement-08.hdf5\n",
            "3277/3277 [==============================] - 3s 778us/sample - loss: 0.9187 - accuracy: 0.5249 - val_loss: 0.7316 - val_accuracy: 0.5192\n",
            "Epoch 9/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.9196 - accuracy: 0.5081\n",
            "Epoch 00009: accuracy did not improve from 0.52487\n",
            "3277/3277 [==============================] - 2s 632us/sample - loss: 0.9212 - accuracy: 0.5081 - val_loss: 0.7362 - val_accuracy: 0.5027\n",
            "Epoch 10/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.9027 - accuracy: 0.5194\n",
            "Epoch 00010: accuracy did not improve from 0.52487\n",
            "3277/3277 [==============================] - 2s 641us/sample - loss: 0.8999 - accuracy: 0.5200 - val_loss: 0.7329 - val_accuracy: 0.5055\n",
            "\n",
            "Fold  6\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "Epoch 1/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.9147 - accuracy: 0.5097\n",
            "Epoch 00001: accuracy did not improve from 0.52487\n",
            "3277/3277 [==============================] - 2s 645us/sample - loss: 0.9167 - accuracy: 0.5093 - val_loss: 0.7235 - val_accuracy: 0.5247\n",
            "Epoch 2/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.9065 - accuracy: 0.5081\n",
            "Epoch 00002: accuracy did not improve from 0.52487\n",
            "3277/3277 [==============================] - 2s 639us/sample - loss: 0.9043 - accuracy: 0.5099 - val_loss: 0.7207 - val_accuracy: 0.5330\n",
            "Epoch 3/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8788 - accuracy: 0.5172\n",
            "Epoch 00003: accuracy did not improve from 0.52487\n",
            "3277/3277 [==============================] - 2s 630us/sample - loss: 0.8800 - accuracy: 0.5163 - val_loss: 0.7261 - val_accuracy: 0.5302\n",
            "Epoch 4/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.9059 - accuracy: 0.5050\n",
            "Epoch 00004: accuracy did not improve from 0.52487\n",
            "3277/3277 [==============================] - 2s 639us/sample - loss: 0.9018 - accuracy: 0.5063 - val_loss: 0.7219 - val_accuracy: 0.5247\n",
            "Epoch 5/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.9042 - accuracy: 0.5025\n",
            "Epoch 00005: accuracy did not improve from 0.52487\n",
            "3277/3277 [==============================] - 2s 640us/sample - loss: 0.9076 - accuracy: 0.4995 - val_loss: 0.7220 - val_accuracy: 0.5220\n",
            "Epoch 6/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8754 - accuracy: 0.5119\n",
            "Epoch 00006: accuracy did not improve from 0.52487\n",
            "3277/3277 [==============================] - 2s 640us/sample - loss: 0.8717 - accuracy: 0.5142 - val_loss: 0.7203 - val_accuracy: 0.5192\n",
            "Epoch 7/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8833 - accuracy: 0.4991\n",
            "Epoch 00007: accuracy did not improve from 0.52487\n",
            "3277/3277 [==============================] - 2s 638us/sample - loss: 0.8785 - accuracy: 0.5023 - val_loss: 0.7195 - val_accuracy: 0.5220\n",
            "Epoch 8/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8576 - accuracy: 0.5241\n",
            "Epoch 00008: accuracy did not improve from 0.52487\n",
            "3277/3277 [==============================] - 2s 637us/sample - loss: 0.8582 - accuracy: 0.5240 - val_loss: 0.7200 - val_accuracy: 0.5192\n",
            "Epoch 9/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8627 - accuracy: 0.5050\n",
            "Epoch 00009: accuracy did not improve from 0.52487\n",
            "3277/3277 [==============================] - 2s 630us/sample - loss: 0.8652 - accuracy: 0.5029 - val_loss: 0.7182 - val_accuracy: 0.5247\n",
            "Epoch 10/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8583 - accuracy: 0.5063\n",
            "Epoch 00010: accuracy did not improve from 0.52487\n",
            "3277/3277 [==============================] - 2s 620us/sample - loss: 0.8593 - accuracy: 0.5056 - val_loss: 0.7194 - val_accuracy: 0.5247\n",
            "\n",
            "Fold  7\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "Epoch 1/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8569 - accuracy: 0.5153\n",
            "Epoch 00001: accuracy did not improve from 0.52487\n",
            "3277/3277 [==============================] - 2s 637us/sample - loss: 0.8568 - accuracy: 0.5154 - val_loss: 0.7287 - val_accuracy: 0.4918\n",
            "Epoch 2/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8735 - accuracy: 0.5150\n",
            "Epoch 00002: accuracy did not improve from 0.52487\n",
            "3277/3277 [==============================] - 2s 653us/sample - loss: 0.8731 - accuracy: 0.5139 - val_loss: 0.7272 - val_accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8457 - accuracy: 0.5197\n",
            "Epoch 00003: accuracy did not improve from 0.52487\n",
            "3277/3277 [==============================] - 2s 655us/sample - loss: 0.8439 - accuracy: 0.5200 - val_loss: 0.7278 - val_accuracy: 0.4945\n",
            "Epoch 4/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8456 - accuracy: 0.5213\n",
            "Epoch 00004: accuracy did not improve from 0.52487\n",
            "3277/3277 [==============================] - 2s 641us/sample - loss: 0.8457 - accuracy: 0.5221 - val_loss: 0.7270 - val_accuracy: 0.4890\n",
            "Epoch 5/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8635 - accuracy: 0.4941\n",
            "Epoch 00005: accuracy did not improve from 0.52487\n",
            "3277/3277 [==============================] - 2s 641us/sample - loss: 0.8638 - accuracy: 0.4937 - val_loss: 0.7276 - val_accuracy: 0.5027\n",
            "Epoch 6/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8693 - accuracy: 0.5000\n",
            "Epoch 00006: accuracy did not improve from 0.52487\n",
            "3277/3277 [==============================] - 2s 638us/sample - loss: 0.8684 - accuracy: 0.4992 - val_loss: 0.7267 - val_accuracy: 0.4945\n",
            "Epoch 7/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8233 - accuracy: 0.5206\n",
            "Epoch 00007: accuracy did not improve from 0.52487\n",
            "3277/3277 [==============================] - 2s 636us/sample - loss: 0.8242 - accuracy: 0.5203 - val_loss: 0.7259 - val_accuracy: 0.5082\n",
            "Epoch 8/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8336 - accuracy: 0.5372\n",
            "Epoch 00008: accuracy improved from 0.52487 to 0.53921, saving model to Small_AlexNet_with_Dropout-weights-improvement-08.hdf5\n",
            "3277/3277 [==============================] - 2s 734us/sample - loss: 0.8297 - accuracy: 0.5392 - val_loss: 0.7259 - val_accuracy: 0.4863\n",
            "Epoch 9/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8243 - accuracy: 0.5178\n",
            "Epoch 00009: accuracy did not improve from 0.53921\n",
            "3277/3277 [==============================] - 2s 638us/sample - loss: 0.8244 - accuracy: 0.5175 - val_loss: 0.7258 - val_accuracy: 0.4918\n",
            "Epoch 10/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8338 - accuracy: 0.5125\n",
            "Epoch 00010: accuracy did not improve from 0.53921\n",
            "3277/3277 [==============================] - 2s 637us/sample - loss: 0.8338 - accuracy: 0.5117 - val_loss: 0.7242 - val_accuracy: 0.4835\n",
            "\n",
            "Fold  8\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "Epoch 1/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8241 - accuracy: 0.5128\n",
            "Epoch 00001: accuracy did not improve from 0.53921\n",
            "3277/3277 [==============================] - 2s 639us/sample - loss: 0.8231 - accuracy: 0.5136 - val_loss: 0.7287 - val_accuracy: 0.4780\n",
            "Epoch 2/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8129 - accuracy: 0.5337\n",
            "Epoch 00002: accuracy did not improve from 0.53921\n",
            "3277/3277 [==============================] - 2s 639us/sample - loss: 0.8123 - accuracy: 0.5313 - val_loss: 0.7284 - val_accuracy: 0.4918\n",
            "Epoch 3/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8439 - accuracy: 0.4984\n",
            "Epoch 00003: accuracy did not improve from 0.53921\n",
            "3277/3277 [==============================] - 2s 645us/sample - loss: 0.8468 - accuracy: 0.4974 - val_loss: 0.7298 - val_accuracy: 0.4890\n",
            "Epoch 4/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8332 - accuracy: 0.5044\n",
            "Epoch 00004: accuracy did not improve from 0.53921\n",
            "3277/3277 [==============================] - 2s 635us/sample - loss: 0.8317 - accuracy: 0.5050 - val_loss: 0.7290 - val_accuracy: 0.4890\n",
            "Epoch 5/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8219 - accuracy: 0.5122\n",
            "Epoch 00005: accuracy did not improve from 0.53921\n",
            "3277/3277 [==============================] - 2s 636us/sample - loss: 0.8211 - accuracy: 0.5124 - val_loss: 0.7277 - val_accuracy: 0.4835\n",
            "Epoch 6/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8138 - accuracy: 0.5184\n",
            "Epoch 00006: accuracy did not improve from 0.53921\n",
            "3277/3277 [==============================] - 2s 641us/sample - loss: 0.8113 - accuracy: 0.5191 - val_loss: 0.7271 - val_accuracy: 0.4808\n",
            "Epoch 7/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8052 - accuracy: 0.5203\n",
            "Epoch 00007: accuracy did not improve from 0.53921\n",
            "3277/3277 [==============================] - 2s 636us/sample - loss: 0.8054 - accuracy: 0.5179 - val_loss: 0.7271 - val_accuracy: 0.4890\n",
            "Epoch 8/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8039 - accuracy: 0.5216\n",
            "Epoch 00008: accuracy did not improve from 0.53921\n",
            "3277/3277 [==============================] - 2s 642us/sample - loss: 0.8042 - accuracy: 0.5194 - val_loss: 0.7276 - val_accuracy: 0.4918\n",
            "Epoch 9/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.7989 - accuracy: 0.5216\n",
            "Epoch 00009: accuracy did not improve from 0.53921\n",
            "3277/3277 [==============================] - 2s 638us/sample - loss: 0.7973 - accuracy: 0.5218 - val_loss: 0.7256 - val_accuracy: 0.4780\n",
            "Epoch 10/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8069 - accuracy: 0.5225\n",
            "Epoch 00010: accuracy did not improve from 0.53921\n",
            "3277/3277 [==============================] - 2s 635us/sample - loss: 0.8058 - accuracy: 0.5230 - val_loss: 0.7270 - val_accuracy: 0.4973\n",
            "\n",
            "Fold  9\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "Epoch 1/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8052 - accuracy: 0.5169\n",
            "Epoch 00001: accuracy did not improve from 0.53921\n",
            "3277/3277 [==============================] - 2s 641us/sample - loss: 0.8057 - accuracy: 0.5169 - val_loss: 0.6927 - val_accuracy: 0.5440\n",
            "Epoch 2/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8047 - accuracy: 0.5213\n",
            "Epoch 00002: accuracy did not improve from 0.53921\n",
            "3277/3277 [==============================] - 2s 637us/sample - loss: 0.8036 - accuracy: 0.5212 - val_loss: 0.6929 - val_accuracy: 0.5412\n",
            "Epoch 3/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8108 - accuracy: 0.5122\n",
            "Epoch 00003: accuracy did not improve from 0.53921\n",
            "3277/3277 [==============================] - 2s 642us/sample - loss: 0.8125 - accuracy: 0.5099 - val_loss: 0.6931 - val_accuracy: 0.5467\n",
            "Epoch 4/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8005 - accuracy: 0.5113\n",
            "Epoch 00004: accuracy did not improve from 0.53921\n",
            "3277/3277 [==============================] - 2s 642us/sample - loss: 0.8003 - accuracy: 0.5117 - val_loss: 0.6937 - val_accuracy: 0.5440\n",
            "Epoch 5/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.7975 - accuracy: 0.5122\n",
            "Epoch 00005: accuracy did not improve from 0.53921\n",
            "3277/3277 [==============================] - 2s 642us/sample - loss: 0.7965 - accuracy: 0.5133 - val_loss: 0.6931 - val_accuracy: 0.5302\n",
            "Epoch 6/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.7904 - accuracy: 0.5053\n",
            "Epoch 00006: accuracy did not improve from 0.53921\n",
            "3277/3277 [==============================] - 2s 642us/sample - loss: 0.7895 - accuracy: 0.5063 - val_loss: 0.6926 - val_accuracy: 0.5412\n",
            "Epoch 7/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.8033 - accuracy: 0.5081\n",
            "Epoch 00007: accuracy did not improve from 0.53921\n",
            "3277/3277 [==============================] - 2s 653us/sample - loss: 0.8032 - accuracy: 0.5075 - val_loss: 0.6935 - val_accuracy: 0.5467\n",
            "Epoch 8/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.7875 - accuracy: 0.5175\n",
            "Epoch 00008: accuracy did not improve from 0.53921\n",
            "3277/3277 [==============================] - 2s 651us/sample - loss: 0.7869 - accuracy: 0.5179 - val_loss: 0.6931 - val_accuracy: 0.5467\n",
            "Epoch 9/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.7879 - accuracy: 0.5241\n",
            "Epoch 00009: accuracy did not improve from 0.53921\n",
            "3277/3277 [==============================] - 2s 652us/sample - loss: 0.7867 - accuracy: 0.5236 - val_loss: 0.6932 - val_accuracy: 0.5549\n",
            "Epoch 10/10\n",
            "3200/3277 [============================>.] - ETA: 0s - loss: 0.7985 - accuracy: 0.4988\n",
            "Epoch 00010: accuracy did not improve from 0.53921\n",
            "3277/3277 [==============================] - 2s 649us/sample - loss: 0.7980 - accuracy: 0.4986 - val_loss: 0.6946 - val_accuracy: 0.5440\n",
            "643/643 [==============================] - 0s 313us/sample - loss: 0.6920 - accuracy: 0.5272\n",
            "Test set metrics: accuracy: 52.72%\n",
            "Saved model Small_AlexNet_with_Dropout to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd_kRUDaTaxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TJu_4vQTatU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a2HKyYnTaqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rzdn49dwTaor",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}