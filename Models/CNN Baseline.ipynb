{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "CNN Baseline.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtZyMdquHZe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, SeparableConv2D, MaxPooling3D, Conv3D, DepthwiseConv2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDot5tyiIVZo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "4286f2c1-2a4b-45d4-935e-ac47c5f77809"
      },
      "source": [
        "# Colab settings/mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/My\\ Drive/CSE\\ 240/Project/Data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/CSE 240/Project/Data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9wUwPkmIqE_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5b8ed161-4be8-4809-d90d-78a623fb0a38"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mSpectrograms\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS-F1iC3HZfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = load_img('Spectrograms/train/concentration/S001E02_AF3.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-g_4KvFHZfL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "2e7962cc-7688-47eb-9366-dfc18dead89b"
      },
      "source": [
        "print(type(img))\n",
        "print(img.format)\n",
        "print(img.mode)\n",
        "print(img.size)\n",
        "print(img)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'PIL.Image.Image'>\n",
            "None\n",
            "RGB\n",
            "(432, 288)\n",
            "<PIL.Image.Image image mode=RGB size=432x288 at 0x7EFF23E8DC18>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5smDQZ8ZHZfR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "32eea6d3-905e-4cc2-c0d1-b370a68011d0"
      },
      "source": [
        "print(type(img))\n",
        "# convert to numpy array\n",
        "img_array = img_to_array(img)\n",
        "print(img_array.dtype)\n",
        "print(img_array.shape)\n",
        "print(img_array[0][0])\n",
        "# convert back to image\n",
        "img_pil = array_to_img(img_array)\n",
        "print(type(img))\n",
        "#for i in range(288):\n",
        "  #for j in range(432):\n",
        "    #print(img_array[i][j])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'PIL.Image.Image'>\n",
            "float32\n",
            "(288, 432, 3)\n",
            "[255. 255. 255.]\n",
            "<class 'PIL.Image.Image'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnYVP4KHHZfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UKrQyG4RzTj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d916344b-582d-486f-bf8a-cd1374942100"
      },
      "source": [
        "base_path = \"Spectrograms/concentration\"\n",
        "concentration_data_array = []\n",
        "for foldername in os.listdir(base_path):\n",
        "  print(foldername)\n",
        "  array = np.zeros((288,432,1))\n",
        "  for filename in os.listdir(os.path.join(base_path, foldername)):\n",
        "    example = foldername\n",
        "    channel = filename.split('.')[0].split(\"_\")[1]\n",
        "    filepath = os.path.join(os.path.join(base_path, foldername), filename)\n",
        "    #print(filename,filepath)\n",
        "    img = load_img(filepath)\n",
        "    img_array = img_to_array(img)\n",
        "    #print(img_array.shape, array.shape)\n",
        "    array = np.concatenate((array, img_array), axis=2)\n",
        "    #print(img_array.shape, array.shape)\n",
        "  concentration_data_array.append(np.delete(array,0,2))\n",
        "#print(data_array['S025E02'].shape)\n",
        "concentration_data_array = np.array(concentration_data_array)\n",
        "print(concentration_data_array.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "S005E04\n",
            "S003E04\n",
            "S002E04\n",
            "S001E04\n",
            "S001E02\n",
            "S006E04\n",
            "S007E04\n",
            "S008E04\n",
            "S009E04\n",
            "S010E04\n",
            "S011E04\n",
            "S013E04\n",
            "S012E04\n",
            "S014E04\n",
            "S015E04\n",
            "S016E04\n",
            "S017E04\n",
            "S018E04\n",
            "S019E04\n",
            "S020E04\n",
            "S021E04\n",
            "S022E04\n",
            "S023E04\n",
            "S024E04\n",
            "S025E04\n",
            "S026E04\n",
            "S027E04\n",
            "S028E04\n",
            "S029E04\n",
            "S030E04\n",
            "S002E02\n",
            "S003E02\n",
            "S004E02\n",
            "S005E02\n",
            "S006E02\n",
            "S007E02\n",
            "S008E02\n",
            "S009E02\n",
            "S010E02\n",
            "S011E02\n",
            "S012E02\n",
            "S013E02\n",
            "S014E02\n",
            "S015E02\n",
            "S016E02\n",
            "S017E02\n",
            "S018E02\n",
            "S019E02\n",
            "S020E02\n",
            "S021E02\n",
            "S022E02\n",
            "S023E02\n",
            "S024E02\n",
            "S025E02\n",
            "S026E02\n",
            "S027E02\n",
            "S028E02\n",
            "S029E02\n",
            "S030E02\n",
            "S004E04\n",
            "(60, 288, 432, 42)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UycYYSlSR6tX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0a41dcc6-b554-4ebd-d705-d882c1422eb8"
      },
      "source": [
        "base_path = \"Spectrograms/relaxed\"\n",
        "relaxed_data_array = []\n",
        "for foldername in os.listdir(base_path):\n",
        "  print(foldername)\n",
        "  array = np.zeros((288,432,1))\n",
        "  for filename in os.listdir(os.path.join(base_path, foldername)):\n",
        "    example = foldername\n",
        "    channel = filename.split('.')[0].split(\"_\")[1]\n",
        "    filepath = os.path.join(os.path.join(base_path, foldername), filename)\n",
        "    #print(filename,filepath)\n",
        "    img = load_img(filepath)\n",
        "    img_array = img_to_array(img)\n",
        "    #print(img_array.shape, array.shape)\n",
        "    array = np.concatenate((array, img_array), axis=2)\n",
        "    #print(img_array.shape, array.shape)\n",
        "  relaxed_data_array.append(np.delete(array,0,2))\n",
        "#print(data_array['S025E02'].shape)\n",
        "relaxed_data_array = np.array(relaxed_data_array)\n",
        "print(relaxed_data_array.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "S001E01\n",
            "S001E03\n",
            "S002E01\n",
            "S002E03\n",
            "S003E01\n",
            "S004E01\n",
            "S005E01\n",
            "S006E01\n",
            "S007E01\n",
            "S008E01\n",
            "S009E01\n",
            "S010E01\n",
            "S011E01\n",
            "S012E01\n",
            "S013E01\n",
            "S014E01\n",
            "S015E01\n",
            "S016E01\n",
            "S017E01\n",
            "S018E01\n",
            "S019E01\n",
            "S020E01\n",
            "S021E01\n",
            "S022E01\n",
            "S023E01\n",
            "S024E01\n",
            "S025E01\n",
            "S026E01\n",
            "S027E01\n",
            "S028E01\n",
            "S029E01\n",
            "S030E01\n",
            "S003E03\n",
            "S004E03\n",
            "S005E03\n",
            "S006E03\n",
            "S007E03\n",
            "S008E03\n",
            "S009E03\n",
            "S010E03\n",
            "S011E03\n",
            "S012E03\n",
            "S013E03\n",
            "S014E03\n",
            "S015E03\n",
            "S016E03\n",
            "S017E03\n",
            "S018E03\n",
            "S019E03\n",
            "S020E03\n",
            "S021E03\n",
            "S022E03\n",
            "S023E03\n",
            "S025E03\n",
            "S024E03\n",
            "S026E03\n",
            "S027E03\n",
            "S028E03\n",
            "S029E03\n",
            "S030E03\n",
            "(60, 288, 432, 42)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn3ekaU7TLHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.concatenate((relaxed_data_array, concentration_data_array))\n",
        "relaxed_data_array, concentration_data_array = None, None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4gn3kqDZ0tg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5f7a7e7c-95c5-4e57-e5d3-859ff7b5fc1e"
      },
      "source": [
        "\n",
        "Y = np.concatenate((np.zeros((60,1)),np.ones((60,1))))\n",
        "print(X.shape, Y.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(120, 288, 432, 42) (120, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4uT-8-Zahh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91H3dUT_au_c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9278639e-bddd-4dec-a5a3-32cd42bf53ee"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "X, Y = None, None"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(102, 288, 432, 42) (18, 288, 432, 42) (102, 1) (18, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr_sNqg8a8Op",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9fb93a9f-32de-48c0-8f87-926f4a18a9e6"
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.15, random_state=42)\n",
        "print(X_train.shape, X_test.shape, X_valid.shape, y_train.shape, y_test.shape, y_valid.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(86, 288, 432, 42) (18, 288, 432, 42) (16, 288, 432, 42) (86, 1) (18, 1) (16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za1yTnatbJQN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "550e809b-4042-4014-9e7a-60c621fd5a6a"
      },
      "source": [
        "print(X_train[4][200][0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
            " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
            " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QX7rdZXHZfm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "bf3c0be8-c066-4536-dabf-09b4c4746d2c"
      },
      "source": [
        "datagen = ImageDataGenerator()\n",
        "train_base_path = \"Spectrograms/train\"\n",
        "test_base_path = \"Spectrograms/test\"\n",
        "validation_base_path = \"Spectrograms/validation\"\n",
        "train_generator = datagen.flow_from_directory(\n",
        "        train_base_path,\n",
        "        target_size=(288, 432),\n",
        "        class_mode='binary')\n",
        "test_generator = datagen.flow_from_directory(\n",
        "        test_base_path,\n",
        "        target_size=(288, 432),\n",
        "        class_mode='binary')\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "        validation_base_path,\n",
        "        target_size=(288, 432),\n",
        "        class_mode='binary')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1344 images belonging to 2 classes.\n",
            "Found 168 images belonging to 2 classes.\n",
            "Found 168 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9ZzdNEHHZfx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b5df5766-0a98-4107-e37a-6a26b63c186e"
      },
      "source": [
        "# confirm the iterator works\n",
        "batchX, batchy = train_generator.next()\n",
        "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))\n",
        "batchX, batchy = validation_generator.next()\n",
        "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch shape=(32, 288, 432, 3), min=0.000, max=255.000\n",
            "Batch shape=(32, 288, 432, 3), min=0.000, max=255.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWr9HkIrHZf3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D\n",
        "\n",
        "#create model\n",
        "model = Sequential()\n",
        "#add model layers\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(288, 432, 42)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtFUlkymnoXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmpc46zgHZf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam = optimizers.Adam(lr=0.00000001)\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGN9jKEoHZgH",
        "colab_type": "code",
        "colab": {},
        "outputId": "b7e3d1ff-e709-4e68-a20c-6c8af10fa203"
      },
      "source": [
        "model.fit_generator(train_generator, epochs=10, steps_per_epoch=42, validation_data=validation_generator, validation_steps=6)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "42/42 [==============================] - 195s 5s/step - loss: 7.8170 - acc: 0.5097 - val_loss: 7.9712 - val_acc: 0.5000\n",
            "Epoch 2/10\n",
            "42/42 [==============================] - 250s 6s/step - loss: 8.2796 - acc: 0.4807 - val_loss: 7.9712 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "42/42 [==============================] - 206s 5s/step - loss: 7.8051 - acc: 0.5104 - val_loss: 7.9712 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "42/42 [==============================] - 203s 5s/step - loss: 7.8763 - acc: 0.5060 - val_loss: 7.9712 - val_acc: 0.5000\n",
            "Epoch 5/10\n",
            "42/42 [==============================] - 196s 5s/step - loss: 8.1610 - acc: 0.4881 - val_loss: 7.9712 - val_acc: 0.5000\n",
            "Epoch 6/10\n",
            "42/42 [==============================] - 217s 5s/step - loss: 7.7814 - acc: 0.5119 - val_loss: 7.9712 - val_acc: 0.5000\n",
            "Epoch 7/10\n",
            "42/42 [==============================] - 236s 6s/step - loss: 8.1373 - acc: 0.4896 - val_loss: 7.9712 - val_acc: 0.5000\n",
            "Epoch 8/10\n",
            "42/42 [==============================] - 203s 5s/step - loss: 7.8170 - acc: 0.5097 - val_loss: 7.9712 - val_acc: 0.5000\n",
            "Epoch 9/10\n",
            "42/42 [==============================] - 201s 5s/step - loss: 8.0779 - acc: 0.4933 - val_loss: 7.9712 - val_acc: 0.5000\n",
            "Epoch 10/10\n",
            "42/42 [==============================] - 211s 5s/step - loss: 8.0305 - acc: 0.4963 - val_loss: 7.9712 - val_acc: 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x18589170d48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G0CXx-zcFq-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b50ed0ac-c63f-467f-c00f-50be82fa0306"
      },
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, batch_size=8, shuffle=True)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 86 samples, validate on 16 samples\n",
            "Epoch 1/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 2/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 3/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 4/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 5/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 6/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 7/50\n",
            "86/86 [==============================] - 3s 31ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 8/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 9/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 10/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 11/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 12/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 13/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 14/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 15/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 16/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 17/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 18/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 19/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 20/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 21/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 22/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 23/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 24/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 25/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 26/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 27/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 28/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 29/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 30/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 31/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 32/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 33/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 34/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 35/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 36/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 37/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 38/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 39/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 40/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 41/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 42/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 43/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 44/50\n",
            "86/86 [==============================] - 3s 31ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 45/50\n",
            "86/86 [==============================] - 3s 31ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 46/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 47/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 48/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 49/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 50/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efc2be2ac50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp7fBqTLHZgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate model\n",
        "loss = model.evaluate_generator(test_generator, steps=6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCcWot8aHZga",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dc52cb54-2c1a-4f0b-f3dc-60ba780cb812"
      },
      "source": [
        "from keras import optimizers\n",
        "#create model\n",
        "model2 = Sequential()\n",
        "#add model layers\n",
        "model2.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(288, 432, 42)))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(50, activation='relu'))\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "sgd = optimizers.SGD(lr=0.00000001, momentum=0.5)\n",
        "model2.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model2.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, batch_size=8, shuffle=True)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 86 samples, validate on 16 samples\n",
            "Epoch 1/50\n",
            "86/86 [==============================] - 3s 38ms/step - loss: 7.1770 - acc: 0.5000 - val_loss: 6.2674 - val_acc: 0.3750\n",
            "Epoch 2/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 8.2435 - acc: 0.4302 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 3/50\n",
            "86/86 [==============================] - 3s 29ms/step - loss: 6.5705 - acc: 0.5349 - val_loss: 5.3310 - val_acc: 0.6250\n",
            "Epoch 4/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 5.8166 - acc: 0.5116 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 5/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 6.7826 - acc: 0.5116 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 6/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 5.9418 - acc: 0.5349 - val_loss: 6.0385 - val_acc: 0.5625\n",
            "Epoch 7/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 6.2927 - acc: 0.5581 - val_loss: 5.3176 - val_acc: 0.6250\n",
            "Epoch 8/50\n",
            "86/86 [==============================] - 3s 29ms/step - loss: 7.4608 - acc: 0.4651 - val_loss: 5.9799 - val_acc: 0.6250\n",
            "Epoch 9/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 7.5911 - acc: 0.4302 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 10/50\n",
            "86/86 [==============================] - 3s 29ms/step - loss: 6.5329 - acc: 0.5116 - val_loss: 4.9100 - val_acc: 0.5625\n",
            "Epoch 11/50\n",
            "86/86 [==============================] - 3s 29ms/step - loss: 6.1887 - acc: 0.5465 - val_loss: 6.0014 - val_acc: 0.6250\n",
            "Epoch 12/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 6.9729 - acc: 0.5000 - val_loss: 4.7407 - val_acc: 0.5625\n",
            "Epoch 13/50\n",
            "86/86 [==============================] - 3s 29ms/step - loss: 6.3078 - acc: 0.5116 - val_loss: 6.0269 - val_acc: 0.5625\n",
            "Epoch 14/50\n",
            "86/86 [==============================] - 3s 29ms/step - loss: 5.9369 - acc: 0.5349 - val_loss: 6.1352 - val_acc: 0.5625\n",
            "Epoch 15/50\n",
            "86/86 [==============================] - 3s 29ms/step - loss: 6.3647 - acc: 0.5000 - val_loss: 5.9786 - val_acc: 0.6250\n",
            "Epoch 16/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 6.1750 - acc: 0.5465 - val_loss: 6.5095 - val_acc: 0.5625\n",
            "Epoch 17/50\n",
            "86/86 [==============================] - 3s 29ms/step - loss: 6.9605 - acc: 0.4651 - val_loss: 5.8043 - val_acc: 0.5625\n",
            "Epoch 18/50\n",
            "86/86 [==============================] - 3s 29ms/step - loss: 6.4597 - acc: 0.4419 - val_loss: 5.4499 - val_acc: 0.5625\n",
            "Epoch 19/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 6.0744 - acc: 0.4651 - val_loss: 5.9788 - val_acc: 0.6250\n",
            "Epoch 20/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 6.8637 - acc: 0.5465 - val_loss: 6.0536 - val_acc: 0.5625\n",
            "Epoch 21/50\n",
            "86/86 [==============================] - 3s 29ms/step - loss: 6.0565 - acc: 0.5233 - val_loss: 6.3788 - val_acc: 0.5625\n",
            "Epoch 22/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 5.5454 - acc: 0.5233 - val_loss: 6.3747 - val_acc: 0.5625\n",
            "Epoch 23/50\n",
            "86/86 [==============================] - 3s 29ms/step - loss: 6.2193 - acc: 0.5349 - val_loss: 6.3598 - val_acc: 0.5625\n",
            "Epoch 24/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 6.3727 - acc: 0.5233 - val_loss: 5.6485 - val_acc: 0.5625\n",
            "Epoch 25/50\n",
            "86/86 [==============================] - 3s 29ms/step - loss: 6.2575 - acc: 0.5233 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 26/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 7.0562 - acc: 0.5349 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 27/50\n",
            "86/86 [==============================] - 3s 29ms/step - loss: 6.7065 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 28/50\n",
            "86/86 [==============================] - 3s 29ms/step - loss: 6.3928 - acc: 0.5814 - val_loss: 6.0724 - val_acc: 0.5625\n",
            "Epoch 29/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 6.1329 - acc: 0.5465 - val_loss: 5.3139 - val_acc: 0.6250\n",
            "Epoch 30/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 6.6070 - acc: 0.4767 - val_loss: 6.2068 - val_acc: 0.5625\n",
            "Epoch 31/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 5.5438 - acc: 0.5349 - val_loss: 6.0270 - val_acc: 0.5625\n",
            "Epoch 32/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 6.9265 - acc: 0.4302 - val_loss: 6.2056 - val_acc: 0.5625\n",
            "Epoch 33/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 5.9858 - acc: 0.5814 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 34/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 5.9630 - acc: 0.5465 - val_loss: 5.3488 - val_acc: 0.6250\n",
            "Epoch 35/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 6.7504 - acc: 0.4651 - val_loss: 6.3953 - val_acc: 0.5625\n",
            "Epoch 36/50\n",
            "86/86 [==============================] - 3s 29ms/step - loss: 7.1894 - acc: 0.4651 - val_loss: 6.3447 - val_acc: 0.5625\n",
            "Epoch 37/50\n",
            "86/86 [==============================] - 3s 29ms/step - loss: 7.3453 - acc: 0.4535 - val_loss: 8.7745 - val_acc: 0.3750\n",
            "Epoch 38/50\n",
            "86/86 [==============================] - 3s 29ms/step - loss: 5.4469 - acc: 0.5814 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 39/50\n",
            "86/86 [==============================] - 3s 29ms/step - loss: 5.6714 - acc: 0.5465 - val_loss: 6.2574 - val_acc: 0.5625\n",
            "Epoch 40/50\n",
            "86/86 [==============================] - 3s 29ms/step - loss: 5.5750 - acc: 0.5698 - val_loss: 6.5501 - val_acc: 0.5625\n",
            "Epoch 41/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 5.8094 - acc: 0.5349 - val_loss: 6.6424 - val_acc: 0.5625\n",
            "Epoch 42/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 5.3076 - acc: 0.5349 - val_loss: 6.0665 - val_acc: 0.5625\n",
            "Epoch 43/50\n",
            "86/86 [==============================] - 3s 29ms/step - loss: 7.1809 - acc: 0.4419 - val_loss: 5.2996 - val_acc: 0.6250\n",
            "Epoch 44/50\n",
            "86/86 [==============================] - 3s 29ms/step - loss: 5.0470 - acc: 0.5581 - val_loss: 6.2027 - val_acc: 0.5625\n",
            "Epoch 45/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 5.9827 - acc: 0.5465 - val_loss: 9.0728 - val_acc: 0.4375\n",
            "Epoch 46/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 8.0756 - acc: 0.4884 - val_loss: 9.8669 - val_acc: 0.3750\n",
            "Epoch 47/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 9.8662 - val_acc: 0.3750\n",
            "Epoch 48/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 9.8662 - val_acc: 0.3750\n",
            "Epoch 49/50\n",
            "86/86 [==============================] - 3s 29ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 9.8662 - val_acc: 0.3750\n",
            "Epoch 50/50\n",
            "86/86 [==============================] - 2s 29ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 9.8662 - val_acc: 0.3750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efc2c06e320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_8TplxJpqHk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "45353169-8e81-4020-9854-0fa2be3a15fc"
      },
      "source": [
        "\n",
        "model3 = Sequential()\n",
        "#add model layers\n",
        "model3.add(SeparableConv2D(256, kernel_size=3, activation='relu', input_shape=(288, 432, 42)))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model3.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(50, activation='relu'))\n",
        "model3.add(Dense(1, activation='sigmoid'))\n",
        "sgd = optimizers.SGD(lr=0.00000001, momentum=0.5)\n",
        "model3.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model3.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, batch_size=8, shuffle=True)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 86 samples, validate on 16 samples\n",
            "Epoch 1/50\n",
            "86/86 [==============================] - 6s 72ms/step - loss: 6.8861 - acc: 0.5000 - val_loss: 5.4613 - val_acc: 0.3750\n",
            "Epoch 2/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 2.1409 - acc: 0.5465 - val_loss: 0.7774 - val_acc: 0.6875\n",
            "Epoch 3/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 1.2870 - acc: 0.5116 - val_loss: 0.7876 - val_acc: 0.6875\n",
            "Epoch 4/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 1.3109 - acc: 0.5581 - val_loss: 0.7722 - val_acc: 0.6875\n",
            "Epoch 5/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 1.2268 - acc: 0.5465 - val_loss: 0.7586 - val_acc: 0.6875\n",
            "Epoch 6/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 1.2203 - acc: 0.5465 - val_loss: 0.7533 - val_acc: 0.6875\n",
            "Epoch 7/50\n",
            "86/86 [==============================] - 5s 53ms/step - loss: 1.2423 - acc: 0.5116 - val_loss: 0.7895 - val_acc: 0.7500\n",
            "Epoch 8/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 1.2012 - acc: 0.5581 - val_loss: 0.8375 - val_acc: 0.6875\n",
            "Epoch 9/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 1.1781 - acc: 0.5349 - val_loss: 0.8885 - val_acc: 0.5000\n",
            "Epoch 10/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 1.2222 - acc: 0.5349 - val_loss: 0.7557 - val_acc: 0.7500\n",
            "Epoch 11/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 1.1479 - acc: 0.6047 - val_loss: 0.8515 - val_acc: 0.6875\n",
            "Epoch 12/50\n",
            "86/86 [==============================] - 5s 53ms/step - loss: 1.1651 - acc: 0.5698 - val_loss: 0.7902 - val_acc: 0.7500\n",
            "Epoch 13/50\n",
            "86/86 [==============================] - 5s 53ms/step - loss: 1.1518 - acc: 0.5581 - val_loss: 0.7898 - val_acc: 0.6875\n",
            "Epoch 14/50\n",
            "86/86 [==============================] - 5s 53ms/step - loss: 1.1992 - acc: 0.5581 - val_loss: 0.7663 - val_acc: 0.7500\n",
            "Epoch 15/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 1.1442 - acc: 0.5465 - val_loss: 0.9889 - val_acc: 0.6250\n",
            "Epoch 16/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 1.1052 - acc: 0.5581 - val_loss: 0.7293 - val_acc: 0.6875\n",
            "Epoch 17/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 1.1094 - acc: 0.5233 - val_loss: 0.8681 - val_acc: 0.5625\n",
            "Epoch 18/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 1.1193 - acc: 0.5581 - val_loss: 0.7569 - val_acc: 0.6875\n",
            "Epoch 19/50\n",
            "86/86 [==============================] - 5s 53ms/step - loss: 1.0631 - acc: 0.5698 - val_loss: 0.7315 - val_acc: 0.6250\n",
            "Epoch 20/50\n",
            "86/86 [==============================] - 5s 53ms/step - loss: 1.1172 - acc: 0.5465 - val_loss: 0.7516 - val_acc: 0.6250\n",
            "Epoch 21/50\n",
            "86/86 [==============================] - 5s 53ms/step - loss: 1.0709 - acc: 0.5581 - val_loss: 0.7559 - val_acc: 0.6250\n",
            "Epoch 22/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 1.0781 - acc: 0.5814 - val_loss: 0.8226 - val_acc: 0.6875\n",
            "Epoch 23/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 1.0545 - acc: 0.5698 - val_loss: 0.7464 - val_acc: 0.6250\n",
            "Epoch 24/50\n",
            "86/86 [==============================] - 5s 53ms/step - loss: 1.0278 - acc: 0.5233 - val_loss: 0.8688 - val_acc: 0.6250\n",
            "Epoch 25/50\n",
            "86/86 [==============================] - 5s 53ms/step - loss: 1.0627 - acc: 0.6047 - val_loss: 0.7632 - val_acc: 0.6250\n",
            "Epoch 26/50\n",
            "86/86 [==============================] - 5s 53ms/step - loss: 0.9979 - acc: 0.5349 - val_loss: 0.7014 - val_acc: 0.6250\n",
            "Epoch 27/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 1.0442 - acc: 0.5814 - val_loss: 0.8291 - val_acc: 0.6875\n",
            "Epoch 28/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 1.0667 - acc: 0.5465 - val_loss: 0.7014 - val_acc: 0.6250\n",
            "Epoch 29/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 0.9724 - acc: 0.5698 - val_loss: 0.9226 - val_acc: 0.6250\n",
            "Epoch 30/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 1.0022 - acc: 0.5814 - val_loss: 0.7086 - val_acc: 0.6250\n",
            "Epoch 31/50\n",
            "86/86 [==============================] - 5s 53ms/step - loss: 0.9897 - acc: 0.5233 - val_loss: 0.9211 - val_acc: 0.6250\n",
            "Epoch 32/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 0.9919 - acc: 0.6047 - val_loss: 0.7408 - val_acc: 0.6875\n",
            "Epoch 33/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 0.9731 - acc: 0.5349 - val_loss: 0.8355 - val_acc: 0.6875\n",
            "Epoch 34/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 0.9775 - acc: 0.5698 - val_loss: 0.7326 - val_acc: 0.6875\n",
            "Epoch 35/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 0.9821 - acc: 0.5814 - val_loss: 0.7412 - val_acc: 0.6875\n",
            "Epoch 36/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 0.9798 - acc: 0.5581 - val_loss: 0.7877 - val_acc: 0.6250\n",
            "Epoch 37/50\n",
            "86/86 [==============================] - 5s 53ms/step - loss: 1.0015 - acc: 0.6047 - val_loss: 0.7700 - val_acc: 0.6250\n",
            "Epoch 38/50\n",
            "86/86 [==============================] - 5s 53ms/step - loss: 0.9512 - acc: 0.5233 - val_loss: 0.9479 - val_acc: 0.6250\n",
            "Epoch 39/50\n",
            "86/86 [==============================] - 5s 53ms/step - loss: 0.9688 - acc: 0.5930 - val_loss: 0.7849 - val_acc: 0.6250\n",
            "Epoch 40/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 0.9569 - acc: 0.5581 - val_loss: 0.9334 - val_acc: 0.6250\n",
            "Epoch 41/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 0.9475 - acc: 0.6047 - val_loss: 0.7488 - val_acc: 0.6875\n",
            "Epoch 42/50\n",
            "86/86 [==============================] - 5s 53ms/step - loss: 0.9513 - acc: 0.5465 - val_loss: 0.7682 - val_acc: 0.6250\n",
            "Epoch 43/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 0.9444 - acc: 0.5698 - val_loss: 0.8851 - val_acc: 0.6250\n",
            "Epoch 44/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 0.9272 - acc: 0.5698 - val_loss: 0.7400 - val_acc: 0.6875\n",
            "Epoch 45/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 0.9680 - acc: 0.5814 - val_loss: 0.7722 - val_acc: 0.6250\n",
            "Epoch 46/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 0.9693 - acc: 0.5698 - val_loss: 0.7312 - val_acc: 0.6875\n",
            "Epoch 47/50\n",
            "86/86 [==============================] - 5s 53ms/step - loss: 0.9515 - acc: 0.5930 - val_loss: 0.7325 - val_acc: 0.6875\n",
            "Epoch 48/50\n",
            "86/86 [==============================] - 5s 53ms/step - loss: 0.9636 - acc: 0.5233 - val_loss: 0.8238 - val_acc: 0.6250\n",
            "Epoch 49/50\n",
            "86/86 [==============================] - 5s 54ms/step - loss: 0.9675 - acc: 0.5814 - val_loss: 0.7937 - val_acc: 0.6250\n",
            "Epoch 50/50\n",
            "86/86 [==============================] - 5s 53ms/step - loss: 0.9299 - acc: 0.5814 - val_loss: 0.7568 - val_acc: 0.6250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efc2b500eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e9a7pHdrfRg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6569f229-7025-49e1-c272-20b3cd6aec9a"
      },
      "source": [
        "model4 = Sequential()\n",
        "#add model layers\n",
        "model4.add(SeparableConv2D(256, kernel_size=5, activation='relu', input_shape=(288, 432, 42)))\n",
        "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model4.add(SeparableConv2D(64, kernel_size=3, activation='relu'))\n",
        "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model4.add(Flatten())\n",
        "model4.add(Dense(50, activation='relu'))\n",
        "model4.add(Dense(1, activation='sigmoid'))\n",
        "sgd = optimizers.SGD(lr=0.00000001, momentum=0.5)\n",
        "model4.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model4.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, batch_size=8, shuffle=True)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 86 samples, validate on 16 samples\n",
            "Epoch 1/50\n",
            "86/86 [==============================] - 6s 75ms/step - loss: 1.1216 - acc: 0.5000 - val_loss: 1.0257 - val_acc: 0.6250\n",
            "Epoch 2/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 1.0565 - acc: 0.5000 - val_loss: 0.9893 - val_acc: 0.6250\n",
            "Epoch 3/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.9977 - acc: 0.5000 - val_loss: 0.9556 - val_acc: 0.6250\n",
            "Epoch 4/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.9466 - acc: 0.5000 - val_loss: 0.9273 - val_acc: 0.6250\n",
            "Epoch 5/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.9026 - acc: 0.5000 - val_loss: 0.9054 - val_acc: 0.6250\n",
            "Epoch 6/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.8642 - acc: 0.5000 - val_loss: 0.8890 - val_acc: 0.6250\n",
            "Epoch 7/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.8323 - acc: 0.4884 - val_loss: 0.8760 - val_acc: 0.6250\n",
            "Epoch 8/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.8052 - acc: 0.4767 - val_loss: 0.8659 - val_acc: 0.6250\n",
            "Epoch 9/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.7823 - acc: 0.4884 - val_loss: 0.8590 - val_acc: 0.5000\n",
            "Epoch 10/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.7637 - acc: 0.5000 - val_loss: 0.8545 - val_acc: 0.5000\n",
            "Epoch 11/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.7486 - acc: 0.5116 - val_loss: 0.8516 - val_acc: 0.5000\n",
            "Epoch 12/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.7354 - acc: 0.5349 - val_loss: 0.8501 - val_acc: 0.5000\n",
            "Epoch 13/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.7249 - acc: 0.5349 - val_loss: 0.8497 - val_acc: 0.4375\n",
            "Epoch 14/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.7167 - acc: 0.5465 - val_loss: 0.8503 - val_acc: 0.4375\n",
            "Epoch 15/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.7098 - acc: 0.5349 - val_loss: 0.8512 - val_acc: 0.3750\n",
            "Epoch 16/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.7037 - acc: 0.5465 - val_loss: 0.8527 - val_acc: 0.2500\n",
            "Epoch 17/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.7000 - acc: 0.5698 - val_loss: 0.8547 - val_acc: 0.2500\n",
            "Epoch 18/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6955 - acc: 0.5814 - val_loss: 0.8566 - val_acc: 0.2500\n",
            "Epoch 19/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6924 - acc: 0.5930 - val_loss: 0.8582 - val_acc: 0.2500\n",
            "Epoch 20/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6910 - acc: 0.5930 - val_loss: 0.8598 - val_acc: 0.2500\n",
            "Epoch 21/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6882 - acc: 0.5930 - val_loss: 0.8621 - val_acc: 0.2500\n",
            "Epoch 22/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6868 - acc: 0.5930 - val_loss: 0.8643 - val_acc: 0.2500\n",
            "Epoch 23/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6855 - acc: 0.6163 - val_loss: 0.8653 - val_acc: 0.2500\n",
            "Epoch 24/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6846 - acc: 0.6163 - val_loss: 0.8673 - val_acc: 0.2500\n",
            "Epoch 25/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6836 - acc: 0.5930 - val_loss: 0.8689 - val_acc: 0.3125\n",
            "Epoch 26/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6837 - acc: 0.5698 - val_loss: 0.8700 - val_acc: 0.3125\n",
            "Epoch 27/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6824 - acc: 0.5814 - val_loss: 0.8714 - val_acc: 0.3125\n",
            "Epoch 28/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6820 - acc: 0.5814 - val_loss: 0.8721 - val_acc: 0.3125\n",
            "Epoch 29/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6819 - acc: 0.5814 - val_loss: 0.8735 - val_acc: 0.3125\n",
            "Epoch 30/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6816 - acc: 0.5814 - val_loss: 0.8739 - val_acc: 0.3125\n",
            "Epoch 31/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6813 - acc: 0.5814 - val_loss: 0.8749 - val_acc: 0.3125\n",
            "Epoch 32/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6809 - acc: 0.5814 - val_loss: 0.8757 - val_acc: 0.3125\n",
            "Epoch 33/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6814 - acc: 0.5814 - val_loss: 0.8761 - val_acc: 0.2500\n",
            "Epoch 34/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6816 - acc: 0.5581 - val_loss: 0.8773 - val_acc: 0.2500\n",
            "Epoch 35/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6812 - acc: 0.5814 - val_loss: 0.8773 - val_acc: 0.2500\n",
            "Epoch 36/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6805 - acc: 0.5698 - val_loss: 0.8782 - val_acc: 0.2500\n",
            "Epoch 37/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6808 - acc: 0.5698 - val_loss: 0.8779 - val_acc: 0.2500\n",
            "Epoch 38/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6812 - acc: 0.5581 - val_loss: 0.8792 - val_acc: 0.2500\n",
            "Epoch 39/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6807 - acc: 0.5581 - val_loss: 0.8791 - val_acc: 0.2500\n",
            "Epoch 40/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6801 - acc: 0.5465 - val_loss: 0.8794 - val_acc: 0.2500\n",
            "Epoch 41/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6807 - acc: 0.5581 - val_loss: 0.8800 - val_acc: 0.2500\n",
            "Epoch 42/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6803 - acc: 0.5581 - val_loss: 0.8797 - val_acc: 0.2500\n",
            "Epoch 43/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6799 - acc: 0.5581 - val_loss: 0.8797 - val_acc: 0.2500\n",
            "Epoch 44/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6808 - acc: 0.5465 - val_loss: 0.8797 - val_acc: 0.2500\n",
            "Epoch 45/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6798 - acc: 0.5581 - val_loss: 0.8808 - val_acc: 0.2500\n",
            "Epoch 46/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6803 - acc: 0.5581 - val_loss: 0.8809 - val_acc: 0.2500\n",
            "Epoch 47/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6798 - acc: 0.5581 - val_loss: 0.8812 - val_acc: 0.2500\n",
            "Epoch 48/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6800 - acc: 0.5698 - val_loss: 0.8820 - val_acc: 0.2500\n",
            "Epoch 49/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6797 - acc: 0.5698 - val_loss: 0.8813 - val_acc: 0.2500\n",
            "Epoch 50/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6797 - acc: 0.5698 - val_loss: 0.8811 - val_acc: 0.2500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efc2b3c4908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFgO1PPttYI6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "e0537781-5dc4-427b-c34b-08009ed09db8"
      },
      "source": [
        "model5 = Sequential()\n",
        "#add model layers\n",
        "model5.add(Conv3D(256, kernel_size=3, activation='relu', input_shape=(288, 432, 42)))\n",
        "model5.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "model5.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
        "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model5.add(Flatten())\n",
        "model5.add(Dense(50, activation='relu'))\n",
        "model5.add(Dense(1, activation='sigmoid'))\n",
        "sgd = optimizers.SGD(lr=0.00000001, momentum=0.5)\n",
        "model5.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model5.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, batch_size=8, shuffle=True)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-da68a5fb0c05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#add model layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m288\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m432\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                     \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m                     \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    303\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    306\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer conv3d_1: expected ndim=5, found ndim=4"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXKDUYtiultA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "c9fda66d-279c-4317-a868-9dbe8fd49bf3"
      },
      "source": [
        "from sklearn import svm\n",
        "model5 = svm.SVC()\n",
        "model5.fit(X_train, y_train)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-974fb9b38b50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    146\u001b[0m         X, y = check_X_y(X, y, dtype=np.float64,\n\u001b[1;32m    147\u001b[0m                          \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                          accept_large_sparse=False)\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[0;32m--> 574\u001b[0;31m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with dim 4. Estimator expected <= 2."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43adlB_Hvptw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d2d2b35e-cfad-4460-8905-08b22699c67d"
      },
      "source": [
        "model6 = Sequential()\n",
        "#add model layers\n",
        "model6.add(DepthwiseConv2D(kernel_size=(3,3), activation='relu', input_shape=(288, 432, 42)))\n",
        "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model6.add(DepthwiseConv2D(kernel_size=(3,3), activation='relu'))\n",
        "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model6.add(Flatten())\n",
        "model6.add(Dense(50, activation='relu'))\n",
        "model6.add(Dense(1, activation='sigmoid'))\n",
        "sgd = optimizers.SGD(lr=0.00000001, momentum=0.5)\n",
        "model6.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model6.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=150, batch_size=8, shuffle=True)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 86 samples, validate on 16 samples\n",
            "Epoch 1/150\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 1.7861 - acc: 0.5000 - val_loss: 2.4542 - val_acc: 0.3750\n",
            "Epoch 2/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.7211 - acc: 0.5000 - val_loss: 2.3723 - val_acc: 0.3750\n",
            "Epoch 3/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.6565 - acc: 0.5000 - val_loss: 2.2836 - val_acc: 0.3750\n",
            "Epoch 4/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.5939 - acc: 0.5000 - val_loss: 2.2029 - val_acc: 0.3750\n",
            "Epoch 5/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.5336 - acc: 0.5000 - val_loss: 2.1223 - val_acc: 0.3750\n",
            "Epoch 6/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.4753 - acc: 0.5000 - val_loss: 2.0438 - val_acc: 0.3750\n",
            "Epoch 7/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.4188 - acc: 0.5000 - val_loss: 1.9698 - val_acc: 0.3750\n",
            "Epoch 8/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.3641 - acc: 0.5000 - val_loss: 1.8948 - val_acc: 0.3750\n",
            "Epoch 9/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.3122 - acc: 0.5000 - val_loss: 1.8242 - val_acc: 0.3750\n",
            "Epoch 10/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.2631 - acc: 0.5000 - val_loss: 1.7601 - val_acc: 0.3750\n",
            "Epoch 11/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.2169 - acc: 0.5000 - val_loss: 1.6935 - val_acc: 0.3750\n",
            "Epoch 12/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.1723 - acc: 0.5000 - val_loss: 1.6340 - val_acc: 0.3750\n",
            "Epoch 13/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.1311 - acc: 0.5116 - val_loss: 1.5764 - val_acc: 0.3750\n",
            "Epoch 14/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.0919 - acc: 0.5116 - val_loss: 1.5234 - val_acc: 0.3750\n",
            "Epoch 15/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.0564 - acc: 0.5116 - val_loss: 1.4701 - val_acc: 0.3750\n",
            "Epoch 16/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.0218 - acc: 0.5116 - val_loss: 1.4215 - val_acc: 0.3750\n",
            "Epoch 17/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.9906 - acc: 0.5116 - val_loss: 1.3775 - val_acc: 0.3750\n",
            "Epoch 18/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.9621 - acc: 0.5116 - val_loss: 1.3332 - val_acc: 0.3750\n",
            "Epoch 19/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.9358 - acc: 0.5116 - val_loss: 1.2922 - val_acc: 0.4375\n",
            "Epoch 20/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.9124 - acc: 0.5233 - val_loss: 1.2584 - val_acc: 0.4375\n",
            "Epoch 21/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.8921 - acc: 0.5233 - val_loss: 1.2256 - val_acc: 0.4375\n",
            "Epoch 22/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.8728 - acc: 0.5349 - val_loss: 1.1934 - val_acc: 0.4375\n",
            "Epoch 23/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.8559 - acc: 0.5465 - val_loss: 1.1667 - val_acc: 0.4375\n",
            "Epoch 24/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.8412 - acc: 0.5233 - val_loss: 1.1419 - val_acc: 0.4375\n",
            "Epoch 25/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.8277 - acc: 0.5233 - val_loss: 1.1188 - val_acc: 0.4375\n",
            "Epoch 26/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.8153 - acc: 0.5000 - val_loss: 1.0985 - val_acc: 0.4375\n",
            "Epoch 27/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.8043 - acc: 0.5349 - val_loss: 1.0794 - val_acc: 0.4375\n",
            "Epoch 28/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7943 - acc: 0.5349 - val_loss: 1.0592 - val_acc: 0.3125\n",
            "Epoch 29/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7856 - acc: 0.5465 - val_loss: 1.0435 - val_acc: 0.3125\n",
            "Epoch 30/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7782 - acc: 0.5465 - val_loss: 1.0276 - val_acc: 0.3125\n",
            "Epoch 31/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7713 - acc: 0.5581 - val_loss: 1.0151 - val_acc: 0.3125\n",
            "Epoch 32/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7656 - acc: 0.5465 - val_loss: 1.0026 - val_acc: 0.3125\n",
            "Epoch 33/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7604 - acc: 0.5465 - val_loss: 0.9913 - val_acc: 0.2500\n",
            "Epoch 34/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7559 - acc: 0.5233 - val_loss: 0.9818 - val_acc: 0.2500\n",
            "Epoch 35/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7519 - acc: 0.5000 - val_loss: 0.9728 - val_acc: 0.2500\n",
            "Epoch 36/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7484 - acc: 0.5000 - val_loss: 0.9641 - val_acc: 0.2500\n",
            "Epoch 37/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7451 - acc: 0.5465 - val_loss: 0.9555 - val_acc: 0.3125\n",
            "Epoch 38/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7422 - acc: 0.5698 - val_loss: 0.9477 - val_acc: 0.3125\n",
            "Epoch 39/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7396 - acc: 0.5814 - val_loss: 0.9412 - val_acc: 0.3125\n",
            "Epoch 40/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7377 - acc: 0.5930 - val_loss: 0.9356 - val_acc: 0.3125\n",
            "Epoch 41/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7364 - acc: 0.5814 - val_loss: 0.9302 - val_acc: 0.3125\n",
            "Epoch 42/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7342 - acc: 0.5814 - val_loss: 0.9263 - val_acc: 0.3125\n",
            "Epoch 43/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7329 - acc: 0.5814 - val_loss: 0.9207 - val_acc: 0.3125\n",
            "Epoch 44/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7315 - acc: 0.5814 - val_loss: 0.9175 - val_acc: 0.3125\n",
            "Epoch 45/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7302 - acc: 0.5814 - val_loss: 0.9133 - val_acc: 0.3125\n",
            "Epoch 46/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7294 - acc: 0.5814 - val_loss: 0.9101 - val_acc: 0.3125\n",
            "Epoch 47/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7285 - acc: 0.5814 - val_loss: 0.9068 - val_acc: 0.3125\n",
            "Epoch 48/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7276 - acc: 0.5930 - val_loss: 0.9032 - val_acc: 0.3125\n",
            "Epoch 49/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7265 - acc: 0.5814 - val_loss: 0.9000 - val_acc: 0.3125\n",
            "Epoch 50/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7262 - acc: 0.5814 - val_loss: 0.8973 - val_acc: 0.3125\n",
            "Epoch 51/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7252 - acc: 0.5814 - val_loss: 0.8939 - val_acc: 0.2500\n",
            "Epoch 52/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7250 - acc: 0.5581 - val_loss: 0.8917 - val_acc: 0.2500\n",
            "Epoch 53/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7245 - acc: 0.5698 - val_loss: 0.8899 - val_acc: 0.2500\n",
            "Epoch 54/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7240 - acc: 0.5581 - val_loss: 0.8876 - val_acc: 0.2500\n",
            "Epoch 55/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7238 - acc: 0.5698 - val_loss: 0.8859 - val_acc: 0.2500\n",
            "Epoch 56/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7235 - acc: 0.5698 - val_loss: 0.8845 - val_acc: 0.2500\n",
            "Epoch 57/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7233 - acc: 0.5581 - val_loss: 0.8831 - val_acc: 0.2500\n",
            "Epoch 58/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7227 - acc: 0.5698 - val_loss: 0.8819 - val_acc: 0.2500\n",
            "Epoch 59/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7227 - acc: 0.5465 - val_loss: 0.8805 - val_acc: 0.2500\n",
            "Epoch 60/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7223 - acc: 0.5349 - val_loss: 0.8790 - val_acc: 0.2500\n",
            "Epoch 61/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7219 - acc: 0.5349 - val_loss: 0.8774 - val_acc: 0.2500\n",
            "Epoch 62/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7216 - acc: 0.5349 - val_loss: 0.8767 - val_acc: 0.2500\n",
            "Epoch 63/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7218 - acc: 0.5349 - val_loss: 0.8752 - val_acc: 0.2500\n",
            "Epoch 64/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7217 - acc: 0.5349 - val_loss: 0.8747 - val_acc: 0.2500\n",
            "Epoch 65/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7212 - acc: 0.5349 - val_loss: 0.8742 - val_acc: 0.2500\n",
            "Epoch 66/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7214 - acc: 0.5349 - val_loss: 0.8726 - val_acc: 0.2500\n",
            "Epoch 67/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7209 - acc: 0.5349 - val_loss: 0.8726 - val_acc: 0.2500\n",
            "Epoch 68/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7209 - acc: 0.5349 - val_loss: 0.8722 - val_acc: 0.2500\n",
            "Epoch 69/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7210 - acc: 0.5349 - val_loss: 0.8703 - val_acc: 0.2500\n",
            "Epoch 70/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7214 - acc: 0.5349 - val_loss: 0.8707 - val_acc: 0.2500\n",
            "Epoch 71/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7204 - acc: 0.5349 - val_loss: 0.8699 - val_acc: 0.2500\n",
            "Epoch 72/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7203 - acc: 0.5349 - val_loss: 0.8694 - val_acc: 0.2500\n",
            "Epoch 73/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7209 - acc: 0.5349 - val_loss: 0.8678 - val_acc: 0.2500\n",
            "Epoch 74/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7203 - acc: 0.5349 - val_loss: 0.8685 - val_acc: 0.2500\n",
            "Epoch 75/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7202 - acc: 0.5349 - val_loss: 0.8686 - val_acc: 0.2500\n",
            "Epoch 76/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7203 - acc: 0.5349 - val_loss: 0.8680 - val_acc: 0.2500\n",
            "Epoch 77/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7206 - acc: 0.5349 - val_loss: 0.8683 - val_acc: 0.2500\n",
            "Epoch 78/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7198 - acc: 0.5349 - val_loss: 0.8673 - val_acc: 0.2500\n",
            "Epoch 79/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7199 - acc: 0.5349 - val_loss: 0.8659 - val_acc: 0.2500\n",
            "Epoch 80/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7197 - acc: 0.5349 - val_loss: 0.8663 - val_acc: 0.2500\n",
            "Epoch 81/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7199 - acc: 0.5349 - val_loss: 0.8659 - val_acc: 0.2500\n",
            "Epoch 82/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7194 - acc: 0.5349 - val_loss: 0.8665 - val_acc: 0.2500\n",
            "Epoch 83/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7197 - acc: 0.5349 - val_loss: 0.8653 - val_acc: 0.2500\n",
            "Epoch 84/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7196 - acc: 0.5349 - val_loss: 0.8661 - val_acc: 0.2500\n",
            "Epoch 85/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7192 - acc: 0.5349 - val_loss: 0.8652 - val_acc: 0.2500\n",
            "Epoch 86/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7190 - acc: 0.5349 - val_loss: 0.8648 - val_acc: 0.2500\n",
            "Epoch 87/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7191 - acc: 0.5349 - val_loss: 0.8645 - val_acc: 0.2500\n",
            "Epoch 88/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7190 - acc: 0.5349 - val_loss: 0.8651 - val_acc: 0.2500\n",
            "Epoch 89/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7191 - acc: 0.5349 - val_loss: 0.8645 - val_acc: 0.2500\n",
            "Epoch 90/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7191 - acc: 0.5349 - val_loss: 0.8641 - val_acc: 0.2500\n",
            "Epoch 91/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7187 - acc: 0.5349 - val_loss: 0.8640 - val_acc: 0.2500\n",
            "Epoch 92/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7186 - acc: 0.5349 - val_loss: 0.8645 - val_acc: 0.2500\n",
            "Epoch 93/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7187 - acc: 0.5349 - val_loss: 0.8642 - val_acc: 0.2500\n",
            "Epoch 94/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7184 - acc: 0.5349 - val_loss: 0.8639 - val_acc: 0.2500\n",
            "Epoch 95/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7185 - acc: 0.5349 - val_loss: 0.8640 - val_acc: 0.2500\n",
            "Epoch 96/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7184 - acc: 0.5349 - val_loss: 0.8635 - val_acc: 0.2500\n",
            "Epoch 97/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7181 - acc: 0.5349 - val_loss: 0.8630 - val_acc: 0.2500\n",
            "Epoch 98/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7181 - acc: 0.5349 - val_loss: 0.8631 - val_acc: 0.2500\n",
            "Epoch 99/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7186 - acc: 0.5349 - val_loss: 0.8633 - val_acc: 0.2500\n",
            "Epoch 100/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7180 - acc: 0.5349 - val_loss: 0.8622 - val_acc: 0.2500\n",
            "Epoch 101/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7179 - acc: 0.5349 - val_loss: 0.8623 - val_acc: 0.2500\n",
            "Epoch 102/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7179 - acc: 0.5349 - val_loss: 0.8627 - val_acc: 0.2500\n",
            "Epoch 103/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7179 - acc: 0.5349 - val_loss: 0.8623 - val_acc: 0.2500\n",
            "Epoch 104/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7178 - acc: 0.5349 - val_loss: 0.8627 - val_acc: 0.2500\n",
            "Epoch 105/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7178 - acc: 0.5349 - val_loss: 0.8627 - val_acc: 0.2500\n",
            "Epoch 106/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7177 - acc: 0.5349 - val_loss: 0.8624 - val_acc: 0.2500\n",
            "Epoch 107/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7174 - acc: 0.5349 - val_loss: 0.8628 - val_acc: 0.2500\n",
            "Epoch 108/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7176 - acc: 0.5349 - val_loss: 0.8631 - val_acc: 0.2500\n",
            "Epoch 109/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7178 - acc: 0.5465 - val_loss: 0.8623 - val_acc: 0.2500\n",
            "Epoch 110/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7176 - acc: 0.5349 - val_loss: 0.8628 - val_acc: 0.2500\n",
            "Epoch 111/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7174 - acc: 0.5349 - val_loss: 0.8620 - val_acc: 0.2500\n",
            "Epoch 112/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7171 - acc: 0.5349 - val_loss: 0.8627 - val_acc: 0.2500\n",
            "Epoch 113/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7170 - acc: 0.5349 - val_loss: 0.8629 - val_acc: 0.2500\n",
            "Epoch 114/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7169 - acc: 0.5349 - val_loss: 0.8629 - val_acc: 0.2500\n",
            "Epoch 115/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7169 - acc: 0.5349 - val_loss: 0.8625 - val_acc: 0.2500\n",
            "Epoch 116/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7168 - acc: 0.5349 - val_loss: 0.8627 - val_acc: 0.2500\n",
            "Epoch 117/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7166 - acc: 0.5349 - val_loss: 0.8627 - val_acc: 0.2500\n",
            "Epoch 118/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7172 - acc: 0.5349 - val_loss: 0.8625 - val_acc: 0.2500\n",
            "Epoch 119/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7168 - acc: 0.5349 - val_loss: 0.8628 - val_acc: 0.2500\n",
            "Epoch 120/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7167 - acc: 0.5465 - val_loss: 0.8622 - val_acc: 0.2500\n",
            "Epoch 121/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7164 - acc: 0.5349 - val_loss: 0.8626 - val_acc: 0.2500\n",
            "Epoch 122/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7165 - acc: 0.5349 - val_loss: 0.8627 - val_acc: 0.2500\n",
            "Epoch 123/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7166 - acc: 0.5349 - val_loss: 0.8628 - val_acc: 0.2500\n",
            "Epoch 124/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7163 - acc: 0.5349 - val_loss: 0.8623 - val_acc: 0.2500\n",
            "Epoch 125/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7165 - acc: 0.5349 - val_loss: 0.8628 - val_acc: 0.2500\n",
            "Epoch 126/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7161 - acc: 0.5349 - val_loss: 0.8624 - val_acc: 0.2500\n",
            "Epoch 127/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7161 - acc: 0.5349 - val_loss: 0.8625 - val_acc: 0.2500\n",
            "Epoch 128/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7166 - acc: 0.5465 - val_loss: 0.8615 - val_acc: 0.2500\n",
            "Epoch 129/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7159 - acc: 0.5349 - val_loss: 0.8626 - val_acc: 0.2500\n",
            "Epoch 130/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7158 - acc: 0.5349 - val_loss: 0.8627 - val_acc: 0.2500\n",
            "Epoch 131/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7157 - acc: 0.5465 - val_loss: 0.8626 - val_acc: 0.2500\n",
            "Epoch 132/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7156 - acc: 0.5465 - val_loss: 0.8625 - val_acc: 0.2500\n",
            "Epoch 133/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7158 - acc: 0.5349 - val_loss: 0.8630 - val_acc: 0.2500\n",
            "Epoch 134/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7158 - acc: 0.5465 - val_loss: 0.8625 - val_acc: 0.2500\n",
            "Epoch 135/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7158 - acc: 0.5349 - val_loss: 0.8623 - val_acc: 0.2500\n",
            "Epoch 136/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7155 - acc: 0.5349 - val_loss: 0.8625 - val_acc: 0.2500\n",
            "Epoch 137/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7156 - acc: 0.5465 - val_loss: 0.8624 - val_acc: 0.2500\n",
            "Epoch 138/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7153 - acc: 0.5465 - val_loss: 0.8625 - val_acc: 0.2500\n",
            "Epoch 139/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7154 - acc: 0.5349 - val_loss: 0.8630 - val_acc: 0.2500\n",
            "Epoch 140/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7153 - acc: 0.5465 - val_loss: 0.8626 - val_acc: 0.2500\n",
            "Epoch 141/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7153 - acc: 0.5349 - val_loss: 0.8631 - val_acc: 0.2500\n",
            "Epoch 142/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7155 - acc: 0.5465 - val_loss: 0.8620 - val_acc: 0.2500\n",
            "Epoch 143/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7150 - acc: 0.5465 - val_loss: 0.8629 - val_acc: 0.2500\n",
            "Epoch 144/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7149 - acc: 0.5349 - val_loss: 0.8624 - val_acc: 0.2500\n",
            "Epoch 145/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7152 - acc: 0.5349 - val_loss: 0.8626 - val_acc: 0.2500\n",
            "Epoch 146/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7152 - acc: 0.5349 - val_loss: 0.8625 - val_acc: 0.2500\n",
            "Epoch 147/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7156 - acc: 0.5465 - val_loss: 0.8617 - val_acc: 0.2500\n",
            "Epoch 148/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7146 - acc: 0.5465 - val_loss: 0.8624 - val_acc: 0.2500\n",
            "Epoch 149/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7147 - acc: 0.5465 - val_loss: 0.8623 - val_acc: 0.2500\n",
            "Epoch 150/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7144 - acc: 0.5465 - val_loss: 0.8612 - val_acc: 0.2500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efc2a061f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O1pRTMMnp0X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "48782d7f-ec4d-44ba-e0f5-4bcdc24e2092"
      },
      "source": [
        "metrics = model2.evaluate(X_test,y_test)\n",
        "print(metrics)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r18/18 [==============================] - 1s 33ms/step\n",
            "[6.268148422241211, 0.6111111044883728]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u2YrNTKpVZf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "63dc4cf8-5994-4139-9e2a-205c40c282bb"
      },
      "source": [
        "metrics = model.evaluate(X_test,y_test)\n",
        "print(metrics)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r18/18 [==============================] - 0s 22ms/step\n",
            "[9.742568969726562, 0.3888888955116272]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9qIig8FphSH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fbd07ff6-2596-4d0d-bcd0-7b5cbf58693a"
      },
      "source": [
        "metrics = model3.evaluate(X_test,y_test)\n",
        "print(metrics)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r18/18 [==============================] - 1s 35ms/step\n",
            "[0.9793123602867126, 0.6666666865348816]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVvQQuKqtDJq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "dfa32511-3a7a-47a5-bf73-0ef435d72711"
      },
      "source": [
        "metrics = model4.evaluate(X_test,y_test)\n",
        "print(metrics)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r18/18 [==============================] - 1s 31ms/step\n",
            "[0.6619123220443726, 0.6111111044883728]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-yXRREwxkrg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "dc835c30-1574-4a3b-b8dd-7f5b690cf597"
      },
      "source": [
        "metrics = model6.evaluate(X_test,y_test)\n",
        "print(metrics)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r18/18 [==============================] - 0s 21ms/step\n",
            "[0.8770436644554138, 0.3888888955116272]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAkKFhsd1Jo0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5c1bab2f-3316-4fa3-8cde-2806a08db507"
      },
      "source": [
        "# higher epochs version\n",
        "metrics = model6.evaluate(X_test,y_test)\n",
        "print(metrics)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r18/18 [==============================] - 0s 22ms/step\n",
            "[0.8298603892326355, 0.3888888955116272]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}