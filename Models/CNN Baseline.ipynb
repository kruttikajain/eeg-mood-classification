{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "CNN Baseline.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtZyMdquHZe6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "1411c6b3-12fc-4b82-f67d-fb27079f28d3"
      },
      "source": [
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, SeparableConv2D, MaxPooling3D, Conv3D, DepthwiseConv2D"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDot5tyiIVZo",
        "colab_type": "code",
        "outputId": "10b67910-70ac-4b88-bcd3-11b324da5669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Colab settings/mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/My\\ Drive/CSE\\ 240/Project/Data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/CSE 240/Project/Data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9wUwPkmIqE_",
        "colab_type": "code",
        "outputId": "f4da1426-c3a1-42e6-e8eb-c2ac31c76fa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd spectrogram_images/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/CSE 240/Project/Data/spectrogram_images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS-F1iC3HZfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = load_img('concentration/S001E02_0/S001E02_0_AF3.png', target_size=(29,43))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-g_4KvFHZfL",
        "colab_type": "code",
        "outputId": "83feb5ab-c6b9-44a0-9d1b-6ba68f41f034",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "print(type(img))\n",
        "print(img.format)\n",
        "print(img.mode)\n",
        "print(img.size)\n",
        "print(img)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'PIL.Image.Image'>\n",
            "None\n",
            "RGB\n",
            "(43, 29)\n",
            "<PIL.Image.Image image mode=RGB size=43x29 at 0x7F4351BAF978>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5smDQZ8ZHZfR",
        "colab_type": "code",
        "outputId": "32eea6d3-905e-4cc2-c0d1-b370a68011d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "print(type(img))\n",
        "# convert to numpy array\n",
        "img_array = img_to_array(img)\n",
        "print(img_array.dtype)\n",
        "print(img_array.shape)\n",
        "print(img_array[0][0])\n",
        "# convert back to image\n",
        "img_pil = array_to_img(img_array)\n",
        "print(type(img))\n",
        "#for i in range(288):\n",
        "  #for j in range(432):\n",
        "    #print(img_array[i][j])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'PIL.Image.Image'>\n",
            "float32\n",
            "(288, 432, 3)\n",
            "[255. 255. 255.]\n",
            "<class 'PIL.Image.Image'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnYVP4KHHZfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UKrQyG4RzTj",
        "colab_type": "code",
        "outputId": "a378229a-d4d8-4379-e014-532e83438bc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "base_path = \"concentration\"\n",
        "concentration_data_array = []\n",
        "for foldername in os.listdir(base_path):\n",
        "  print(foldername)\n",
        "  array = np.zeros((144,216,1))\n",
        "  for filename in os.listdir(os.path.join(base_path, foldername)):\n",
        "    example = foldername\n",
        "    channel = filename.split('.')[0].split(\"_\")[1]\n",
        "    filepath = os.path.join(os.path.join(base_path, foldername), filename)\n",
        "    #print(filename,filepath)\n",
        "    img = load_img(filepath, target_size=(144,216))\n",
        "    img_array = img_to_array(img)\n",
        "    #print(img_array.shape, array.shape)\n",
        "    array = np.concatenate((array, img_array), axis=2)\n",
        "    #print(img_array.shape, array.shape)\n",
        "  concentration_data_array.append(np.delete(array,0,2))\n",
        "#print(data_array['S025E02'].shape)\n",
        "concentration_data_array = np.array(concentration_data_array)\n",
        "print(concentration_data_array.shape)\n",
        "np.save(\"concentration_array_50.npy\", concentration_data_array)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "S015E02_8\n",
            "S015E02_9\n",
            "S015E02_10\n",
            "S015E02_11\n",
            "S015E02_12\n",
            "S015E02_13\n",
            "S015E02_14\n",
            "S015E02_15\n",
            "S015E02_16\n",
            "S015E02_17\n",
            "S015E02_18\n",
            "S015E02_19\n",
            "S015E02_20\n",
            "S015E02_21\n",
            "S015E02_22\n",
            "S015E02_23\n",
            "S015E02_24\n",
            "S015E02_25\n",
            "S015E02_26\n",
            "S015E02_27\n",
            "S015E02_28\n",
            "S015E02_29\n",
            "S015E02_30\n",
            "S015E02_31\n",
            "S015E02_32\n",
            "S015E02_33\n",
            "S015E02_34\n",
            "S015E02_35\n",
            "S015E04_0\n",
            "S015E04_1\n",
            "S015E04_2\n",
            "S015E04_3\n",
            "S015E04_4\n",
            "S015E04_5\n",
            "S015E04_6\n",
            "S015E04_7\n",
            "S015E04_8\n",
            "S015E04_9\n",
            "S015E04_10\n",
            "S015E04_11\n",
            "S015E04_12\n",
            "S015E04_13\n",
            "S015E04_14\n",
            "S015E04_15\n",
            "S015E04_16\n",
            "S015E04_17\n",
            "S015E04_18\n",
            "S015E04_19\n",
            "S015E04_20\n",
            "S015E04_21\n",
            "S015E04_22\n",
            "S015E04_23\n",
            "S015E04_24\n",
            "S015E04_25\n",
            "S015E04_26\n",
            "S015E04_27\n",
            "S015E04_28\n",
            "S015E04_29\n",
            "S015E04_30\n",
            "S015E04_31\n",
            "S015E04_32\n",
            "S015E04_33\n",
            "S015E04_34\n",
            "S015E04_35\n",
            "S017E02_0\n",
            "S017E02_1\n",
            "S017E02_2\n",
            "S017E02_3\n",
            "S017E02_4\n",
            "S017E02_5\n",
            "S017E02_6\n",
            "S017E02_7\n",
            "S017E02_8\n",
            "S017E02_9\n",
            "S017E02_10\n",
            "S017E02_11\n",
            "S017E02_12\n",
            "S017E02_13\n",
            "S017E02_14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dvs3eypBE6PF",
        "colab_type": "text"
      },
      "source": [
        "Save to file\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUWNqNQREwtQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"concentration_array.npy\", concentration_data_array)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Pi_9c2bFlxq",
        "colab_type": "code",
        "outputId": "e206305c-eff5-4603-e827-dc88b9966f95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "concentration_data_array = None\n",
        "loaded_array = np.load(\"concentration_array.npy\")\n",
        "print(loaded_array.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2088, 29, 43, 42)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-85fd7f47c2fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloaded_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"concentration_array.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcentration_data_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UycYYSlSR6tX",
        "colab_type": "code",
        "outputId": "4c12e64c-d2f2-4f6c-87ad-9b01b36cb240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "base_path = \"relaxed\"\n",
        "relaxed_data_array = []\n",
        "for foldername in os.listdir(base_path):\n",
        "  print(foldername)\n",
        "  array = np.zeros((29,43,1))\n",
        "  for filename in os.listdir(os.path.join(base_path, foldername)):\n",
        "    example = foldername\n",
        "    channel = filename.split('.')[0].split(\"_\")[1]\n",
        "    filepath = os.path.join(os.path.join(base_path, foldername), filename)\n",
        "    #print(filename,filepath)\n",
        "    img = load_img(filepath, target_size=(29,43))\n",
        "    img_array = img_to_array(img)\n",
        "    #print(img_array.shape, array.shape)\n",
        "    array = np.concatenate((array, img_array), axis=2)\n",
        "    #print(img_array.shape, array.shape)\n",
        "  relaxed_data_array.append(np.delete(array,0,2))\n",
        "#print(data_array['S025E02'].shape)\n",
        "relaxed_data_array = np.array(relaxed_data_array)\n",
        "print(relaxed_data_array.shape)\n",
        "np.save(\"relaxed_array.npy\", relaxed_data_array)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "S015E01_8\n",
            "S015E01_9\n",
            "S015E01_10\n",
            "S015E01_11\n",
            "S015E01_12\n",
            "S015E01_13\n",
            "S015E01_14\n",
            "S015E01_15\n",
            "S015E01_16\n",
            "S015E01_17\n",
            "S015E01_18\n",
            "S015E01_19\n",
            "S015E01_20\n",
            "S015E01_21\n",
            "S015E01_22\n",
            "S015E01_23\n",
            "S015E01_24\n",
            "S015E01_25\n",
            "S015E01_26\n",
            "S015E01_27\n",
            "S015E01_28\n",
            "S015E01_29\n",
            "S015E01_30\n",
            "S015E01_31\n",
            "S015E01_32\n",
            "S015E01_33\n",
            "S015E01_34\n",
            "S015E01_35\n",
            "S015E03_0\n",
            "S015E03_1\n",
            "S015E03_2\n",
            "S015E03_3\n",
            "S015E03_4\n",
            "S015E03_5\n",
            "S015E03_6\n",
            "S015E03_7\n",
            "S015E03_8\n",
            "S015E03_9\n",
            "S015E03_10\n",
            "S015E03_11\n",
            "S015E03_12\n",
            "S015E03_13\n",
            "S015E03_14\n",
            "S015E03_15\n",
            "S015E03_16\n",
            "S015E03_17\n",
            "S015E03_18\n",
            "S015E03_19\n",
            "S015E03_20\n",
            "S015E03_21\n",
            "S015E03_22\n",
            "S015E03_23\n",
            "S015E03_24\n",
            "S015E03_25\n",
            "S015E03_26\n",
            "S015E03_27\n",
            "S015E03_28\n",
            "S015E03_29\n",
            "S015E03_30\n",
            "S015E03_31\n",
            "S015E03_32\n",
            "S015E03_33\n",
            "S015E03_34\n",
            "S015E03_35\n",
            "S017E01_0\n",
            "S017E01_1\n",
            "S017E01_2\n",
            "S017E01_3\n",
            "S017E01_4\n",
            "S017E01_5\n",
            "S017E01_6\n",
            "S017E01_7\n",
            "S017E01_8\n",
            "S017E01_9\n",
            "S017E01_10\n",
            "S017E01_11\n",
            "S017E01_12\n",
            "S017E01_13\n",
            "S017E01_14\n",
            "S017E01_15\n",
            "S017E01_16\n",
            "S017E01_17\n",
            "S017E01_18\n",
            "S017E01_19\n",
            "S017E01_20\n",
            "S017E01_21\n",
            "S017E01_22\n",
            "S017E01_23\n",
            "S017E01_24\n",
            "S017E01_25\n",
            "S017E01_26\n",
            "S017E01_27\n",
            "S017E01_28\n",
            "S017E01_29\n",
            "S017E01_30\n",
            "S017E01_31\n",
            "S017E01_32\n",
            "S017E01_33\n",
            "S017E01_34\n",
            "S017E01_35\n",
            "S017E03_0\n",
            "S017E03_1\n",
            "S017E03_2\n",
            "S017E03_3\n",
            "S017E03_4\n",
            "S017E03_5\n",
            "S017E03_6\n",
            "S017E03_7\n",
            "S017E03_8\n",
            "S017E03_9\n",
            "S017E03_10\n",
            "S017E03_11\n",
            "S017E03_12\n",
            "S017E03_13\n",
            "S017E03_14\n",
            "S017E03_15\n",
            "S017E03_16\n",
            "S017E03_17\n",
            "S017E03_18\n",
            "S017E03_19\n",
            "S017E03_20\n",
            "S017E03_21\n",
            "S017E03_22\n",
            "S017E03_23\n",
            "S017E03_24\n",
            "S017E03_25\n",
            "S017E03_26\n",
            "S017E03_27\n",
            "S017E03_28\n",
            "S017E03_29\n",
            "S017E03_30\n",
            "S017E03_31\n",
            "S017E03_32\n",
            "S017E03_33\n",
            "S017E03_34\n",
            "S017E03_35\n",
            "S014E01_0\n",
            "S014E01_1\n",
            "S014E01_2\n",
            "S014E01_3\n",
            "S014E01_4\n",
            "S014E01_5\n",
            "S014E01_6\n",
            "S014E01_7\n",
            "S014E01_8\n",
            "S014E01_9\n",
            "S014E01_10\n",
            "S014E01_11\n",
            "S014E01_12\n",
            "S014E01_13\n",
            "S014E01_14\n",
            "S014E01_15\n",
            "S014E01_16\n",
            "S014E01_17\n",
            "S014E01_18\n",
            "S014E01_19\n",
            "S014E01_20\n",
            "S014E01_21\n",
            "S014E01_22\n",
            "S014E01_23\n",
            "S014E01_24\n",
            "S014E01_25\n",
            "S014E01_26\n",
            "S014E01_27\n",
            "S014E01_28\n",
            "S014E01_29\n",
            "S014E01_30\n",
            "S014E01_31\n",
            "S014E01_32\n",
            "S014E01_33\n",
            "S014E01_34\n",
            "S014E01_35\n",
            "S014E03_0\n",
            "S014E03_1\n",
            "S014E03_2\n",
            "S014E03_3\n",
            "S014E03_4\n",
            "S014E03_5\n",
            "S014E03_6\n",
            "S014E03_7\n",
            "S014E03_8\n",
            "S014E03_9\n",
            "S014E03_10\n",
            "S014E03_11\n",
            "S014E03_12\n",
            "S014E03_13\n",
            "S014E03_14\n",
            "S014E03_15\n",
            "S014E03_16\n",
            "S014E03_17\n",
            "S014E03_18\n",
            "S014E03_19\n",
            "S014E03_20\n",
            "S014E03_21\n",
            "S014E03_22\n",
            "S014E03_23\n",
            "S014E03_24\n",
            "S014E03_25\n",
            "S014E03_26\n",
            "S014E03_27\n",
            "S014E03_28\n",
            "S014E03_29\n",
            "S014E03_30\n",
            "S014E03_31\n",
            "S014E03_32\n",
            "S014E03_33\n",
            "S014E03_34\n",
            "S014E03_35\n",
            "S016E01_0\n",
            "S016E01_1\n",
            "S016E01_2\n",
            "S016E01_3\n",
            "S016E01_4\n",
            "S016E01_5\n",
            "S016E01_6\n",
            "S016E01_7\n",
            "S016E01_8\n",
            "S016E01_9\n",
            "S016E01_10\n",
            "S016E01_11\n",
            "S016E01_12\n",
            "S016E01_13\n",
            "S016E01_14\n",
            "S016E01_15\n",
            "S016E01_16\n",
            "S016E01_17\n",
            "S016E01_18\n",
            "S016E01_19\n",
            "S016E01_20\n",
            "S016E01_21\n",
            "S016E01_22\n",
            "S016E01_23\n",
            "S016E01_24\n",
            "S016E01_25\n",
            "S016E01_26\n",
            "S016E01_27\n",
            "S016E01_28\n",
            "S016E01_29\n",
            "S016E01_30\n",
            "S016E01_31\n",
            "S016E01_32\n",
            "S016E01_33\n",
            "S016E01_34\n",
            "S016E01_35\n",
            "S016E03_0\n",
            "S016E03_1\n",
            "S016E03_2\n",
            "S016E03_3\n",
            "S016E03_4\n",
            "S016E03_5\n",
            "S016E03_6\n",
            "S016E03_7\n",
            "S016E03_8\n",
            "S016E03_9\n",
            "S016E03_10\n",
            "S016E03_11\n",
            "S016E03_12\n",
            "S016E03_13\n",
            "S016E03_14\n",
            "S016E03_15\n",
            "S016E03_16\n",
            "S016E03_17\n",
            "S016E03_18\n",
            "S016E03_19\n",
            "S016E03_20\n",
            "S016E03_21\n",
            "S016E03_22\n",
            "S016E03_23\n",
            "S016E03_24\n",
            "S016E03_25\n",
            "S016E03_26\n",
            "S016E03_27\n",
            "S016E03_28\n",
            "S016E03_29\n",
            "S016E03_30\n",
            "S016E03_31\n",
            "S016E03_32\n",
            "S016E03_33\n",
            "S016E03_34\n",
            "S016E03_35\n",
            "S018E01_0\n",
            "S018E01_1\n",
            "S018E01_2\n",
            "S018E01_3\n",
            "S018E01_4\n",
            "S018E01_5\n",
            "S018E01_6\n",
            "S018E01_7\n",
            "S018E01_8\n",
            "S018E01_9\n",
            "S018E01_10\n",
            "S018E01_11\n",
            "S018E01_12\n",
            "S018E01_13\n",
            "S018E01_14\n",
            "S018E01_15\n",
            "S018E01_16\n",
            "S018E01_17\n",
            "S018E01_18\n",
            "S018E01_19\n",
            "S018E01_20\n",
            "S018E01_21\n",
            "S018E01_22\n",
            "S018E01_23\n",
            "S018E01_24\n",
            "S018E01_25\n",
            "S018E01_26\n",
            "S018E01_27\n",
            "S018E01_28\n",
            "S018E01_29\n",
            "S018E01_30\n",
            "S018E01_31\n",
            "S018E01_32\n",
            "S018E01_33\n",
            "S018E01_34\n",
            "S018E01_35\n",
            "S018E03_0\n",
            "S018E03_1\n",
            "S018E03_2\n",
            "S018E03_3\n",
            "S018E03_4\n",
            "S018E03_5\n",
            "S018E03_6\n",
            "S018E03_7\n",
            "S018E03_8\n",
            "S018E03_9\n",
            "S018E03_10\n",
            "S018E03_11\n",
            "S018E03_12\n",
            "S018E03_13\n",
            "S018E03_14\n",
            "S018E03_15\n",
            "S018E03_16\n",
            "S018E03_17\n",
            "S018E03_18\n",
            "S018E03_19\n",
            "S018E03_20\n",
            "S018E03_21\n",
            "S018E03_22\n",
            "S018E03_23\n",
            "S018E03_24\n",
            "S018E03_25\n",
            "S018E03_26\n",
            "S018E03_27\n",
            "S018E03_28\n",
            "S018E03_29\n",
            "S018E03_30\n",
            "S018E03_31\n",
            "S018E03_32\n",
            "S018E03_33\n",
            "S018E03_34\n",
            "S018E03_35\n",
            "S020E01_0\n",
            "S020E01_1\n",
            "S020E01_2\n",
            "S020E01_3\n",
            "S020E01_4\n",
            "S020E01_5\n",
            "S020E01_6\n",
            "S020E01_7\n",
            "S020E01_8\n",
            "S020E01_9\n",
            "S020E01_10\n",
            "S020E01_11\n",
            "S020E01_12\n",
            "S020E01_13\n",
            "S020E01_14\n",
            "S020E01_15\n",
            "S020E01_16\n",
            "S020E01_17\n",
            "S020E01_18\n",
            "S020E01_19\n",
            "S020E01_20\n",
            "S020E01_21\n",
            "S020E01_22\n",
            "S020E01_23\n",
            "S020E01_24\n",
            "S020E01_25\n",
            "S020E01_26\n",
            "S020E01_27\n",
            "S020E01_28\n",
            "S020E01_29\n",
            "S020E01_30\n",
            "S020E01_31\n",
            "S020E01_32\n",
            "S020E01_33\n",
            "S020E01_34\n",
            "S020E01_35\n",
            "S020E03_0\n",
            "S020E03_1\n",
            "S020E03_2\n",
            "S020E03_3\n",
            "S020E03_4\n",
            "S020E03_5\n",
            "S020E03_6\n",
            "S020E03_7\n",
            "S020E03_8\n",
            "S020E03_9\n",
            "S020E03_10\n",
            "S020E03_11\n",
            "S020E03_12\n",
            "S020E03_13\n",
            "S020E03_14\n",
            "S020E03_15\n",
            "S020E03_16\n",
            "S020E03_17\n",
            "S020E03_18\n",
            "S020E03_19\n",
            "S020E03_20\n",
            "S020E03_21\n",
            "S020E03_22\n",
            "S020E03_23\n",
            "S020E03_24\n",
            "S020E03_25\n",
            "S020E03_26\n",
            "S020E03_27\n",
            "S020E03_28\n",
            "S020E03_29\n",
            "S020E03_30\n",
            "S020E03_31\n",
            "S020E03_32\n",
            "S020E03_33\n",
            "S020E03_34\n",
            "S020E03_35\n",
            "S022E01_0\n",
            "S022E01_1\n",
            "S022E01_2\n",
            "S022E01_3\n",
            "S022E01_4\n",
            "S022E01_5\n",
            "S022E01_6\n",
            "S022E01_7\n",
            "S022E01_8\n",
            "S022E01_9\n",
            "S022E01_10\n",
            "S022E01_11\n",
            "S022E01_12\n",
            "S022E01_13\n",
            "S022E01_14\n",
            "S022E01_15\n",
            "S022E01_16\n",
            "S022E01_17\n",
            "S022E01_18\n",
            "S022E01_19\n",
            "S022E01_20\n",
            "S022E01_21\n",
            "S022E01_22\n",
            "S022E01_23\n",
            "S022E01_24\n",
            "S022E01_25\n",
            "S022E01_26\n",
            "S022E01_27\n",
            "S022E01_28\n",
            "S022E01_29\n",
            "S022E01_30\n",
            "S022E01_31\n",
            "S022E01_32\n",
            "S022E01_33\n",
            "S022E01_34\n",
            "S022E01_35\n",
            "S022E03_0\n",
            "S022E03_1\n",
            "S022E03_2\n",
            "S022E03_3\n",
            "S022E03_4\n",
            "S022E03_5\n",
            "S022E03_6\n",
            "S022E03_7\n",
            "S022E03_8\n",
            "S022E03_9\n",
            "S022E03_10\n",
            "S022E03_11\n",
            "S022E03_12\n",
            "S022E03_13\n",
            "S022E03_14\n",
            "S022E03_15\n",
            "S022E03_16\n",
            "S022E03_17\n",
            "S022E03_18\n",
            "S022E03_19\n",
            "S022E03_20\n",
            "S022E03_21\n",
            "S022E03_22\n",
            "S022E03_23\n",
            "S022E03_24\n",
            "S022E03_25\n",
            "S022E03_26\n",
            "S022E03_27\n",
            "S022E03_28\n",
            "S022E03_29\n",
            "S022E03_30\n",
            "S022E03_31\n",
            "S022E03_32\n",
            "S022E03_33\n",
            "S022E03_34\n",
            "S022E03_35\n",
            "S024E01_0\n",
            "S024E01_1\n",
            "S024E01_2\n",
            "S024E01_3\n",
            "S024E01_4\n",
            "S024E01_5\n",
            "S024E01_6\n",
            "S024E01_7\n",
            "S024E01_8\n",
            "S024E01_9\n",
            "S024E01_10\n",
            "S024E01_11\n",
            "S024E01_12\n",
            "S024E01_13\n",
            "S024E01_14\n",
            "S024E01_15\n",
            "S024E01_16\n",
            "S024E01_17\n",
            "S024E01_18\n",
            "S024E01_19\n",
            "S024E01_20\n",
            "S024E01_21\n",
            "S024E01_22\n",
            "S024E01_23\n",
            "S024E01_24\n",
            "S024E01_25\n",
            "S024E01_26\n",
            "S024E01_27\n",
            "S024E01_28\n",
            "S024E01_29\n",
            "S024E01_30\n",
            "S024E01_31\n",
            "S024E01_32\n",
            "S024E01_33\n",
            "S024E01_34\n",
            "S024E01_35\n",
            "S024E03_0\n",
            "S024E03_1\n",
            "S024E03_2\n",
            "S024E03_3\n",
            "S024E03_4\n",
            "S024E03_5\n",
            "S024E03_6\n",
            "S024E03_7\n",
            "S024E03_8\n",
            "S024E03_9\n",
            "S024E03_10\n",
            "S024E03_11\n",
            "S024E03_12\n",
            "S024E03_13\n",
            "S024E03_14\n",
            "S024E03_15\n",
            "S024E03_16\n",
            "S024E03_17\n",
            "S024E03_18\n",
            "S024E03_19\n",
            "S024E03_20\n",
            "S024E03_21\n",
            "S024E03_22\n",
            "S024E03_23\n",
            "S024E03_24\n",
            "S024E03_25\n",
            "S024E03_26\n",
            "S024E03_27\n",
            "S024E03_28\n",
            "S024E03_29\n",
            "S024E03_30\n",
            "S024E03_31\n",
            "S024E03_32\n",
            "S024E03_33\n",
            "S024E03_34\n",
            "S024E03_35\n",
            "S026E01_0\n",
            "S026E01_1\n",
            "S026E01_2\n",
            "S026E01_3\n",
            "S026E01_4\n",
            "S026E01_5\n",
            "S026E01_6\n",
            "S026E01_7\n",
            "S026E01_8\n",
            "S026E01_9\n",
            "S026E01_10\n",
            "S026E01_11\n",
            "S026E01_12\n",
            "S026E01_13\n",
            "S026E01_14\n",
            "S026E01_15\n",
            "S026E01_16\n",
            "S026E01_17\n",
            "S026E01_18\n",
            "S026E01_19\n",
            "S026E01_20\n",
            "S026E01_21\n",
            "S026E01_22\n",
            "S026E01_23\n",
            "S026E01_24\n",
            "S026E01_25\n",
            "S026E01_26\n",
            "S026E01_27\n",
            "S026E01_28\n",
            "S026E01_29\n",
            "S026E01_30\n",
            "S026E01_31\n",
            "S026E01_32\n",
            "S026E01_33\n",
            "S026E01_34\n",
            "S026E01_35\n",
            "S026E03_0\n",
            "S026E03_1\n",
            "S026E03_2\n",
            "S026E03_3\n",
            "S026E03_4\n",
            "S026E03_5\n",
            "S026E03_6\n",
            "S026E03_7\n",
            "S026E03_8\n",
            "S026E03_9\n",
            "S026E03_10\n",
            "S026E03_11\n",
            "S026E03_12\n",
            "S026E03_13\n",
            "S026E03_14\n",
            "S026E03_15\n",
            "S026E03_16\n",
            "S026E03_17\n",
            "S026E03_18\n",
            "S026E03_19\n",
            "S026E03_20\n",
            "S026E03_21\n",
            "S026E03_22\n",
            "S026E03_23\n",
            "S026E03_24\n",
            "S026E03_25\n",
            "S026E03_26\n",
            "S026E03_27\n",
            "S026E03_28\n",
            "S026E03_29\n",
            "S026E03_30\n",
            "S026E03_31\n",
            "S026E03_32\n",
            "S026E03_33\n",
            "S026E03_34\n",
            "S026E03_35\n",
            "S019E01_0\n",
            "S019E01_1\n",
            "S019E01_2\n",
            "S019E01_3\n",
            "S019E01_4\n",
            "S019E01_5\n",
            "S019E01_6\n",
            "S019E01_7\n",
            "S019E01_8\n",
            "S019E01_9\n",
            "S019E01_10\n",
            "S019E01_11\n",
            "S019E01_12\n",
            "S019E01_13\n",
            "S019E01_14\n",
            "S019E01_15\n",
            "S019E01_16\n",
            "S019E01_17\n",
            "S019E01_18\n",
            "S019E01_19\n",
            "S019E01_20\n",
            "S019E01_21\n",
            "S019E01_22\n",
            "S019E01_23\n",
            "S019E01_24\n",
            "S019E01_25\n",
            "S019E01_26\n",
            "S019E01_27\n",
            "S019E01_28\n",
            "S019E01_29\n",
            "S019E01_30\n",
            "S019E01_31\n",
            "S019E01_32\n",
            "S019E01_33\n",
            "S019E01_34\n",
            "S019E01_35\n",
            "S019E03_0\n",
            "S019E03_1\n",
            "S019E03_2\n",
            "S019E03_3\n",
            "S019E03_4\n",
            "S019E03_5\n",
            "S019E03_6\n",
            "S019E03_7\n",
            "S019E03_8\n",
            "S019E03_9\n",
            "S019E03_10\n",
            "S019E03_11\n",
            "S019E03_12\n",
            "S019E03_13\n",
            "S019E03_14\n",
            "S019E03_15\n",
            "S019E03_16\n",
            "S019E03_17\n",
            "S019E03_18\n",
            "S019E03_19\n",
            "S019E03_20\n",
            "S019E03_21\n",
            "S019E03_22\n",
            "S019E03_23\n",
            "S019E03_24\n",
            "S019E03_25\n",
            "S019E03_26\n",
            "S019E03_27\n",
            "S019E03_28\n",
            "S019E03_29\n",
            "S019E03_30\n",
            "S019E03_31\n",
            "S019E03_32\n",
            "S019E03_33\n",
            "S019E03_34\n",
            "S019E03_35\n",
            "S021E01_0\n",
            "S021E01_1\n",
            "S021E01_2\n",
            "S021E01_3\n",
            "S021E01_4\n",
            "S021E01_5\n",
            "S021E01_6\n",
            "S021E01_7\n",
            "S021E01_8\n",
            "S021E01_9\n",
            "S021E01_10\n",
            "S021E01_11\n",
            "S021E01_12\n",
            "S021E01_13\n",
            "S021E01_14\n",
            "S021E01_15\n",
            "S021E01_16\n",
            "S021E01_17\n",
            "S021E01_18\n",
            "S021E01_19\n",
            "S021E01_20\n",
            "S021E01_21\n",
            "S021E01_22\n",
            "S021E01_23\n",
            "S021E01_24\n",
            "S021E01_25\n",
            "S021E01_26\n",
            "S021E01_27\n",
            "S021E01_28\n",
            "S021E01_29\n",
            "S021E01_30\n",
            "S021E01_31\n",
            "S021E01_32\n",
            "S021E01_33\n",
            "S021E01_34\n",
            "S021E01_35\n",
            "S021E03_0\n",
            "S021E03_1\n",
            "S021E03_2\n",
            "S021E03_3\n",
            "S021E03_4\n",
            "S021E03_5\n",
            "S021E03_6\n",
            "S021E03_7\n",
            "S021E03_8\n",
            "S021E03_9\n",
            "S021E03_10\n",
            "S021E03_11\n",
            "S021E03_12\n",
            "S021E03_13\n",
            "S021E03_14\n",
            "S021E03_15\n",
            "S021E03_16\n",
            "S021E03_17\n",
            "S021E03_18\n",
            "S021E03_19\n",
            "S021E03_20\n",
            "S021E03_21\n",
            "S021E03_22\n",
            "S021E03_23\n",
            "S021E03_24\n",
            "S021E03_25\n",
            "S021E03_26\n",
            "S021E03_27\n",
            "S021E03_28\n",
            "S021E03_29\n",
            "S021E03_30\n",
            "S021E03_31\n",
            "S021E03_32\n",
            "S021E03_33\n",
            "S021E03_34\n",
            "S021E03_35\n",
            "S023E01_0\n",
            "S023E01_1\n",
            "S023E01_2\n",
            "S023E01_3\n",
            "S023E01_4\n",
            "S023E01_5\n",
            "S023E01_6\n",
            "S023E01_7\n",
            "S023E01_8\n",
            "S023E01_9\n",
            "S023E01_10\n",
            "S023E01_11\n",
            "S023E01_12\n",
            "S023E01_13\n",
            "S023E01_14\n",
            "S023E01_15\n",
            "S023E01_16\n",
            "S023E01_17\n",
            "S023E01_18\n",
            "S023E01_19\n",
            "S023E01_20\n",
            "S023E01_21\n",
            "S023E01_22\n",
            "S023E01_23\n",
            "S023E01_24\n",
            "S023E01_25\n",
            "S023E01_26\n",
            "S023E01_27\n",
            "S023E01_28\n",
            "S023E01_29\n",
            "S023E01_30\n",
            "S023E01_31\n",
            "S023E01_32\n",
            "S023E01_33\n",
            "S023E01_34\n",
            "S023E01_35\n",
            "S023E03_0\n",
            "S023E03_1\n",
            "S023E03_2\n",
            "S023E03_3\n",
            "S023E03_4\n",
            "S023E03_5\n",
            "S023E03_6\n",
            "S023E03_7\n",
            "S023E03_8\n",
            "S023E03_9\n",
            "S023E03_10\n",
            "S023E03_11\n",
            "S023E03_12\n",
            "S023E03_13\n",
            "S023E03_14\n",
            "S023E03_15\n",
            "S023E03_16\n",
            "S023E03_17\n",
            "S023E03_18\n",
            "S023E03_19\n",
            "S023E03_20\n",
            "S023E03_21\n",
            "S023E03_22\n",
            "S023E03_23\n",
            "S023E03_24\n",
            "S023E03_25\n",
            "S023E03_26\n",
            "S023E03_27\n",
            "S023E03_28\n",
            "S023E03_29\n",
            "S023E03_30\n",
            "S023E03_31\n",
            "S023E03_32\n",
            "S023E03_33\n",
            "S023E03_34\n",
            "S023E03_35\n",
            "S025E01_0\n",
            "S025E01_1\n",
            "S025E01_2\n",
            "S025E01_3\n",
            "S025E01_4\n",
            "S025E01_5\n",
            "S025E01_6\n",
            "S025E01_7\n",
            "S025E01_8\n",
            "S025E01_9\n",
            "S025E01_10\n",
            "S025E01_11\n",
            "S025E01_12\n",
            "S025E01_13\n",
            "S025E01_14\n",
            "S025E01_15\n",
            "S025E01_16\n",
            "S025E01_17\n",
            "S025E01_18\n",
            "S025E01_19\n",
            "S025E01_20\n",
            "S025E01_21\n",
            "S025E01_22\n",
            "S025E01_23\n",
            "S025E01_24\n",
            "S025E01_25\n",
            "S025E01_26\n",
            "S025E01_27\n",
            "S025E01_28\n",
            "S025E01_29\n",
            "S025E01_30\n",
            "S025E01_31\n",
            "S025E01_32\n",
            "S025E01_33\n",
            "S025E01_34\n",
            "S025E01_35\n",
            "S025E03_0\n",
            "S025E03_1\n",
            "S025E03_2\n",
            "S025E03_3\n",
            "S025E03_4\n",
            "S025E03_5\n",
            "S025E03_6\n",
            "S025E03_7\n",
            "S025E03_8\n",
            "S025E03_9\n",
            "S025E03_10\n",
            "S025E03_11\n",
            "S025E03_12\n",
            "S025E03_13\n",
            "S025E03_14\n",
            "S025E03_15\n",
            "S025E03_16\n",
            "S025E03_17\n",
            "S025E03_18\n",
            "S025E03_19\n",
            "S025E03_20\n",
            "S025E03_21\n",
            "S025E03_22\n",
            "S025E03_23\n",
            "S025E03_24\n",
            "S025E03_25\n",
            "S025E03_26\n",
            "S025E03_27\n",
            "S025E03_28\n",
            "S025E03_29\n",
            "S025E03_30\n",
            "S025E03_31\n",
            "S025E03_32\n",
            "S025E03_33\n",
            "S025E03_34\n",
            "S025E03_35\n",
            "S027E01_0\n",
            "S027E01_1\n",
            "S027E01_2\n",
            "S027E01_3\n",
            "S027E01_4\n",
            "S027E01_5\n",
            "S027E01_6\n",
            "S027E01_7\n",
            "S027E01_8\n",
            "S027E01_9\n",
            "S027E01_10\n",
            "S027E01_11\n",
            "S027E01_12\n",
            "S027E01_13\n",
            "S027E01_14\n",
            "S027E01_15\n",
            "S027E01_16\n",
            "S027E01_17\n",
            "S027E01_18\n",
            "S027E01_19\n",
            "S027E01_20\n",
            "S027E01_21\n",
            "S027E01_22\n",
            "S027E01_23\n",
            "S027E01_24\n",
            "S027E01_25\n",
            "S027E01_26\n",
            "S027E01_27\n",
            "S027E01_28\n",
            "S027E01_29\n",
            "S027E01_30\n",
            "S027E01_31\n",
            "S027E01_32\n",
            "S027E01_33\n",
            "S027E01_34\n",
            "S027E01_35\n",
            "S027E03_0\n",
            "S027E03_1\n",
            "S027E03_2\n",
            "S027E03_3\n",
            "S027E03_4\n",
            "S027E03_5\n",
            "S027E03_6\n",
            "S027E03_7\n",
            "S027E03_8\n",
            "S027E03_9\n",
            "S027E03_10\n",
            "S027E03_11\n",
            "S027E03_12\n",
            "S027E03_13\n",
            "S027E03_14\n",
            "S027E03_15\n",
            "S027E03_16\n",
            "S027E03_17\n",
            "S027E03_18\n",
            "S027E03_19\n",
            "S027E03_20\n",
            "S027E03_21\n",
            "S027E03_22\n",
            "S027E03_23\n",
            "S027E03_24\n",
            "S027E03_25\n",
            "S027E03_26\n",
            "S027E03_27\n",
            "S027E03_28\n",
            "S027E03_29\n",
            "S027E03_30\n",
            "S027E03_31\n",
            "S027E03_32\n",
            "S027E03_33\n",
            "S027E03_34\n",
            "S027E03_35\n",
            "S029E01_16\n",
            "S029E01_17\n",
            "S029E01_18\n",
            "S029E01_19\n",
            "S029E01_20\n",
            "S029E01_21\n",
            "S029E01_22\n",
            "S029E01_23\n",
            "S029E01_24\n",
            "S029E01_25\n",
            "S029E01_26\n",
            "S029E01_27\n",
            "S029E01_28\n",
            "S029E01_29\n",
            "S029E01_30\n",
            "S029E01_31\n",
            "S029E01_32\n",
            "S029E01_33\n",
            "S029E01_34\n",
            "S029E01_35\n",
            "S029E03_0\n",
            "S029E03_1\n",
            "S029E03_2\n",
            "S029E03_3\n",
            "S029E03_4\n",
            "S029E03_5\n",
            "S029E03_6\n",
            "S029E03_7\n",
            "S029E03_8\n",
            "S029E03_9\n",
            "S029E03_10\n",
            "S029E03_11\n",
            "S029E03_12\n",
            "S029E03_13\n",
            "S029E03_14\n",
            "S029E03_15\n",
            "S029E03_16\n",
            "S029E03_17\n",
            "S029E03_18\n",
            "S029E03_19\n",
            "S029E03_20\n",
            "S029E03_21\n",
            "S029E03_22\n",
            "S029E03_23\n",
            "S029E03_24\n",
            "S029E03_25\n",
            "S029E03_26\n",
            "S029E03_27\n",
            "S029E03_28\n",
            "S029E03_29\n",
            "S029E03_30\n",
            "S029E03_31\n",
            "S029E03_32\n",
            "S029E03_33\n",
            "S029E03_34\n",
            "S029E03_35\n",
            "S030E01_0\n",
            "S030E01_1\n",
            "S030E01_2\n",
            "S030E01_3\n",
            "S030E01_4\n",
            "S030E01_5\n",
            "S030E01_6\n",
            "S030E01_7\n",
            "S030E01_8\n",
            "S030E01_9\n",
            "S030E01_10\n",
            "S030E01_11\n",
            "S030E01_12\n",
            "S030E01_13\n",
            "S030E01_14\n",
            "S030E01_15\n",
            "S030E01_16\n",
            "S030E01_17\n",
            "S030E01_18\n",
            "S030E01_19\n",
            "S030E01_20\n",
            "S030E01_21\n",
            "S030E01_22\n",
            "S030E01_23\n",
            "S030E01_24\n",
            "S030E01_25\n",
            "S030E01_26\n",
            "S030E01_27\n",
            "S030E01_28\n",
            "S030E01_29\n",
            "S030E01_30\n",
            "S030E01_31\n",
            "S030E01_32\n",
            "S030E01_33\n",
            "S030E01_34\n",
            "S030E01_35\n",
            "S030E03_0\n",
            "S030E03_1\n",
            "S030E03_2\n",
            "S030E03_3\n",
            "S030E03_4\n",
            "S030E03_5\n",
            "S030E03_6\n",
            "S030E03_7\n",
            "S030E03_8\n",
            "S030E03_9\n",
            "S030E03_10\n",
            "S030E03_11\n",
            "S030E03_12\n",
            "S030E03_13\n",
            "S030E03_14\n",
            "S030E03_15\n",
            "S030E03_16\n",
            "S030E03_17\n",
            "S030E03_18\n",
            "S030E03_19\n",
            "S030E03_20\n",
            "S030E03_21\n",
            "S030E03_22\n",
            "S030E03_23\n",
            "S030E03_24\n",
            "S030E03_25\n",
            "S030E03_26\n",
            "S030E03_27\n",
            "S030E03_28\n",
            "S030E03_29\n",
            "S030E03_30\n",
            "S030E03_31\n",
            "S030E03_32\n",
            "S030E03_33\n",
            "S030E03_34\n",
            "S030E03_35\n",
            "S001E01_0\n",
            "S001E01_1\n",
            "S001E01_2\n",
            "S001E01_3\n",
            "S001E01_4\n",
            "S001E01_5\n",
            "S001E01_6\n",
            "S001E01_7\n",
            "S001E01_8\n",
            "S001E01_9\n",
            "S001E01_10\n",
            "S001E01_11\n",
            "S001E01_12\n",
            "S001E01_13\n",
            "S001E01_14\n",
            "S001E01_15\n",
            "S001E01_16\n",
            "S001E01_17\n",
            "S001E01_18\n",
            "S001E01_19\n",
            "S001E01_20\n",
            "S001E01_21\n",
            "S001E01_22\n",
            "S001E01_23\n",
            "S001E01_24\n",
            "S001E01_25\n",
            "S001E01_26\n",
            "S001E01_27\n",
            "S001E01_28\n",
            "S001E01_29\n",
            "S001E01_30\n",
            "S001E01_31\n",
            "S001E01_32\n",
            "S001E01_33\n",
            "S001E01_34\n",
            "S001E01_35\n",
            "S001E03_0\n",
            "S001E03_1\n",
            "S001E03_2\n",
            "S001E03_3\n",
            "S001E03_4\n",
            "S001E03_5\n",
            "S001E03_6\n",
            "S001E03_7\n",
            "S001E03_8\n",
            "S001E03_9\n",
            "S001E03_10\n",
            "S001E03_11\n",
            "S001E03_12\n",
            "S001E03_13\n",
            "S001E03_14\n",
            "S001E03_15\n",
            "S001E03_16\n",
            "S001E03_17\n",
            "S001E03_18\n",
            "S001E03_19\n",
            "S001E03_20\n",
            "S001E03_21\n",
            "S001E03_22\n",
            "S001E03_23\n",
            "S001E03_24\n",
            "S001E03_25\n",
            "S001E03_26\n",
            "S001E03_27\n",
            "S001E03_28\n",
            "S001E03_29\n",
            "S001E03_30\n",
            "S001E03_31\n",
            "S001E03_32\n",
            "S001E03_33\n",
            "S001E03_34\n",
            "S001E03_35\n",
            "S002E01_0\n",
            "S002E01_1\n",
            "S002E01_2\n",
            "S002E01_3\n",
            "S002E01_4\n",
            "S002E01_5\n",
            "S002E01_6\n",
            "S002E01_7\n",
            "S002E01_8\n",
            "S002E01_9\n",
            "S002E01_10\n",
            "S002E01_11\n",
            "S002E01_12\n",
            "S002E01_13\n",
            "S002E01_14\n",
            "S002E01_15\n",
            "S002E01_16\n",
            "S002E01_17\n",
            "S002E01_18\n",
            "S002E01_19\n",
            "S002E01_20\n",
            "S002E01_21\n",
            "S002E01_22\n",
            "S002E01_23\n",
            "S002E01_24\n",
            "S002E01_25\n",
            "S002E01_26\n",
            "S002E01_27\n",
            "S002E01_28\n",
            "S002E01_29\n",
            "S002E01_30\n",
            "S002E01_31\n",
            "S002E01_32\n",
            "S002E01_33\n",
            "S002E01_34\n",
            "S002E01_35\n",
            "S002E03_0\n",
            "S002E03_1\n",
            "S002E03_2\n",
            "S002E03_3\n",
            "S002E03_4\n",
            "S002E03_5\n",
            "S002E03_6\n",
            "S002E03_7\n",
            "S002E03_8\n",
            "S002E03_9\n",
            "S002E03_10\n",
            "S002E03_11\n",
            "S002E03_12\n",
            "S002E03_13\n",
            "S002E03_14\n",
            "S002E03_15\n",
            "S002E03_16\n",
            "S002E03_17\n",
            "S002E03_18\n",
            "S002E03_19\n",
            "S002E03_20\n",
            "S002E03_21\n",
            "S002E03_22\n",
            "S002E03_23\n",
            "S002E03_24\n",
            "S002E03_25\n",
            "S002E03_26\n",
            "S002E03_27\n",
            "S002E03_28\n",
            "S002E03_29\n",
            "S002E03_30\n",
            "S002E03_31\n",
            "S002E03_32\n",
            "S002E03_33\n",
            "S002E03_34\n",
            "S002E03_35\n",
            "S003E01_0\n",
            "S003E01_1\n",
            "S003E01_2\n",
            "S003E01_3\n",
            "S003E01_4\n",
            "S003E01_5\n",
            "S003E01_6\n",
            "S003E01_7\n",
            "S003E01_8\n",
            "S003E01_9\n",
            "S003E01_10\n",
            "S003E01_11\n",
            "S003E01_12\n",
            "S003E01_13\n",
            "S003E01_14\n",
            "S003E01_15\n",
            "S003E01_16\n",
            "S003E01_17\n",
            "S003E01_18\n",
            "S003E01_19\n",
            "S003E01_20\n",
            "S003E01_21\n",
            "S003E01_22\n",
            "S003E01_23\n",
            "S003E01_24\n",
            "S003E01_25\n",
            "S003E01_26\n",
            "S003E01_27\n",
            "S003E01_28\n",
            "S003E01_29\n",
            "S003E01_30\n",
            "S003E01_31\n",
            "S003E01_32\n",
            "S003E01_33\n",
            "S003E01_34\n",
            "S003E01_35\n",
            "S003E03_0\n",
            "S003E03_1\n",
            "S003E03_2\n",
            "S003E03_3\n",
            "S003E03_4\n",
            "S003E03_5\n",
            "S003E03_6\n",
            "S003E03_7\n",
            "S003E03_8\n",
            "S003E03_9\n",
            "S003E03_10\n",
            "S003E03_11\n",
            "S003E03_12\n",
            "S003E03_13\n",
            "S003E03_14\n",
            "S003E03_15\n",
            "S003E03_16\n",
            "S003E03_17\n",
            "S003E03_18\n",
            "S003E03_19\n",
            "S003E03_20\n",
            "S003E03_21\n",
            "S003E03_22\n",
            "S003E03_23\n",
            "S003E03_24\n",
            "S003E03_25\n",
            "S003E03_26\n",
            "S003E03_27\n",
            "S003E03_28\n",
            "S003E03_29\n",
            "S003E03_30\n",
            "S003E03_31\n",
            "S003E03_32\n",
            "S003E03_33\n",
            "S003E03_34\n",
            "S003E03_35\n",
            "S004E01_0\n",
            "S004E01_1\n",
            "S004E01_2\n",
            "S004E01_3\n",
            "S004E01_4\n",
            "S004E01_5\n",
            "S004E01_6\n",
            "S004E01_7\n",
            "S004E01_8\n",
            "S004E01_9\n",
            "S004E01_10\n",
            "S004E01_11\n",
            "S004E01_12\n",
            "S004E01_13\n",
            "S004E01_14\n",
            "S004E01_15\n",
            "S004E01_16\n",
            "S004E01_17\n",
            "S004E01_18\n",
            "S004E01_19\n",
            "S004E01_20\n",
            "S004E01_21\n",
            "S004E01_22\n",
            "S004E01_23\n",
            "S004E01_24\n",
            "S004E01_25\n",
            "S004E01_26\n",
            "S004E01_27\n",
            "S004E01_28\n",
            "S004E01_29\n",
            "S004E01_30\n",
            "S004E01_31\n",
            "S004E01_32\n",
            "S004E01_33\n",
            "S004E01_34\n",
            "S004E01_35\n",
            "S004E03_0\n",
            "S004E03_1\n",
            "S004E03_2\n",
            "S004E03_3\n",
            "S004E03_4\n",
            "S004E03_5\n",
            "S004E03_6\n",
            "S004E03_7\n",
            "S004E03_8\n",
            "S004E03_9\n",
            "S004E03_10\n",
            "S004E03_11\n",
            "S004E03_12\n",
            "S004E03_13\n",
            "S004E03_14\n",
            "S004E03_15\n",
            "S004E03_16\n",
            "S004E03_17\n",
            "S004E03_18\n",
            "S004E03_19\n",
            "S004E03_20\n",
            "S004E03_21\n",
            "S004E03_22\n",
            "S004E03_23\n",
            "S004E03_24\n",
            "S004E03_25\n",
            "S004E03_26\n",
            "S004E03_27\n",
            "S004E03_28\n",
            "S004E03_29\n",
            "S004E03_30\n",
            "S004E03_31\n",
            "S004E03_32\n",
            "S004E03_33\n",
            "S004E03_34\n",
            "S004E03_35\n",
            "S006E01_0\n",
            "S006E01_1\n",
            "S006E01_2\n",
            "S006E01_3\n",
            "S006E01_4\n",
            "S006E01_5\n",
            "S006E01_6\n",
            "S006E01_7\n",
            "S006E01_8\n",
            "S006E01_9\n",
            "S006E01_10\n",
            "S006E01_11\n",
            "S006E01_12\n",
            "S006E01_13\n",
            "S006E01_14\n",
            "S006E01_15\n",
            "S006E01_16\n",
            "S006E01_17\n",
            "S006E01_18\n",
            "S006E01_19\n",
            "S006E01_20\n",
            "S006E01_21\n",
            "S006E01_22\n",
            "S006E01_23\n",
            "S006E01_24\n",
            "S006E01_25\n",
            "S006E01_26\n",
            "S006E01_27\n",
            "S006E01_28\n",
            "S006E01_29\n",
            "S006E01_30\n",
            "S006E01_31\n",
            "S006E01_32\n",
            "S006E01_33\n",
            "S006E01_34\n",
            "S006E01_35\n",
            "S005E01_0\n",
            "S005E01_1\n",
            "S005E01_2\n",
            "S005E01_3\n",
            "S005E01_4\n",
            "S005E01_5\n",
            "S005E01_6\n",
            "S005E01_7\n",
            "S005E01_8\n",
            "S005E01_9\n",
            "S005E01_10\n",
            "S005E01_11\n",
            "S005E01_12\n",
            "S005E01_13\n",
            "S005E01_14\n",
            "S005E01_15\n",
            "S005E01_16\n",
            "S005E01_17\n",
            "S005E01_18\n",
            "S005E01_19\n",
            "S005E01_20\n",
            "S005E01_21\n",
            "S005E01_22\n",
            "S005E01_23\n",
            "S005E01_24\n",
            "S005E01_25\n",
            "S006E03_0\n",
            "S005E01_26\n",
            "S006E03_1\n",
            "S005E01_27\n",
            "S006E03_2\n",
            "S005E01_28\n",
            "S006E03_3\n",
            "S005E01_29\n",
            "S006E03_4\n",
            "S005E01_30\n",
            "S006E03_5\n",
            "S005E01_31\n",
            "S006E03_6\n",
            "S005E01_32\n",
            "S005E01_33\n",
            "S006E03_7\n",
            "S005E01_34\n",
            "S006E03_8\n",
            "S005E01_35\n",
            "S006E03_9\n",
            "S006E03_10\n",
            "S006E03_11\n",
            "S006E03_12\n",
            "S006E03_13\n",
            "S006E03_14\n",
            "S006E03_15\n",
            "S006E03_16\n",
            "S006E03_17\n",
            "S006E03_18\n",
            "S006E03_19\n",
            "S006E03_20\n",
            "S006E03_21\n",
            "S006E03_22\n",
            "S006E03_23\n",
            "S006E03_24\n",
            "S006E03_25\n",
            "S006E03_26\n",
            "S006E03_27\n",
            "S006E03_28\n",
            "S006E03_29\n",
            "S006E03_30\n",
            "S006E03_31\n",
            "S006E03_32\n",
            "S006E03_33\n",
            "S006E03_34\n",
            "S006E03_35\n",
            "S005E03_0\n",
            "S005E03_1\n",
            "S005E03_2\n",
            "S005E03_3\n",
            "S005E03_4\n",
            "S005E03_5\n",
            "S005E03_6\n",
            "S005E03_7\n",
            "S005E03_8\n",
            "S005E03_9\n",
            "S005E03_10\n",
            "S005E03_11\n",
            "S005E03_12\n",
            "S005E03_13\n",
            "S005E03_14\n",
            "S005E03_15\n",
            "S005E03_16\n",
            "S005E03_17\n",
            "S005E03_18\n",
            "S005E03_19\n",
            "S005E03_20\n",
            "S005E03_21\n",
            "S005E03_22\n",
            "S005E03_23\n",
            "S005E03_24\n",
            "S005E03_25\n",
            "S005E03_26\n",
            "S005E03_27\n",
            "S005E03_28\n",
            "S005E03_29\n",
            "S005E03_30\n",
            "S005E03_31\n",
            "S005E03_32\n",
            "S005E03_33\n",
            "S005E03_34\n",
            "S005E03_35\n",
            "S008E01_0\n",
            "S008E01_1\n",
            "S008E01_2\n",
            "S008E01_3\n",
            "S008E01_4\n",
            "S008E01_5\n",
            "S008E01_6\n",
            "S008E01_7\n",
            "S008E01_8\n",
            "S008E01_9\n",
            "S008E01_10\n",
            "S008E01_11\n",
            "S008E01_12\n",
            "S008E01_13\n",
            "S008E01_14\n",
            "S008E01_15\n",
            "S008E01_16\n",
            "S008E01_17\n",
            "S008E01_18\n",
            "S008E01_19\n",
            "S008E01_20\n",
            "S008E01_21\n",
            "S008E01_22\n",
            "S008E01_23\n",
            "S008E01_24\n",
            "S008E01_25\n",
            "S008E01_26\n",
            "S008E01_27\n",
            "S008E01_28\n",
            "S008E01_29\n",
            "S008E01_30\n",
            "S008E01_31\n",
            "S008E01_32\n",
            "S008E01_33\n",
            "S008E01_34\n",
            "S008E01_35\n",
            "S008E03_0\n",
            "S008E03_1\n",
            "S008E03_2\n",
            "S008E03_3\n",
            "S008E03_4\n",
            "S008E03_5\n",
            "S008E03_6\n",
            "S008E03_7\n",
            "S008E03_8\n",
            "S008E03_9\n",
            "S008E03_10\n",
            "S008E03_11\n",
            "S008E03_12\n",
            "S008E03_13\n",
            "S008E03_14\n",
            "S008E03_15\n",
            "S008E03_16\n",
            "S008E03_17\n",
            "S008E03_18\n",
            "S008E03_19\n",
            "S008E03_20\n",
            "S008E03_21\n",
            "S008E03_22\n",
            "S008E03_23\n",
            "S008E03_24\n",
            "S008E03_25\n",
            "S008E03_26\n",
            "S008E03_27\n",
            "S008E03_28\n",
            "S008E03_29\n",
            "S008E03_30\n",
            "S008E03_31\n",
            "S008E03_32\n",
            "S008E03_33\n",
            "S008E03_34\n",
            "S008E03_35\n",
            "S007E01_0\n",
            "S007E01_1\n",
            "S007E01_2\n",
            "S007E01_3\n",
            "S007E01_4\n",
            "S007E01_5\n",
            "S007E01_6\n",
            "S007E01_7\n",
            "S007E01_8\n",
            "S007E01_9\n",
            "S007E01_10\n",
            "S007E01_11\n",
            "S007E01_12\n",
            "S007E01_13\n",
            "S007E01_14\n",
            "S007E01_15\n",
            "S007E01_16\n",
            "S007E01_17\n",
            "S007E01_18\n",
            "S007E01_19\n",
            "S007E01_20\n",
            "S007E01_21\n",
            "S007E01_22\n",
            "S007E01_23\n",
            "S007E01_24\n",
            "S007E01_25\n",
            "S007E01_26\n",
            "S007E01_27\n",
            "S007E01_28\n",
            "S007E01_29\n",
            "S007E01_30\n",
            "S007E01_31\n",
            "S007E01_32\n",
            "S007E01_33\n",
            "S007E01_34\n",
            "S007E01_35\n",
            "S007E03_0\n",
            "S007E03_1\n",
            "S007E03_2\n",
            "S007E03_3\n",
            "S007E03_4\n",
            "S007E03_5\n",
            "S007E03_6\n",
            "S007E03_7\n",
            "S007E03_8\n",
            "S007E03_9\n",
            "S007E03_10\n",
            "S007E03_11\n",
            "S007E03_12\n",
            "S007E03_13\n",
            "S007E03_14\n",
            "S007E03_15\n",
            "S007E03_16\n",
            "S007E03_17\n",
            "S007E03_18\n",
            "S007E03_19\n",
            "S007E03_20\n",
            "S007E03_21\n",
            "S007E03_22\n",
            "S007E03_23\n",
            "S007E03_24\n",
            "S007E03_25\n",
            "S007E03_26\n",
            "S007E03_27\n",
            "S007E03_28\n",
            "S007E03_29\n",
            "S007E03_30\n",
            "S007E03_31\n",
            "S007E03_32\n",
            "S007E03_33\n",
            "S007E03_34\n",
            "S007E03_35\n",
            "S009E01_0\n",
            "S009E01_1\n",
            "S009E01_2\n",
            "S009E01_3\n",
            "S009E01_4\n",
            "S009E01_5\n",
            "S009E01_6\n",
            "S009E01_7\n",
            "S009E01_8\n",
            "S009E01_9\n",
            "S009E01_10\n",
            "S009E01_11\n",
            "S009E01_12\n",
            "S009E01_13\n",
            "S009E01_14\n",
            "S009E01_15\n",
            "S009E01_16\n",
            "S009E01_17\n",
            "S009E01_18\n",
            "S009E01_19\n",
            "S009E01_20\n",
            "S009E01_21\n",
            "S009E01_22\n",
            "S009E01_23\n",
            "S009E01_24\n",
            "S009E01_25\n",
            "S009E01_26\n",
            "S009E01_27\n",
            "S009E01_28\n",
            "S009E01_29\n",
            "S009E01_30\n",
            "S009E01_31\n",
            "S009E01_32\n",
            "S009E01_33\n",
            "S009E01_34\n",
            "S009E01_35\n",
            "S009E03_0\n",
            "S009E03_1\n",
            "S009E03_2\n",
            "S009E03_3\n",
            "S009E03_4\n",
            "S009E03_5\n",
            "S009E03_6\n",
            "S009E03_7\n",
            "S009E03_8\n",
            "S009E03_9\n",
            "S009E03_10\n",
            "S009E03_11\n",
            "S009E03_12\n",
            "S009E03_13\n",
            "S009E03_14\n",
            "S009E03_15\n",
            "S009E03_16\n",
            "S009E03_17\n",
            "S009E03_18\n",
            "S009E03_19\n",
            "S009E03_20\n",
            "S009E03_21\n",
            "S009E03_22\n",
            "S009E03_23\n",
            "S009E03_24\n",
            "S009E03_25\n",
            "S009E03_26\n",
            "S009E03_27\n",
            "S009E03_28\n",
            "S009E03_29\n",
            "S009E03_30\n",
            "S009E03_31\n",
            "S009E03_32\n",
            "S009E03_33\n",
            "S009E03_34\n",
            "S009E03_35\n",
            "S011E01_0\n",
            "S011E01_1\n",
            "S011E01_2\n",
            "S011E01_3\n",
            "S011E01_4\n",
            "S011E01_5\n",
            "S011E01_6\n",
            "S011E01_7\n",
            "S011E01_8\n",
            "S011E01_9\n",
            "S011E01_10\n",
            "S011E01_11\n",
            "S011E01_12\n",
            "S011E01_13\n",
            "S011E01_14\n",
            "S011E01_15\n",
            "S011E01_16\n",
            "S011E01_17\n",
            "S011E01_18\n",
            "S011E01_19\n",
            "S011E01_20\n",
            "S011E01_21\n",
            "S011E01_22\n",
            "S011E01_23\n",
            "S011E01_24\n",
            "S011E01_25\n",
            "S011E01_26\n",
            "S011E01_27\n",
            "S011E01_28\n",
            "S011E01_29\n",
            "S011E01_30\n",
            "S011E01_31\n",
            "S011E01_32\n",
            "S011E01_33\n",
            "S011E01_34\n",
            "S011E01_35\n",
            "S011E03_0\n",
            "S011E03_1\n",
            "S011E03_2\n",
            "S011E03_3\n",
            "S011E03_4\n",
            "S011E03_5\n",
            "S011E03_6\n",
            "S011E03_7\n",
            "S011E03_8\n",
            "S011E03_9\n",
            "S011E03_10\n",
            "S011E03_11\n",
            "S011E03_12\n",
            "S011E03_13\n",
            "S011E03_14\n",
            "S011E03_15\n",
            "S011E03_16\n",
            "S011E03_17\n",
            "S011E03_18\n",
            "S011E03_19\n",
            "S011E03_20\n",
            "S011E03_21\n",
            "S011E03_22\n",
            "S011E03_23\n",
            "S011E03_24\n",
            "S011E03_25\n",
            "S011E03_26\n",
            "S011E03_27\n",
            "S011E03_28\n",
            "S011E03_29\n",
            "S011E03_30\n",
            "S011E03_31\n",
            "S011E03_32\n",
            "S011E03_33\n",
            "S011E03_34\n",
            "S011E03_35\n",
            "S012E01_0\n",
            "S012E01_1\n",
            "S012E01_2\n",
            "S012E01_3\n",
            "S012E01_4\n",
            "S012E01_5\n",
            "S012E01_6\n",
            "S012E01_7\n",
            "S012E01_8\n",
            "S012E01_9\n",
            "S012E01_10\n",
            "S012E01_11\n",
            "S012E01_12\n",
            "S012E01_13\n",
            "S012E01_14\n",
            "S012E01_15\n",
            "S012E01_16\n",
            "S012E01_17\n",
            "S012E01_18\n",
            "S012E01_19\n",
            "S012E01_20\n",
            "S012E01_21\n",
            "S012E01_22\n",
            "S012E01_23\n",
            "S012E01_24\n",
            "S013E01_0\n",
            "S012E01_25\n",
            "S013E01_1\n",
            "S012E01_26\n",
            "S013E01_2\n",
            "S012E01_27\n",
            "S013E01_3\n",
            "S012E01_28\n",
            "S013E01_4\n",
            "S012E01_29\n",
            "S013E01_5\n",
            "S012E01_30\n",
            "S013E01_6\n",
            "S012E01_31\n",
            "S013E01_7\n",
            "S013E01_8\n",
            "S013E01_9\n",
            "S013E01_10\n",
            "S013E01_11\n",
            "S013E01_12\n",
            "S013E01_13\n",
            "S013E01_14\n",
            "S012E01_32\n",
            "S013E01_15\n",
            "S012E01_33\n",
            "S013E01_16\n",
            "S012E01_34\n",
            "S013E01_17\n",
            "S012E01_35\n",
            "S013E01_18\n",
            "S013E01_19\n",
            "S013E01_20\n",
            "S013E01_21\n",
            "S013E01_22\n",
            "S013E01_23\n",
            "S013E01_24\n",
            "S013E01_25\n",
            "S013E01_26\n",
            "S013E01_27\n",
            "S013E01_28\n",
            "S013E01_29\n",
            "S013E01_30\n",
            "S013E01_31\n",
            "S013E01_32\n",
            "S013E01_33\n",
            "S013E01_34\n",
            "S013E01_35\n",
            "S012E03_0\n",
            "S012E03_1\n",
            "S012E03_2\n",
            "S012E03_3\n",
            "S012E03_4\n",
            "S012E03_5\n",
            "S012E03_6\n",
            "S012E03_7\n",
            "S012E03_8\n",
            "S012E03_9\n",
            "S012E03_10\n",
            "S012E03_11\n",
            "S012E03_12\n",
            "S012E03_13\n",
            "S012E03_14\n",
            "S012E03_15\n",
            "S012E03_16\n",
            "S012E03_17\n",
            "S012E03_18\n",
            "S012E03_19\n",
            "S012E03_20\n",
            "S013E03_0\n",
            "S012E03_21\n",
            "S013E03_1\n",
            "S012E03_22\n",
            "S013E03_2\n",
            "S012E03_23\n",
            "S013E03_3\n",
            "S012E03_24\n",
            "S013E03_4\n",
            "S012E03_25\n",
            "S013E03_5\n",
            "S012E03_26\n",
            "S013E03_6\n",
            "S012E03_27\n",
            "S013E03_7\n",
            "S012E03_28\n",
            "S013E03_8\n",
            "S012E03_29\n",
            "S013E03_9\n",
            "S012E03_30\n",
            "S013E03_10\n",
            "S012E03_31\n",
            "S013E03_11\n",
            "S012E03_32\n",
            "S013E03_12\n",
            "S013E03_13\n",
            "S013E03_14\n",
            "S012E03_33\n",
            "S013E03_15\n",
            "S012E03_34\n",
            "S013E03_16\n",
            "S012E03_35\n",
            "S013E03_17\n",
            "S013E03_18\n",
            "S013E03_19\n",
            "S013E03_20\n",
            "S013E03_21\n",
            "S013E03_22\n",
            "S013E03_23\n",
            "S013E03_24\n",
            "S013E03_25\n",
            "S013E03_26\n",
            "S013E03_27\n",
            "S013E03_28\n",
            "S013E03_29\n",
            "S013E03_30\n",
            "S013E03_31\n",
            "S013E03_32\n",
            "S013E03_33\n",
            "S013E03_34\n",
            "S013E03_35\n",
            "S015E01_0\n",
            "S015E01_1\n",
            "S015E01_2\n",
            "S015E01_3\n",
            "S015E01_4\n",
            "S015E01_5\n",
            "S015E01_6\n",
            "S015E01_7\n",
            "S028E03_0\n",
            "S028E03_1\n",
            "S028E03_2\n",
            "S028E03_3\n",
            "S028E03_4\n",
            "S028E03_5\n",
            "S028E03_6\n",
            "S028E03_7\n",
            "S028E03_8\n",
            "S028E03_9\n",
            "S028E03_10\n",
            "S028E03_11\n",
            "S028E03_12\n",
            "S028E03_13\n",
            "S028E03_14\n",
            "S028E03_15\n",
            "S028E03_16\n",
            "S028E03_17\n",
            "S028E03_18\n",
            "S028E03_19\n",
            "S028E03_20\n",
            "S028E03_21\n",
            "S028E03_22\n",
            "S028E03_23\n",
            "S028E03_24\n",
            "S028E03_25\n",
            "S028E03_26\n",
            "S028E03_27\n",
            "S028E03_28\n",
            "S028E03_29\n",
            "S028E03_30\n",
            "S028E03_31\n",
            "S028E03_32\n",
            "S028E03_33\n",
            "S028E03_34\n",
            "S028E03_35\n",
            "S029E01_0\n",
            "S029E01_1\n",
            "S029E01_2\n",
            "S029E01_3\n",
            "S029E01_4\n",
            "S029E01_5\n",
            "S029E01_6\n",
            "S029E01_7\n",
            "S029E01_8\n",
            "S029E01_9\n",
            "S029E01_10\n",
            "S029E01_11\n",
            "S029E01_12\n",
            "S029E01_13\n",
            "S029E01_14\n",
            "S029E01_15\n",
            "(2052, 29, 43, 42)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnnxMiFAgaOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "concentration_data_array = np.load(\"concentration_array.npy\")\n",
        "relaxed_data_array = np.load(\"relaxed_array.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn3ekaU7TLHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.concatenate((relaxed_data_array, concentration_data_array))\n",
        "relaxed_data_array, concentration_data_array = None, None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fbrf0r8yhAxC",
        "colab_type": "code",
        "outputId": "33e36495-ee93-447e-a18d-ac4e71d614fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4140, 29, 43, 42)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4gn3kqDZ0tg",
        "colab_type": "code",
        "outputId": "fb1c523a-b561-4901-8282-932d9571171a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "Y = np.concatenate((np.zeros((2052,1)),np.ones((2088,1))))\n",
        "print(X.shape, Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4140, 29, 43, 42) (4140, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4uT-8-Zahh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91H3dUT_au_c",
        "colab_type": "code",
        "outputId": "52141322-bbfb-452b-dd85-30f31e7f3c1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "X, Y = None, None"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3519, 29, 43, 42) (621, 29, 43, 42) (3519, 1) (621, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr_sNqg8a8Op",
        "colab_type": "code",
        "outputId": "e6500f79-cd1e-4a07-ed31-8770042c09e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.15, random_state=42)\n",
        "print(X_train.shape, X_test.shape, X_valid.shape, y_train.shape, y_test.shape, y_valid.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2991, 29, 43, 42) (621, 29, 43, 42) (528, 29, 43, 42) (2991, 1) (621, 1) (528, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za1yTnatbJQN",
        "colab_type": "code",
        "outputId": "550e809b-4042-4014-9e7a-60c621fd5a6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(X_train[4][200][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
            " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.\n",
            " 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255. 255.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QX7rdZXHZfm",
        "colab_type": "code",
        "outputId": "bf3c0be8-c066-4536-dabf-09b4c4746d2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "datagen = ImageDataGenerator()\n",
        "train_base_path = \"Spectrograms/train\"\n",
        "test_base_path = \"Spectrograms/test\"\n",
        "validation_base_path = \"Spectrograms/validation\"\n",
        "train_generator = datagen.flow_from_directory(\n",
        "        train_base_path,\n",
        "        target_size=(288, 432),\n",
        "        class_mode='binary')\n",
        "test_generator = datagen.flow_from_directory(\n",
        "        test_base_path,\n",
        "        target_size=(288, 432),\n",
        "        class_mode='binary')\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "        validation_base_path,\n",
        "        target_size=(288, 432),\n",
        "        class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1344 images belonging to 2 classes.\n",
            "Found 168 images belonging to 2 classes.\n",
            "Found 168 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9ZzdNEHHZfx",
        "colab_type": "code",
        "outputId": "b5df5766-0a98-4107-e37a-6a26b63c186e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# confirm the iterator works\n",
        "batchX, batchy = train_generator.next()\n",
        "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))\n",
        "batchX, batchy = validation_generator.next()\n",
        "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch shape=(32, 288, 432, 3), min=0.000, max=255.000\n",
            "Batch shape=(32, 288, 432, 3), min=0.000, max=255.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWr9HkIrHZf3",
        "colab_type": "code",
        "outputId": "e38c8c7a-1d0c-46ae-ec88-ce3852240b30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D\n",
        "\n",
        "#create model\n",
        "model = Sequential()\n",
        "#add model layers\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(288, 432, 42)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtFUlkymnoXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmpc46zgHZf-",
        "colab_type": "code",
        "outputId": "f84dae4e-b8f2-4067-b5f7-d90fde502a64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        }
      },
      "source": [
        "adam = optimizers.Adam(lr=0.00000001)\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGN9jKEoHZgH",
        "colab_type": "code",
        "outputId": "b7e3d1ff-e709-4e68-a20c-6c8af10fa203",
        "colab": {}
      },
      "source": [
        "model.fit_generator(train_generator, epochs=10, steps_per_epoch=42, validation_data=validation_generator, validation_steps=6)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "42/42 [==============================] - 195s 5s/step - loss: 7.8170 - acc: 0.5097 - val_loss: 7.9712 - val_acc: 0.5000\n",
            "Epoch 2/10\n",
            "42/42 [==============================] - 250s 6s/step - loss: 8.2796 - acc: 0.4807 - val_loss: 7.9712 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "42/42 [==============================] - 206s 5s/step - loss: 7.8051 - acc: 0.5104 - val_loss: 7.9712 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "42/42 [==============================] - 203s 5s/step - loss: 7.8763 - acc: 0.5060 - val_loss: 7.9712 - val_acc: 0.5000\n",
            "Epoch 5/10\n",
            "42/42 [==============================] - 196s 5s/step - loss: 8.1610 - acc: 0.4881 - val_loss: 7.9712 - val_acc: 0.5000\n",
            "Epoch 6/10\n",
            "42/42 [==============================] - 217s 5s/step - loss: 7.7814 - acc: 0.5119 - val_loss: 7.9712 - val_acc: 0.5000\n",
            "Epoch 7/10\n",
            "42/42 [==============================] - 236s 6s/step - loss: 8.1373 - acc: 0.4896 - val_loss: 7.9712 - val_acc: 0.5000\n",
            "Epoch 8/10\n",
            "42/42 [==============================] - 203s 5s/step - loss: 7.8170 - acc: 0.5097 - val_loss: 7.9712 - val_acc: 0.5000\n",
            "Epoch 9/10\n",
            "42/42 [==============================] - 201s 5s/step - loss: 8.0779 - acc: 0.4933 - val_loss: 7.9712 - val_acc: 0.5000\n",
            "Epoch 10/10\n",
            "42/42 [==============================] - 211s 5s/step - loss: 8.0305 - acc: 0.4963 - val_loss: 7.9712 - val_acc: 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x18589170d48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G0CXx-zcFq-",
        "colab_type": "code",
        "outputId": "b50ed0ac-c63f-467f-c00f-50be82fa0306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, batch_size=8, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 86 samples, validate on 16 samples\n",
            "Epoch 1/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 2/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 3/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 4/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 5/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 6/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 7/50\n",
            "86/86 [==============================] - 3s 31ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 8/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 9/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 10/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 11/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 12/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 13/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 14/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 15/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 16/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 17/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 18/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 19/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 20/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 21/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 22/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 23/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 24/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 25/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 26/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 27/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 28/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 29/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 30/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 31/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 32/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 33/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 34/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 35/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 36/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 37/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 38/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 39/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 40/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 41/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 42/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 43/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 44/50\n",
            "86/86 [==============================] - 3s 31ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 45/50\n",
            "86/86 [==============================] - 3s 31ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 46/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 47/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 48/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 49/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n",
            "Epoch 50/50\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 5.9784 - val_acc: 0.6250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efc2be2ac50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp7fBqTLHZgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate model\n",
        "loss = model.evaluate_generator(test_generator, steps=6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCcWot8aHZga",
        "colab_type": "code",
        "outputId": "2b37b023-7b2b-49bf-edc8-0f01c585f9ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras import optimizers\n",
        "#create model\n",
        "model2 = Sequential()\n",
        "#add model layers\n",
        "model2.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(29, 43, 42)))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(50, activation='relu'))\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "sgd = optimizers.SGD(lr=0.00000001, momentum=0.5)\n",
        "model2.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model2.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, batch_size=8, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 2991 samples, validate on 528 samples\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "2991/2991 [==============================] - 19s 6ms/step - loss: 6.4773 - acc: 0.4754 - val_loss: 5.8327 - val_acc: 0.4811\n",
            "Epoch 2/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 5.2788 - acc: 0.4804 - val_loss: 5.2367 - val_acc: 0.4678\n",
            "Epoch 3/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 4.8965 - acc: 0.4865 - val_loss: 4.9559 - val_acc: 0.4716\n",
            "Epoch 4/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 4.6621 - acc: 0.4928 - val_loss: 4.8091 - val_acc: 0.4773\n",
            "Epoch 5/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 4.5020 - acc: 0.4985 - val_loss: 4.7007 - val_acc: 0.4792\n",
            "Epoch 6/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 4.4084 - acc: 0.5022 - val_loss: 4.6369 - val_acc: 0.4792\n",
            "Epoch 7/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 4.3325 - acc: 0.5048 - val_loss: 4.5804 - val_acc: 0.4905\n",
            "Epoch 8/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 4.2739 - acc: 0.5122 - val_loss: 4.5424 - val_acc: 0.4905\n",
            "Epoch 9/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 4.2282 - acc: 0.5105 - val_loss: 4.5414 - val_acc: 0.4867\n",
            "Epoch 10/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 4.1861 - acc: 0.5139 - val_loss: 4.5126 - val_acc: 0.4886\n",
            "Epoch 11/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 4.1516 - acc: 0.5109 - val_loss: 4.4721 - val_acc: 0.4905\n",
            "Epoch 12/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 4.1160 - acc: 0.5125 - val_loss: 4.4235 - val_acc: 0.4924\n",
            "Epoch 13/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 4.0897 - acc: 0.5129 - val_loss: 4.4163 - val_acc: 0.4981\n",
            "Epoch 14/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 4.0637 - acc: 0.5149 - val_loss: 4.3896 - val_acc: 0.5038\n",
            "Epoch 15/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 4.0316 - acc: 0.5162 - val_loss: 4.3819 - val_acc: 0.5076\n",
            "Epoch 16/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 4.0223 - acc: 0.5155 - val_loss: 4.3694 - val_acc: 0.5095\n",
            "Epoch 17/50\n",
            "2991/2991 [==============================] - 6s 2ms/step - loss: 3.9918 - acc: 0.5182 - val_loss: 4.3272 - val_acc: 0.5019\n",
            "Epoch 18/50\n",
            "2991/2991 [==============================] - 6s 2ms/step - loss: 3.9891 - acc: 0.5176 - val_loss: 4.3167 - val_acc: 0.5076\n",
            "Epoch 19/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 3.9693 - acc: 0.5159 - val_loss: 4.3414 - val_acc: 0.5000\n",
            "Epoch 20/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 3.9588 - acc: 0.5196 - val_loss: 4.3579 - val_acc: 0.5038\n",
            "Epoch 21/50\n",
            "2991/2991 [==============================] - 6s 2ms/step - loss: 3.9538 - acc: 0.5199 - val_loss: 4.3368 - val_acc: 0.5038\n",
            "Epoch 22/50\n",
            "2991/2991 [==============================] - 7s 2ms/step - loss: 3.9317 - acc: 0.5165 - val_loss: 4.3311 - val_acc: 0.5076\n",
            "Epoch 23/50\n",
            "2991/2991 [==============================] - 7s 2ms/step - loss: 3.9286 - acc: 0.5252 - val_loss: 4.3229 - val_acc: 0.5133\n",
            "Epoch 24/50\n",
            "2991/2991 [==============================] - 7s 2ms/step - loss: 3.9190 - acc: 0.5252 - val_loss: 4.2992 - val_acc: 0.5095\n",
            "Epoch 25/50\n",
            "2991/2991 [==============================] - 7s 2ms/step - loss: 3.9074 - acc: 0.5232 - val_loss: 4.2650 - val_acc: 0.5057\n",
            "Epoch 26/50\n",
            "2991/2991 [==============================] - 7s 2ms/step - loss: 3.8942 - acc: 0.5259 - val_loss: 4.2490 - val_acc: 0.5076\n",
            "Epoch 27/50\n",
            "2991/2991 [==============================] - 7s 2ms/step - loss: 3.8818 - acc: 0.5236 - val_loss: 4.2410 - val_acc: 0.5095\n",
            "Epoch 28/50\n",
            "2991/2991 [==============================] - 6s 2ms/step - loss: 3.8768 - acc: 0.5252 - val_loss: 4.2378 - val_acc: 0.5095\n",
            "Epoch 29/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 3.8655 - acc: 0.5272 - val_loss: 4.2658 - val_acc: 0.5133\n",
            "Epoch 30/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 3.8559 - acc: 0.5283 - val_loss: 4.2506 - val_acc: 0.5152\n",
            "Epoch 31/50\n",
            "2991/2991 [==============================] - 6s 2ms/step - loss: 3.8499 - acc: 0.5279 - val_loss: 4.2291 - val_acc: 0.5133\n",
            "Epoch 32/50\n",
            "2991/2991 [==============================] - 7s 2ms/step - loss: 3.8421 - acc: 0.5283 - val_loss: 4.2196 - val_acc: 0.5133\n",
            "Epoch 33/50\n",
            "2991/2991 [==============================] - 6s 2ms/step - loss: 3.8387 - acc: 0.5279 - val_loss: 4.2073 - val_acc: 0.5133\n",
            "Epoch 34/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 3.8266 - acc: 0.5246 - val_loss: 4.1772 - val_acc: 0.4962\n",
            "Epoch 35/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 3.8226 - acc: 0.5269 - val_loss: 4.1743 - val_acc: 0.5038\n",
            "Epoch 36/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 3.8129 - acc: 0.5259 - val_loss: 4.2065 - val_acc: 0.5152\n",
            "Epoch 37/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 3.8037 - acc: 0.5236 - val_loss: 4.2691 - val_acc: 0.5038\n",
            "Epoch 38/50\n",
            "2991/2991 [==============================] - 6s 2ms/step - loss: 3.8065 - acc: 0.5276 - val_loss: 4.1815 - val_acc: 0.5114\n",
            "Epoch 39/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 3.7991 - acc: 0.5249 - val_loss: 4.1848 - val_acc: 0.5114\n",
            "Epoch 40/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 3.7919 - acc: 0.5266 - val_loss: 4.1847 - val_acc: 0.5076\n",
            "Epoch 41/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 3.7869 - acc: 0.5232 - val_loss: 4.1403 - val_acc: 0.5057\n",
            "Epoch 42/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 3.7803 - acc: 0.5256 - val_loss: 4.1520 - val_acc: 0.5095\n",
            "Epoch 43/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 3.7770 - acc: 0.5252 - val_loss: 4.1469 - val_acc: 0.5095\n",
            "Epoch 44/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 3.7680 - acc: 0.5246 - val_loss: 4.1501 - val_acc: 0.5038\n",
            "Epoch 45/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 3.7624 - acc: 0.5216 - val_loss: 4.1180 - val_acc: 0.5019\n",
            "Epoch 46/50\n",
            "2991/2991 [==============================] - 6s 2ms/step - loss: 3.7612 - acc: 0.5196 - val_loss: 4.1336 - val_acc: 0.5019\n",
            "Epoch 47/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 3.7475 - acc: 0.5242 - val_loss: 4.1432 - val_acc: 0.5000\n",
            "Epoch 48/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 3.7479 - acc: 0.5206 - val_loss: 4.1244 - val_acc: 0.5076\n",
            "Epoch 49/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 3.7414 - acc: 0.5252 - val_loss: 4.1277 - val_acc: 0.5057\n",
            "Epoch 50/50\n",
            "2991/2991 [==============================] - 5s 2ms/step - loss: 3.7367 - acc: 0.5249 - val_loss: 4.1069 - val_acc: 0.5019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f98093bdb38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_8TplxJpqHk",
        "colab_type": "code",
        "outputId": "47545c94-6b9c-4e58-83f1-337877cca018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "model3 = Sequential()\n",
        "#add model layers\n",
        "model3.add(SeparableConv2D(512, kernel_size=5, activation='relu', input_shape=(29, 43, 42)))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model3.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(50, activation='relu'))\n",
        "model3.add(Dense(1, activation='sigmoid'))\n",
        "sgd = optimizers.SGD(lr=0.00000001, momentum=0.5)\n",
        "model3.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model3.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, batch_size=8, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2991 samples, validate on 528 samples\n",
            "Epoch 1/50\n",
            "2991/2991 [==============================] - 10s 3ms/step - loss: 6.2329 - acc: 0.4888 - val_loss: 5.1691 - val_acc: 0.5114\n",
            "Epoch 2/50\n",
            "2991/2991 [==============================] - 8s 3ms/step - loss: 4.6302 - acc: 0.4888 - val_loss: 3.6184 - val_acc: 0.5114\n",
            "Epoch 3/50\n",
            "2991/2991 [==============================] - 8s 3ms/step - loss: 3.0519 - acc: 0.4881 - val_loss: 2.2074 - val_acc: 0.5114\n",
            "Epoch 4/50\n",
            "2991/2991 [==============================] - 8s 3ms/step - loss: 1.7548 - acc: 0.4838 - val_loss: 1.2699 - val_acc: 0.4716\n",
            "Epoch 5/50\n",
            "2991/2991 [==============================] - 8s 3ms/step - loss: 1.0833 - acc: 0.4691 - val_loss: 0.9718 - val_acc: 0.4659\n",
            "Epoch 6/50\n",
            "2991/2991 [==============================] - 8s 3ms/step - loss: 0.9074 - acc: 0.4637 - val_loss: 0.9239 - val_acc: 0.4621\n",
            "Epoch 7/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.8718 - acc: 0.4748 - val_loss: 0.9132 - val_acc: 0.4697\n",
            "Epoch 8/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.8592 - acc: 0.4871 - val_loss: 0.9042 - val_acc: 0.4678\n",
            "Epoch 9/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.8500 - acc: 0.4901 - val_loss: 0.8961 - val_acc: 0.4678\n",
            "Epoch 10/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.8418 - acc: 0.4928 - val_loss: 0.8870 - val_acc: 0.4659\n",
            "Epoch 11/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.8351 - acc: 0.4928 - val_loss: 0.8805 - val_acc: 0.4659\n",
            "Epoch 12/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.8287 - acc: 0.4908 - val_loss: 0.8740 - val_acc: 0.4716\n",
            "Epoch 13/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.8234 - acc: 0.4921 - val_loss: 0.8689 - val_acc: 0.4716\n",
            "Epoch 14/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.8186 - acc: 0.4931 - val_loss: 0.8638 - val_acc: 0.4830\n",
            "Epoch 15/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.8142 - acc: 0.4945 - val_loss: 0.8588 - val_acc: 0.4811\n",
            "Epoch 16/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.8104 - acc: 0.4978 - val_loss: 0.8556 - val_acc: 0.4867\n",
            "Epoch 17/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.8071 - acc: 0.4995 - val_loss: 0.8522 - val_acc: 0.4981\n",
            "Epoch 18/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.8040 - acc: 0.5022 - val_loss: 0.8494 - val_acc: 0.4962\n",
            "Epoch 19/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.8013 - acc: 0.5062 - val_loss: 0.8463 - val_acc: 0.4905\n",
            "Epoch 20/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7988 - acc: 0.5025 - val_loss: 0.8440 - val_acc: 0.4867\n",
            "Epoch 21/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7965 - acc: 0.5059 - val_loss: 0.8411 - val_acc: 0.4924\n",
            "Epoch 22/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7944 - acc: 0.5045 - val_loss: 0.8389 - val_acc: 0.4867\n",
            "Epoch 23/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7927 - acc: 0.5062 - val_loss: 0.8369 - val_acc: 0.4848\n",
            "Epoch 24/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7911 - acc: 0.5059 - val_loss: 0.8356 - val_acc: 0.4848\n",
            "Epoch 25/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7897 - acc: 0.5112 - val_loss: 0.8346 - val_acc: 0.4943\n",
            "Epoch 26/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7883 - acc: 0.5142 - val_loss: 0.8327 - val_acc: 0.5000\n",
            "Epoch 27/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7871 - acc: 0.5145 - val_loss: 0.8313 - val_acc: 0.5019\n",
            "Epoch 28/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7860 - acc: 0.5165 - val_loss: 0.8310 - val_acc: 0.5019\n",
            "Epoch 29/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7851 - acc: 0.5169 - val_loss: 0.8298 - val_acc: 0.5038\n",
            "Epoch 30/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7842 - acc: 0.5199 - val_loss: 0.8283 - val_acc: 0.5057\n",
            "Epoch 31/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7833 - acc: 0.5199 - val_loss: 0.8272 - val_acc: 0.5038\n",
            "Epoch 32/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7825 - acc: 0.5206 - val_loss: 0.8262 - val_acc: 0.5095\n",
            "Epoch 33/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7817 - acc: 0.5212 - val_loss: 0.8263 - val_acc: 0.5095\n",
            "Epoch 34/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7810 - acc: 0.5236 - val_loss: 0.8256 - val_acc: 0.5076\n",
            "Epoch 35/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7803 - acc: 0.5236 - val_loss: 0.8250 - val_acc: 0.5038\n",
            "Epoch 36/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7796 - acc: 0.5202 - val_loss: 0.8250 - val_acc: 0.5038\n",
            "Epoch 37/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7791 - acc: 0.5242 - val_loss: 0.8240 - val_acc: 0.5000\n",
            "Epoch 38/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7785 - acc: 0.5216 - val_loss: 0.8230 - val_acc: 0.4981\n",
            "Epoch 39/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7780 - acc: 0.5219 - val_loss: 0.8226 - val_acc: 0.5000\n",
            "Epoch 40/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7774 - acc: 0.5206 - val_loss: 0.8220 - val_acc: 0.5038\n",
            "Epoch 41/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7769 - acc: 0.5216 - val_loss: 0.8220 - val_acc: 0.5076\n",
            "Epoch 42/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7765 - acc: 0.5239 - val_loss: 0.8211 - val_acc: 0.5152\n",
            "Epoch 43/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7760 - acc: 0.5219 - val_loss: 0.8209 - val_acc: 0.5189\n",
            "Epoch 44/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7755 - acc: 0.5216 - val_loss: 0.8207 - val_acc: 0.5208\n",
            "Epoch 45/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7750 - acc: 0.5212 - val_loss: 0.8194 - val_acc: 0.5208\n",
            "Epoch 46/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7746 - acc: 0.5192 - val_loss: 0.8193 - val_acc: 0.5227\n",
            "Epoch 47/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7742 - acc: 0.5222 - val_loss: 0.8195 - val_acc: 0.5246\n",
            "Epoch 48/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7738 - acc: 0.5209 - val_loss: 0.8193 - val_acc: 0.5284\n",
            "Epoch 49/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7734 - acc: 0.5209 - val_loss: 0.8184 - val_acc: 0.5265\n",
            "Epoch 50/50\n",
            "2991/2991 [==============================] - 9s 3ms/step - loss: 0.7730 - acc: 0.5222 - val_loss: 0.8180 - val_acc: 0.5227\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f97aeb1ed30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e9a7pHdrfRg",
        "colab_type": "code",
        "outputId": "6569f229-7025-49e1-c272-20b3cd6aec9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model4 = Sequential()\n",
        "#add model layers\n",
        "model4.add(SeparableConv2D(256, kernel_size=5, activation='relu', input_shape=(288, 432, 42)))\n",
        "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model4.add(SeparableConv2D(64, kernel_size=3, activation='relu'))\n",
        "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model4.add(Flatten())\n",
        "model4.add(Dense(50, activation='relu'))\n",
        "model4.add(Dense(1, activation='sigmoid'))\n",
        "sgd = optimizers.SGD(lr=0.00000001, momentum=0.5)\n",
        "model4.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model4.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, batch_size=8, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 86 samples, validate on 16 samples\n",
            "Epoch 1/50\n",
            "86/86 [==============================] - 6s 75ms/step - loss: 1.1216 - acc: 0.5000 - val_loss: 1.0257 - val_acc: 0.6250\n",
            "Epoch 2/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 1.0565 - acc: 0.5000 - val_loss: 0.9893 - val_acc: 0.6250\n",
            "Epoch 3/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.9977 - acc: 0.5000 - val_loss: 0.9556 - val_acc: 0.6250\n",
            "Epoch 4/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.9466 - acc: 0.5000 - val_loss: 0.9273 - val_acc: 0.6250\n",
            "Epoch 5/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.9026 - acc: 0.5000 - val_loss: 0.9054 - val_acc: 0.6250\n",
            "Epoch 6/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.8642 - acc: 0.5000 - val_loss: 0.8890 - val_acc: 0.6250\n",
            "Epoch 7/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.8323 - acc: 0.4884 - val_loss: 0.8760 - val_acc: 0.6250\n",
            "Epoch 8/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.8052 - acc: 0.4767 - val_loss: 0.8659 - val_acc: 0.6250\n",
            "Epoch 9/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.7823 - acc: 0.4884 - val_loss: 0.8590 - val_acc: 0.5000\n",
            "Epoch 10/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.7637 - acc: 0.5000 - val_loss: 0.8545 - val_acc: 0.5000\n",
            "Epoch 11/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.7486 - acc: 0.5116 - val_loss: 0.8516 - val_acc: 0.5000\n",
            "Epoch 12/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.7354 - acc: 0.5349 - val_loss: 0.8501 - val_acc: 0.5000\n",
            "Epoch 13/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.7249 - acc: 0.5349 - val_loss: 0.8497 - val_acc: 0.4375\n",
            "Epoch 14/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.7167 - acc: 0.5465 - val_loss: 0.8503 - val_acc: 0.4375\n",
            "Epoch 15/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.7098 - acc: 0.5349 - val_loss: 0.8512 - val_acc: 0.3750\n",
            "Epoch 16/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.7037 - acc: 0.5465 - val_loss: 0.8527 - val_acc: 0.2500\n",
            "Epoch 17/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.7000 - acc: 0.5698 - val_loss: 0.8547 - val_acc: 0.2500\n",
            "Epoch 18/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6955 - acc: 0.5814 - val_loss: 0.8566 - val_acc: 0.2500\n",
            "Epoch 19/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6924 - acc: 0.5930 - val_loss: 0.8582 - val_acc: 0.2500\n",
            "Epoch 20/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6910 - acc: 0.5930 - val_loss: 0.8598 - val_acc: 0.2500\n",
            "Epoch 21/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6882 - acc: 0.5930 - val_loss: 0.8621 - val_acc: 0.2500\n",
            "Epoch 22/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6868 - acc: 0.5930 - val_loss: 0.8643 - val_acc: 0.2500\n",
            "Epoch 23/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6855 - acc: 0.6163 - val_loss: 0.8653 - val_acc: 0.2500\n",
            "Epoch 24/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6846 - acc: 0.6163 - val_loss: 0.8673 - val_acc: 0.2500\n",
            "Epoch 25/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6836 - acc: 0.5930 - val_loss: 0.8689 - val_acc: 0.3125\n",
            "Epoch 26/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6837 - acc: 0.5698 - val_loss: 0.8700 - val_acc: 0.3125\n",
            "Epoch 27/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6824 - acc: 0.5814 - val_loss: 0.8714 - val_acc: 0.3125\n",
            "Epoch 28/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6820 - acc: 0.5814 - val_loss: 0.8721 - val_acc: 0.3125\n",
            "Epoch 29/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6819 - acc: 0.5814 - val_loss: 0.8735 - val_acc: 0.3125\n",
            "Epoch 30/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6816 - acc: 0.5814 - val_loss: 0.8739 - val_acc: 0.3125\n",
            "Epoch 31/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6813 - acc: 0.5814 - val_loss: 0.8749 - val_acc: 0.3125\n",
            "Epoch 32/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6809 - acc: 0.5814 - val_loss: 0.8757 - val_acc: 0.3125\n",
            "Epoch 33/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6814 - acc: 0.5814 - val_loss: 0.8761 - val_acc: 0.2500\n",
            "Epoch 34/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6816 - acc: 0.5581 - val_loss: 0.8773 - val_acc: 0.2500\n",
            "Epoch 35/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6812 - acc: 0.5814 - val_loss: 0.8773 - val_acc: 0.2500\n",
            "Epoch 36/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6805 - acc: 0.5698 - val_loss: 0.8782 - val_acc: 0.2500\n",
            "Epoch 37/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6808 - acc: 0.5698 - val_loss: 0.8779 - val_acc: 0.2500\n",
            "Epoch 38/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6812 - acc: 0.5581 - val_loss: 0.8792 - val_acc: 0.2500\n",
            "Epoch 39/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6807 - acc: 0.5581 - val_loss: 0.8791 - val_acc: 0.2500\n",
            "Epoch 40/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6801 - acc: 0.5465 - val_loss: 0.8794 - val_acc: 0.2500\n",
            "Epoch 41/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6807 - acc: 0.5581 - val_loss: 0.8800 - val_acc: 0.2500\n",
            "Epoch 42/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6803 - acc: 0.5581 - val_loss: 0.8797 - val_acc: 0.2500\n",
            "Epoch 43/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6799 - acc: 0.5581 - val_loss: 0.8797 - val_acc: 0.2500\n",
            "Epoch 44/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6808 - acc: 0.5465 - val_loss: 0.8797 - val_acc: 0.2500\n",
            "Epoch 45/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6798 - acc: 0.5581 - val_loss: 0.8808 - val_acc: 0.2500\n",
            "Epoch 46/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6803 - acc: 0.5581 - val_loss: 0.8809 - val_acc: 0.2500\n",
            "Epoch 47/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6798 - acc: 0.5581 - val_loss: 0.8812 - val_acc: 0.2500\n",
            "Epoch 48/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6800 - acc: 0.5698 - val_loss: 0.8820 - val_acc: 0.2500\n",
            "Epoch 49/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6797 - acc: 0.5698 - val_loss: 0.8813 - val_acc: 0.2500\n",
            "Epoch 50/50\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.6797 - acc: 0.5698 - val_loss: 0.8811 - val_acc: 0.2500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efc2b3c4908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFgO1PPttYI6",
        "colab_type": "code",
        "outputId": "e0537781-5dc4-427b-c34b-08009ed09db8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "source": [
        "model5 = Sequential()\n",
        "#add model layers\n",
        "model5.add(Conv3D(256, kernel_size=3, activation='relu', input_shape=(288, 432, 42)))\n",
        "model5.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "model5.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
        "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model5.add(Flatten())\n",
        "model5.add(Dense(50, activation='relu'))\n",
        "model5.add(Dense(1, activation='sigmoid'))\n",
        "sgd = optimizers.SGD(lr=0.00000001, momentum=0.5)\n",
        "model5.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model5.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, batch_size=8, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-da68a5fb0c05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#add model layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m288\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m432\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                     \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m                     \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    303\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    306\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer conv3d_1: expected ndim=5, found ndim=4"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXKDUYtiultA",
        "colab_type": "code",
        "outputId": "c9fda66d-279c-4317-a868-9dbe8fd49bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "from sklearn import svm\n",
        "model5 = svm.SVC()\n",
        "model5.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-974fb9b38b50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    146\u001b[0m         X, y = check_X_y(X, y, dtype=np.float64,\n\u001b[1;32m    147\u001b[0m                          \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                          accept_large_sparse=False)\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[0;32m--> 574\u001b[0;31m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with dim 4. Estimator expected <= 2."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43adlB_Hvptw",
        "colab_type": "code",
        "outputId": "d2d2b35e-cfad-4460-8905-08b22699c67d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model6 = Sequential()\n",
        "#add model layers\n",
        "model6.add(DepthwiseConv2D(kernel_size=(3,3), activation='relu', input_shape=(288, 432, 42)))\n",
        "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model6.add(DepthwiseConv2D(kernel_size=(3,3), activation='relu'))\n",
        "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model6.add(Flatten())\n",
        "model6.add(Dense(50, activation='relu'))\n",
        "model6.add(Dense(1, activation='sigmoid'))\n",
        "sgd = optimizers.SGD(lr=0.00000001, momentum=0.5)\n",
        "model6.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model6.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=150, batch_size=8, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 86 samples, validate on 16 samples\n",
            "Epoch 1/150\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 1.7861 - acc: 0.5000 - val_loss: 2.4542 - val_acc: 0.3750\n",
            "Epoch 2/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.7211 - acc: 0.5000 - val_loss: 2.3723 - val_acc: 0.3750\n",
            "Epoch 3/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.6565 - acc: 0.5000 - val_loss: 2.2836 - val_acc: 0.3750\n",
            "Epoch 4/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.5939 - acc: 0.5000 - val_loss: 2.2029 - val_acc: 0.3750\n",
            "Epoch 5/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.5336 - acc: 0.5000 - val_loss: 2.1223 - val_acc: 0.3750\n",
            "Epoch 6/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.4753 - acc: 0.5000 - val_loss: 2.0438 - val_acc: 0.3750\n",
            "Epoch 7/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.4188 - acc: 0.5000 - val_loss: 1.9698 - val_acc: 0.3750\n",
            "Epoch 8/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.3641 - acc: 0.5000 - val_loss: 1.8948 - val_acc: 0.3750\n",
            "Epoch 9/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.3122 - acc: 0.5000 - val_loss: 1.8242 - val_acc: 0.3750\n",
            "Epoch 10/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.2631 - acc: 0.5000 - val_loss: 1.7601 - val_acc: 0.3750\n",
            "Epoch 11/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.2169 - acc: 0.5000 - val_loss: 1.6935 - val_acc: 0.3750\n",
            "Epoch 12/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.1723 - acc: 0.5000 - val_loss: 1.6340 - val_acc: 0.3750\n",
            "Epoch 13/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.1311 - acc: 0.5116 - val_loss: 1.5764 - val_acc: 0.3750\n",
            "Epoch 14/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.0919 - acc: 0.5116 - val_loss: 1.5234 - val_acc: 0.3750\n",
            "Epoch 15/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.0564 - acc: 0.5116 - val_loss: 1.4701 - val_acc: 0.3750\n",
            "Epoch 16/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 1.0218 - acc: 0.5116 - val_loss: 1.4215 - val_acc: 0.3750\n",
            "Epoch 17/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.9906 - acc: 0.5116 - val_loss: 1.3775 - val_acc: 0.3750\n",
            "Epoch 18/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.9621 - acc: 0.5116 - val_loss: 1.3332 - val_acc: 0.3750\n",
            "Epoch 19/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.9358 - acc: 0.5116 - val_loss: 1.2922 - val_acc: 0.4375\n",
            "Epoch 20/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.9124 - acc: 0.5233 - val_loss: 1.2584 - val_acc: 0.4375\n",
            "Epoch 21/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.8921 - acc: 0.5233 - val_loss: 1.2256 - val_acc: 0.4375\n",
            "Epoch 22/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.8728 - acc: 0.5349 - val_loss: 1.1934 - val_acc: 0.4375\n",
            "Epoch 23/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.8559 - acc: 0.5465 - val_loss: 1.1667 - val_acc: 0.4375\n",
            "Epoch 24/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.8412 - acc: 0.5233 - val_loss: 1.1419 - val_acc: 0.4375\n",
            "Epoch 25/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.8277 - acc: 0.5233 - val_loss: 1.1188 - val_acc: 0.4375\n",
            "Epoch 26/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.8153 - acc: 0.5000 - val_loss: 1.0985 - val_acc: 0.4375\n",
            "Epoch 27/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.8043 - acc: 0.5349 - val_loss: 1.0794 - val_acc: 0.4375\n",
            "Epoch 28/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7943 - acc: 0.5349 - val_loss: 1.0592 - val_acc: 0.3125\n",
            "Epoch 29/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7856 - acc: 0.5465 - val_loss: 1.0435 - val_acc: 0.3125\n",
            "Epoch 30/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7782 - acc: 0.5465 - val_loss: 1.0276 - val_acc: 0.3125\n",
            "Epoch 31/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7713 - acc: 0.5581 - val_loss: 1.0151 - val_acc: 0.3125\n",
            "Epoch 32/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7656 - acc: 0.5465 - val_loss: 1.0026 - val_acc: 0.3125\n",
            "Epoch 33/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7604 - acc: 0.5465 - val_loss: 0.9913 - val_acc: 0.2500\n",
            "Epoch 34/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7559 - acc: 0.5233 - val_loss: 0.9818 - val_acc: 0.2500\n",
            "Epoch 35/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7519 - acc: 0.5000 - val_loss: 0.9728 - val_acc: 0.2500\n",
            "Epoch 36/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7484 - acc: 0.5000 - val_loss: 0.9641 - val_acc: 0.2500\n",
            "Epoch 37/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7451 - acc: 0.5465 - val_loss: 0.9555 - val_acc: 0.3125\n",
            "Epoch 38/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7422 - acc: 0.5698 - val_loss: 0.9477 - val_acc: 0.3125\n",
            "Epoch 39/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7396 - acc: 0.5814 - val_loss: 0.9412 - val_acc: 0.3125\n",
            "Epoch 40/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7377 - acc: 0.5930 - val_loss: 0.9356 - val_acc: 0.3125\n",
            "Epoch 41/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7364 - acc: 0.5814 - val_loss: 0.9302 - val_acc: 0.3125\n",
            "Epoch 42/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7342 - acc: 0.5814 - val_loss: 0.9263 - val_acc: 0.3125\n",
            "Epoch 43/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7329 - acc: 0.5814 - val_loss: 0.9207 - val_acc: 0.3125\n",
            "Epoch 44/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7315 - acc: 0.5814 - val_loss: 0.9175 - val_acc: 0.3125\n",
            "Epoch 45/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7302 - acc: 0.5814 - val_loss: 0.9133 - val_acc: 0.3125\n",
            "Epoch 46/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7294 - acc: 0.5814 - val_loss: 0.9101 - val_acc: 0.3125\n",
            "Epoch 47/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7285 - acc: 0.5814 - val_loss: 0.9068 - val_acc: 0.3125\n",
            "Epoch 48/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7276 - acc: 0.5930 - val_loss: 0.9032 - val_acc: 0.3125\n",
            "Epoch 49/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7265 - acc: 0.5814 - val_loss: 0.9000 - val_acc: 0.3125\n",
            "Epoch 50/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7262 - acc: 0.5814 - val_loss: 0.8973 - val_acc: 0.3125\n",
            "Epoch 51/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7252 - acc: 0.5814 - val_loss: 0.8939 - val_acc: 0.2500\n",
            "Epoch 52/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7250 - acc: 0.5581 - val_loss: 0.8917 - val_acc: 0.2500\n",
            "Epoch 53/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7245 - acc: 0.5698 - val_loss: 0.8899 - val_acc: 0.2500\n",
            "Epoch 54/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7240 - acc: 0.5581 - val_loss: 0.8876 - val_acc: 0.2500\n",
            "Epoch 55/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7238 - acc: 0.5698 - val_loss: 0.8859 - val_acc: 0.2500\n",
            "Epoch 56/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7235 - acc: 0.5698 - val_loss: 0.8845 - val_acc: 0.2500\n",
            "Epoch 57/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7233 - acc: 0.5581 - val_loss: 0.8831 - val_acc: 0.2500\n",
            "Epoch 58/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7227 - acc: 0.5698 - val_loss: 0.8819 - val_acc: 0.2500\n",
            "Epoch 59/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7227 - acc: 0.5465 - val_loss: 0.8805 - val_acc: 0.2500\n",
            "Epoch 60/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7223 - acc: 0.5349 - val_loss: 0.8790 - val_acc: 0.2500\n",
            "Epoch 61/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7219 - acc: 0.5349 - val_loss: 0.8774 - val_acc: 0.2500\n",
            "Epoch 62/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7216 - acc: 0.5349 - val_loss: 0.8767 - val_acc: 0.2500\n",
            "Epoch 63/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7218 - acc: 0.5349 - val_loss: 0.8752 - val_acc: 0.2500\n",
            "Epoch 64/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7217 - acc: 0.5349 - val_loss: 0.8747 - val_acc: 0.2500\n",
            "Epoch 65/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7212 - acc: 0.5349 - val_loss: 0.8742 - val_acc: 0.2500\n",
            "Epoch 66/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7214 - acc: 0.5349 - val_loss: 0.8726 - val_acc: 0.2500\n",
            "Epoch 67/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7209 - acc: 0.5349 - val_loss: 0.8726 - val_acc: 0.2500\n",
            "Epoch 68/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7209 - acc: 0.5349 - val_loss: 0.8722 - val_acc: 0.2500\n",
            "Epoch 69/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7210 - acc: 0.5349 - val_loss: 0.8703 - val_acc: 0.2500\n",
            "Epoch 70/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7214 - acc: 0.5349 - val_loss: 0.8707 - val_acc: 0.2500\n",
            "Epoch 71/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7204 - acc: 0.5349 - val_loss: 0.8699 - val_acc: 0.2500\n",
            "Epoch 72/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7203 - acc: 0.5349 - val_loss: 0.8694 - val_acc: 0.2500\n",
            "Epoch 73/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7209 - acc: 0.5349 - val_loss: 0.8678 - val_acc: 0.2500\n",
            "Epoch 74/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7203 - acc: 0.5349 - val_loss: 0.8685 - val_acc: 0.2500\n",
            "Epoch 75/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7202 - acc: 0.5349 - val_loss: 0.8686 - val_acc: 0.2500\n",
            "Epoch 76/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7203 - acc: 0.5349 - val_loss: 0.8680 - val_acc: 0.2500\n",
            "Epoch 77/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7206 - acc: 0.5349 - val_loss: 0.8683 - val_acc: 0.2500\n",
            "Epoch 78/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7198 - acc: 0.5349 - val_loss: 0.8673 - val_acc: 0.2500\n",
            "Epoch 79/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7199 - acc: 0.5349 - val_loss: 0.8659 - val_acc: 0.2500\n",
            "Epoch 80/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7197 - acc: 0.5349 - val_loss: 0.8663 - val_acc: 0.2500\n",
            "Epoch 81/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7199 - acc: 0.5349 - val_loss: 0.8659 - val_acc: 0.2500\n",
            "Epoch 82/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7194 - acc: 0.5349 - val_loss: 0.8665 - val_acc: 0.2500\n",
            "Epoch 83/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7197 - acc: 0.5349 - val_loss: 0.8653 - val_acc: 0.2500\n",
            "Epoch 84/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7196 - acc: 0.5349 - val_loss: 0.8661 - val_acc: 0.2500\n",
            "Epoch 85/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7192 - acc: 0.5349 - val_loss: 0.8652 - val_acc: 0.2500\n",
            "Epoch 86/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7190 - acc: 0.5349 - val_loss: 0.8648 - val_acc: 0.2500\n",
            "Epoch 87/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7191 - acc: 0.5349 - val_loss: 0.8645 - val_acc: 0.2500\n",
            "Epoch 88/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7190 - acc: 0.5349 - val_loss: 0.8651 - val_acc: 0.2500\n",
            "Epoch 89/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7191 - acc: 0.5349 - val_loss: 0.8645 - val_acc: 0.2500\n",
            "Epoch 90/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7191 - acc: 0.5349 - val_loss: 0.8641 - val_acc: 0.2500\n",
            "Epoch 91/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7187 - acc: 0.5349 - val_loss: 0.8640 - val_acc: 0.2500\n",
            "Epoch 92/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7186 - acc: 0.5349 - val_loss: 0.8645 - val_acc: 0.2500\n",
            "Epoch 93/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7187 - acc: 0.5349 - val_loss: 0.8642 - val_acc: 0.2500\n",
            "Epoch 94/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7184 - acc: 0.5349 - val_loss: 0.8639 - val_acc: 0.2500\n",
            "Epoch 95/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7185 - acc: 0.5349 - val_loss: 0.8640 - val_acc: 0.2500\n",
            "Epoch 96/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7184 - acc: 0.5349 - val_loss: 0.8635 - val_acc: 0.2500\n",
            "Epoch 97/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7181 - acc: 0.5349 - val_loss: 0.8630 - val_acc: 0.2500\n",
            "Epoch 98/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7181 - acc: 0.5349 - val_loss: 0.8631 - val_acc: 0.2500\n",
            "Epoch 99/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7186 - acc: 0.5349 - val_loss: 0.8633 - val_acc: 0.2500\n",
            "Epoch 100/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7180 - acc: 0.5349 - val_loss: 0.8622 - val_acc: 0.2500\n",
            "Epoch 101/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7179 - acc: 0.5349 - val_loss: 0.8623 - val_acc: 0.2500\n",
            "Epoch 102/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7179 - acc: 0.5349 - val_loss: 0.8627 - val_acc: 0.2500\n",
            "Epoch 103/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7179 - acc: 0.5349 - val_loss: 0.8623 - val_acc: 0.2500\n",
            "Epoch 104/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7178 - acc: 0.5349 - val_loss: 0.8627 - val_acc: 0.2500\n",
            "Epoch 105/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7178 - acc: 0.5349 - val_loss: 0.8627 - val_acc: 0.2500\n",
            "Epoch 106/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7177 - acc: 0.5349 - val_loss: 0.8624 - val_acc: 0.2500\n",
            "Epoch 107/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7174 - acc: 0.5349 - val_loss: 0.8628 - val_acc: 0.2500\n",
            "Epoch 108/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7176 - acc: 0.5349 - val_loss: 0.8631 - val_acc: 0.2500\n",
            "Epoch 109/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7178 - acc: 0.5465 - val_loss: 0.8623 - val_acc: 0.2500\n",
            "Epoch 110/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7176 - acc: 0.5349 - val_loss: 0.8628 - val_acc: 0.2500\n",
            "Epoch 111/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7174 - acc: 0.5349 - val_loss: 0.8620 - val_acc: 0.2500\n",
            "Epoch 112/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7171 - acc: 0.5349 - val_loss: 0.8627 - val_acc: 0.2500\n",
            "Epoch 113/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7170 - acc: 0.5349 - val_loss: 0.8629 - val_acc: 0.2500\n",
            "Epoch 114/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7169 - acc: 0.5349 - val_loss: 0.8629 - val_acc: 0.2500\n",
            "Epoch 115/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7169 - acc: 0.5349 - val_loss: 0.8625 - val_acc: 0.2500\n",
            "Epoch 116/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7168 - acc: 0.5349 - val_loss: 0.8627 - val_acc: 0.2500\n",
            "Epoch 117/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7166 - acc: 0.5349 - val_loss: 0.8627 - val_acc: 0.2500\n",
            "Epoch 118/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7172 - acc: 0.5349 - val_loss: 0.8625 - val_acc: 0.2500\n",
            "Epoch 119/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7168 - acc: 0.5349 - val_loss: 0.8628 - val_acc: 0.2500\n",
            "Epoch 120/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7167 - acc: 0.5465 - val_loss: 0.8622 - val_acc: 0.2500\n",
            "Epoch 121/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7164 - acc: 0.5349 - val_loss: 0.8626 - val_acc: 0.2500\n",
            "Epoch 122/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7165 - acc: 0.5349 - val_loss: 0.8627 - val_acc: 0.2500\n",
            "Epoch 123/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7166 - acc: 0.5349 - val_loss: 0.8628 - val_acc: 0.2500\n",
            "Epoch 124/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7163 - acc: 0.5349 - val_loss: 0.8623 - val_acc: 0.2500\n",
            "Epoch 125/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7165 - acc: 0.5349 - val_loss: 0.8628 - val_acc: 0.2500\n",
            "Epoch 126/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7161 - acc: 0.5349 - val_loss: 0.8624 - val_acc: 0.2500\n",
            "Epoch 127/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7161 - acc: 0.5349 - val_loss: 0.8625 - val_acc: 0.2500\n",
            "Epoch 128/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7166 - acc: 0.5465 - val_loss: 0.8615 - val_acc: 0.2500\n",
            "Epoch 129/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7159 - acc: 0.5349 - val_loss: 0.8626 - val_acc: 0.2500\n",
            "Epoch 130/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7158 - acc: 0.5349 - val_loss: 0.8627 - val_acc: 0.2500\n",
            "Epoch 131/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7157 - acc: 0.5465 - val_loss: 0.8626 - val_acc: 0.2500\n",
            "Epoch 132/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7156 - acc: 0.5465 - val_loss: 0.8625 - val_acc: 0.2500\n",
            "Epoch 133/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7158 - acc: 0.5349 - val_loss: 0.8630 - val_acc: 0.2500\n",
            "Epoch 134/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7158 - acc: 0.5465 - val_loss: 0.8625 - val_acc: 0.2500\n",
            "Epoch 135/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7158 - acc: 0.5349 - val_loss: 0.8623 - val_acc: 0.2500\n",
            "Epoch 136/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7155 - acc: 0.5349 - val_loss: 0.8625 - val_acc: 0.2500\n",
            "Epoch 137/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7156 - acc: 0.5465 - val_loss: 0.8624 - val_acc: 0.2500\n",
            "Epoch 138/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7153 - acc: 0.5465 - val_loss: 0.8625 - val_acc: 0.2500\n",
            "Epoch 139/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7154 - acc: 0.5349 - val_loss: 0.8630 - val_acc: 0.2500\n",
            "Epoch 140/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7153 - acc: 0.5465 - val_loss: 0.8626 - val_acc: 0.2500\n",
            "Epoch 141/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7153 - acc: 0.5349 - val_loss: 0.8631 - val_acc: 0.2500\n",
            "Epoch 142/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7155 - acc: 0.5465 - val_loss: 0.8620 - val_acc: 0.2500\n",
            "Epoch 143/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7150 - acc: 0.5465 - val_loss: 0.8629 - val_acc: 0.2500\n",
            "Epoch 144/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7149 - acc: 0.5349 - val_loss: 0.8624 - val_acc: 0.2500\n",
            "Epoch 145/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7152 - acc: 0.5349 - val_loss: 0.8626 - val_acc: 0.2500\n",
            "Epoch 146/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7152 - acc: 0.5349 - val_loss: 0.8625 - val_acc: 0.2500\n",
            "Epoch 147/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7156 - acc: 0.5465 - val_loss: 0.8617 - val_acc: 0.2500\n",
            "Epoch 148/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7146 - acc: 0.5465 - val_loss: 0.8624 - val_acc: 0.2500\n",
            "Epoch 149/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7147 - acc: 0.5465 - val_loss: 0.8623 - val_acc: 0.2500\n",
            "Epoch 150/150\n",
            "86/86 [==============================] - 4s 49ms/step - loss: 0.7144 - acc: 0.5465 - val_loss: 0.8612 - val_acc: 0.2500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efc2a061f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O1pRTMMnp0X",
        "colab_type": "code",
        "outputId": "9908f5c2-cbd4-4030-c8bc-d28aaa7177e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "metrics = model2.evaluate(X_test,y_test)\n",
        "print(metrics)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "621/621 [==============================] - 0s 795us/step\n",
            "[3.535203630029675, 0.5378421904000299]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u2YrNTKpVZf",
        "colab_type": "code",
        "outputId": "63dc4cf8-5994-4139-9e2a-205c40c282bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "metrics = model.evaluate(X_test,y_test)\n",
        "print(metrics)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r18/18 [==============================] - 0s 22ms/step\n",
            "[9.742568969726562, 0.3888888955116272]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9qIig8FphSH",
        "colab_type": "code",
        "outputId": "f8a60a71-e18c-4fb2-fe64-9812ca9dba25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "metrics = model3.evaluate(X_test,y_test)\n",
        "print(metrics)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "621/621 [==============================] - 1s 1ms/step\n",
            "[0.7628745698698477, 0.5346215784837658]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVvQQuKqtDJq",
        "colab_type": "code",
        "outputId": "dfa32511-3a7a-47a5-bf73-0ef435d72711",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "metrics = model4.evaluate(X_test,y_test)\n",
        "print(metrics)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r18/18 [==============================] - 1s 31ms/step\n",
            "[0.6619123220443726, 0.6111111044883728]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-yXRREwxkrg",
        "colab_type": "code",
        "outputId": "dc835c30-1574-4a3b-b8dd-7f5b690cf597",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "metrics = model6.evaluate(X_test,y_test)\n",
        "print(metrics)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r18/18 [==============================] - 0s 21ms/step\n",
            "[0.8770436644554138, 0.3888888955116272]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAkKFhsd1Jo0",
        "colab_type": "code",
        "outputId": "5c1bab2f-3316-4fa3-8cde-2806a08db507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# higher epochs version\n",
        "metrics = model6.evaluate(X_test,y_test)\n",
        "print(metrics)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r18/18 [==============================] - 0s 22ms/step\n",
            "[0.8298603892326355, 0.3888888955116272]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}