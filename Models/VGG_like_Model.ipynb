{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG-like Model.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omkarpat/eeg-mood-classification/blob/master/Models/VGG_like_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_sCm971u4dS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d00bcba8-203c-4165-9ab2-a09ee2709007"
      },
      "source": [
        "# Colab settings/mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/My\\ Drive/CSE\\ 240/Project/Data/spectrogram_images/"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: 'gdrive/My Drive/CSE 240/Project/Data/spectrogram_images/'\n",
            "/content/gdrive/My Drive/CSE 240/Project/Data/spectrogram_images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEFSwnTevLwd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43b43242-c8d5-45e0-8642-fa1e5c14e450"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Convolution2D, Conv2D, MaxPooling2D, Lambda, GlobalMaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Activation, AveragePooling2D, Concatenate, SeparableConv2D, MaxPooling3D, Conv3D, DepthwiseConv2D\n",
        "from tensorflow.keras.models import model_from_json"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV0KFC7xvTHM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "188f4b8d-4f03-4073-cce0-dcd6c0a7c066"
      },
      "source": [
        "base_path = \".\"\n",
        "concentration_data_array = None\n",
        "relaxed_data_array = None\n",
        "print(\"loading data from .npy files...\")\n",
        "for filename in os.listdir(base_path):\n",
        "  if \"concentration_array_updated_spectrograms\" in filename and \"final\" not in filename:\n",
        "    print(filename)\n",
        "    concentration_data_array = np.concatenate((concentration_data_array, np.load(filename))) if concentration_data_array is not None else np.load(filename)\n",
        "  if \"relaxed_array_updated_spectrograms\" in filename:\n",
        "    print(filename)\n",
        "    relaxed_data_array = np.concatenate((relaxed_data_array, np.load(filename))) if relaxed_data_array is not None else np.load(filename)\n",
        "print(concentration_data_array.shape, relaxed_data_array.shape)\n",
        "print(len(concentration_data_array), len(relaxed_data_array))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading data from .npy files...\n",
            "concentration_array_updated_spectrograms_1.npy\n",
            "concentration_array_updated_spectrograms_2.npy\n",
            "concentration_array_updated_spectrograms_3.npy\n",
            "concentration_array_updated_spectrograms_4.npy\n",
            "concentration_array_updated_spectrograms_5.npy\n",
            "concentration_array_updated_spectrograms_6.npy\n",
            "relaxed_array_updated_spectrograms_1.npy\n",
            "relaxed_array_updated_spectrograms_2.npy\n",
            "relaxed_array_updated_spectrograms_3.npy\n",
            "relaxed_array_updated_spectrograms_4.npy\n",
            "relaxed_array_updated_spectrograms_5.npy\n",
            "relaxed_array_updated_spectrograms_final.npy\n",
            "(2160, 29, 43, 42) (2124, 29, 43, 42)\n",
            "2160 2124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWjZwiYLypAV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae55d77a-dee9-4b28-c720-ca220fdd3a2d"
      },
      "source": [
        "X = np.concatenate((relaxed_data_array, concentration_data_array))\n",
        "Y = np.concatenate((np.zeros((len(relaxed_data_array),1)),np.ones((len(concentration_data_array),1))))\n",
        "print(X.shape, Y.shape)\n",
        "relaxed_data_array, concentration_data_array = None, None"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4284, 29, 43, 42) (4284, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaQQIZAGy2ej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
        "X, Y = None, None\n",
        "folds = list(StratifiedKFold(n_splits=8, shuffle=True, random_state=1).split(X_train, y_train))\n",
        "#X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.15, random_state=42)\n",
        "#print(X_train.shape, X_test.shape, X_valid.shape, y_train.shape, y_test.shape, y_valid.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVt79b4tzKrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = \"vgg-like\"\n",
        "def get_model():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(input_shape=(29,43,42),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\", data_format='channels_first'))\n",
        "  model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "  #model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "  #model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "  #model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "  #model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "  #model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(units=4096,activation=\"relu\"))\n",
        "\n",
        "  model.add(Dense(units=4096,activation=\"relu\"))\n",
        "  model.add(Dense(units=2, activation=\"softmax\")) \n",
        "\n",
        "  # model.add(Conv2D(64, kernel_size=5, strides=(1,1), padding='valid', activation='relu', input_shape = (29, 43, 42)))\n",
        "  # model.add(Conv2D(128, kernel_size=3, activation='relu'))\n",
        "  # model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\n",
        "  # model.add(Conv2D(256, kernel_size=3, strides=(1,1), padding='valid', activation='relu'))\n",
        "  # model.add(Conv2D(512, kernel_size=2, activation='relu'))\n",
        "  # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  \n",
        "  # model.add(Flatten())\n",
        "  # model.add(Dense(100, activation='relu'))\n",
        "  # model.add(Dense(50, activation='relu'))\n",
        "  # model.add(Dense(1, activation='sigmoid'))\n",
        "  \n",
        "  #sgd = optimizers.SGD(lr=0.000001, momentum=0.7, decay=1e-6)\n",
        "  #model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "  adm = optimizers.Adam(lr=0.0001, decay=1e-6)\n",
        "  model.compile(optimizer=adm, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "  model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiqXkhrOZF7Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "72d7f846-eca4-4c7a-b58a-c0343e1c5074"
      },
      "source": [
        "filepath= model_name + \"-weights-improvement-{epoch:02d}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "model2 = get_model()\n",
        "for j, (train_idx, val_idx) in enumerate(folds):\n",
        "  print('\\nFold ',j)\n",
        "  X_train_cv = X_train[train_idx]\n",
        "  y_train_cv = y_train[train_idx]\n",
        "  X_valid_cv = X_train[val_idx]\n",
        "  y_valid_cv= y_train[val_idx]\n",
        "  # checkpoint\n",
        "  model2.fit(X_train_cv, y_train_cv, validation_data=(X_valid_cv, y_valid_cv), epochs=15, batch_size=32, callbacks=callbacks_list, shuffle=True)\n",
        "score = model2.evaluate(X_test,y_test)\n",
        "print(\"Test set metrics: %s: %.2f%%\" % (model2.metrics_names[1], score[1]*100))\n",
        "model2_json = model2.to_json()\n",
        "with open(model_name + \".json\", \"w\") as json_file:\n",
        "    json_file.write(model2_json)\n",
        "# serialize weights to HDF5\n",
        "model2.save_weights(model_name + \".h5\")\n",
        "print(\"Saved model %s to disk\" % (model_name))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold  0\n",
            "Train on 3185 samples, validate on 456 samples\n",
            "Epoch 1/15\n",
            "3168/3185 [============================>.] - ETA: 0s - loss: 0.7153 - accuracy: 0.5073\n",
            "Epoch 00001: accuracy improved from -inf to 0.50706, saving model to vgg-like-weights-improvement-01.hdf5\n",
            "3185/3185 [==============================] - 18s 6ms/sample - loss: 0.7152 - accuracy: 0.5071 - val_loss: 0.6929 - val_accuracy: 0.5022\n",
            "Epoch 2/15\n",
            "3168/3185 [============================>.] - ETA: 0s - loss: 0.6925 - accuracy: 0.5060\n",
            "Epoch 00002: accuracy did not improve from 0.50706\n",
            "3185/3185 [==============================] - 10s 3ms/sample - loss: 0.6925 - accuracy: 0.5055 - val_loss: 0.6858 - val_accuracy: 0.5482\n",
            "Epoch 3/15\n",
            "3168/3185 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.5114\n",
            "Epoch 00003: accuracy improved from 0.50706 to 0.51115, saving model to vgg-like-weights-improvement-03.hdf5\n",
            "3185/3185 [==============================] - 19s 6ms/sample - loss: 0.6931 - accuracy: 0.5111 - val_loss: 0.6910 - val_accuracy: 0.5110\n",
            "Epoch 4/15\n",
            "3168/3185 [============================>.] - ETA: 0s - loss: 0.6833 - accuracy: 0.5265\n",
            "Epoch 00004: accuracy improved from 0.51115 to 0.52527, saving model to vgg-like-weights-improvement-04.hdf5\n",
            "3185/3185 [==============================] - 17s 5ms/sample - loss: 0.6834 - accuracy: 0.5253 - val_loss: 0.6732 - val_accuracy: 0.5175\n",
            "Epoch 5/15\n",
            "3168/3185 [============================>.] - ETA: 0s - loss: 0.6881 - accuracy: 0.5041\n",
            "Epoch 00005: accuracy did not improve from 0.52527\n",
            "3185/3185 [==============================] - 10s 3ms/sample - loss: 0.6882 - accuracy: 0.5049 - val_loss: 0.6931 - val_accuracy: 0.5110\n",
            "Epoch 6/15\n",
            "3168/3185 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5114\n",
            "Epoch 00006: accuracy did not improve from 0.52527\n",
            "3185/3185 [==============================] - 10s 3ms/sample - loss: 0.6931 - accuracy: 0.5121 - val_loss: 0.6927 - val_accuracy: 0.5110\n",
            "Epoch 7/15\n",
            "3168/3185 [============================>.] - ETA: 0s - loss: 0.6925 - accuracy: 0.5117\n",
            "Epoch 00007: accuracy did not improve from 0.52527\n",
            "3185/3185 [==============================] - 10s 3ms/sample - loss: 0.6925 - accuracy: 0.5121 - val_loss: 0.6923 - val_accuracy: 0.5110\n",
            "Epoch 8/15\n",
            "3168/3185 [============================>.] - ETA: 0s - loss: 0.6870 - accuracy: 0.5142\n",
            "Epoch 00008: accuracy did not improve from 0.52527\n",
            "3185/3185 [==============================] - 10s 3ms/sample - loss: 0.6870 - accuracy: 0.5140 - val_loss: 0.6929 - val_accuracy: 0.5110\n",
            "Epoch 9/15\n",
            "3168/3185 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.5104\n",
            "Epoch 00009: accuracy did not improve from 0.52527\n",
            "3185/3185 [==============================] - 10s 3ms/sample - loss: 0.6930 - accuracy: 0.5099 - val_loss: 0.6928 - val_accuracy: 0.5110\n",
            "Epoch 10/15\n",
            "3168/3185 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.4962\n",
            "Epoch 00010: accuracy did not improve from 0.52527\n",
            "3185/3185 [==============================] - 10s 3ms/sample - loss: 0.6931 - accuracy: 0.4970 - val_loss: 0.6919 - val_accuracy: 0.5110\n",
            "Epoch 11/15\n",
            "3168/3185 [============================>.] - ETA: 0s - loss: 0.6880 - accuracy: 0.5167\n",
            "Epoch 00011: accuracy did not improve from 0.52527\n",
            "3185/3185 [==============================] - 10s 3ms/sample - loss: 0.6881 - accuracy: 0.5162 - val_loss: 0.6735 - val_accuracy: 0.5110\n",
            "Epoch 12/15\n",
            "3168/3185 [============================>.] - ETA: 0s - loss: 0.6812 - accuracy: 0.5170\n",
            "Epoch 00012: accuracy did not improve from 0.52527\n",
            "3185/3185 [==============================] - 10s 3ms/sample - loss: 0.6813 - accuracy: 0.5162 - val_loss: 0.6926 - val_accuracy: 0.5110\n",
            "Epoch 13/15\n",
            "3168/3185 [============================>.] - ETA: 0s - loss: 0.6818 - accuracy: 0.5088\n",
            "Epoch 00013: accuracy did not improve from 0.52527\n",
            "3185/3185 [==============================] - 10s 3ms/sample - loss: 0.6819 - accuracy: 0.5093 - val_loss: 0.6733 - val_accuracy: 0.5154\n",
            "Epoch 14/15\n",
            "3168/3185 [============================>.] - ETA: 0s - loss: 0.6783 - accuracy: 0.5246\n",
            "Epoch 00014: accuracy did not improve from 0.52527\n",
            "3185/3185 [==============================] - 10s 3ms/sample - loss: 0.6783 - accuracy: 0.5243 - val_loss: 0.6927 - val_accuracy: 0.5132\n",
            "Epoch 15/15\n",
            "3168/3185 [============================>.] - ETA: 0s - loss: 0.6861 - accuracy: 0.5189\n",
            "Epoch 00015: accuracy did not improve from 0.52527\n",
            "3185/3185 [==============================] - 10s 3ms/sample - loss: 0.6862 - accuracy: 0.5184 - val_loss: 0.6731 - val_accuracy: 0.5197\n",
            "\n",
            "Fold  1\n",
            "Train on 3186 samples, validate on 455 samples\n",
            "Epoch 1/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6771 - accuracy: 0.5155\n",
            "Epoch 00001: accuracy did not improve from 0.52527\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6772 - accuracy: 0.5160 - val_loss: 0.6799 - val_accuracy: 0.5187\n",
            "Epoch 2/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6776 - accuracy: 0.5155\n",
            "Epoch 00002: accuracy did not improve from 0.52527\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6777 - accuracy: 0.5151 - val_loss: 0.6808 - val_accuracy: 0.5121\n",
            "Epoch 3/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6771 - accuracy: 0.4949\n",
            "Epoch 00003: accuracy did not improve from 0.52527\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6772 - accuracy: 0.4962 - val_loss: 0.6808 - val_accuracy: 0.5121\n",
            "Epoch 4/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6772 - accuracy: 0.5079\n",
            "Epoch 00004: accuracy did not improve from 0.52527\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6773 - accuracy: 0.5085 - val_loss: 0.6797 - val_accuracy: 0.5209\n",
            "Epoch 5/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5196\n",
            "Epoch 00005: accuracy did not improve from 0.52527\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6932 - accuracy: 0.5195 - val_loss: 0.6910 - val_accuracy: 0.5121\n",
            "Epoch 6/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6798 - accuracy: 0.5230\n",
            "Epoch 00006: accuracy did not improve from 0.52527\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6800 - accuracy: 0.5217 - val_loss: 0.6814 - val_accuracy: 0.5055\n",
            "Epoch 7/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6810 - accuracy: 0.5047\n",
            "Epoch 00007: accuracy did not improve from 0.52527\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6811 - accuracy: 0.5050 - val_loss: 0.6927 - val_accuracy: 0.5121\n",
            "Epoch 8/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6964 - accuracy: 0.5107\n",
            "Epoch 00008: accuracy did not improve from 0.52527\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6964 - accuracy: 0.5097 - val_loss: 0.6926 - val_accuracy: 0.5121\n",
            "Epoch 9/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.5032\n",
            "Epoch 00009: accuracy did not improve from 0.52527\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6927 - accuracy: 0.5035 - val_loss: 0.6929 - val_accuracy: 0.5121\n",
            "Epoch 10/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6929 - accuracy: 0.5117\n",
            "Epoch 00010: accuracy did not improve from 0.52527\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6930 - accuracy: 0.5107 - val_loss: 0.6930 - val_accuracy: 0.5121\n",
            "Epoch 11/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5060\n",
            "Epoch 00011: accuracy did not improve from 0.52527\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6931 - accuracy: 0.5069 - val_loss: 0.6928 - val_accuracy: 0.5121\n",
            "Epoch 12/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.5114\n",
            "Epoch 00012: accuracy did not improve from 0.52527\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6927 - accuracy: 0.5119 - val_loss: 0.6918 - val_accuracy: 0.5121\n",
            "Epoch 13/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6918 - accuracy: 0.5152\n",
            "Epoch 00013: accuracy did not improve from 0.52527\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6918 - accuracy: 0.5157 - val_loss: 0.6915 - val_accuracy: 0.4989\n",
            "Epoch 14/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6850 - accuracy: 0.5063\n",
            "Epoch 00014: accuracy did not improve from 0.52527\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6870 - accuracy: 0.5060 - val_loss: 0.6807 - val_accuracy: 0.5121\n",
            "Epoch 15/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.5079\n",
            "Epoch 00015: accuracy did not improve from 0.52527\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6927 - accuracy: 0.5075 - val_loss: 0.6923 - val_accuracy: 0.5121\n",
            "\n",
            "Fold  2\n",
            "Train on 3186 samples, validate on 455 samples\n",
            "Epoch 1/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6924 - accuracy: 0.5142\n",
            "Epoch 00001: accuracy did not improve from 0.52527\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6925 - accuracy: 0.5132 - val_loss: 0.6939 - val_accuracy: 0.5121\n",
            "Epoch 2/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.5016\n",
            "Epoch 00002: accuracy did not improve from 0.52527\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6927 - accuracy: 0.5022 - val_loss: 0.6915 - val_accuracy: 0.5121\n",
            "Epoch 3/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6921 - accuracy: 0.5110\n",
            "Epoch 00003: accuracy did not improve from 0.52527\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6921 - accuracy: 0.5110 - val_loss: 0.6907 - val_accuracy: 0.5121\n",
            "Epoch 4/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6910 - accuracy: 0.5107\n",
            "Epoch 00004: accuracy did not improve from 0.52527\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6910 - accuracy: 0.5110 - val_loss: 0.6862 - val_accuracy: 0.5143\n",
            "Epoch 5/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6808 - accuracy: 0.5234\n",
            "Epoch 00005: accuracy did not improve from 0.52527\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6806 - accuracy: 0.5235 - val_loss: 0.6699 - val_accuracy: 0.5319\n",
            "Epoch 6/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6771 - accuracy: 0.5294\n",
            "Epoch 00006: accuracy improved from 0.52527 to 0.52919, saving model to vgg-like-weights-improvement-06.hdf5\n",
            "3186/3186 [==============================] - 13s 4ms/sample - loss: 0.6772 - accuracy: 0.5292 - val_loss: 0.6772 - val_accuracy: 0.5165\n",
            "Epoch 7/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6903 - accuracy: 0.5126\n",
            "Epoch 00007: accuracy did not improve from 0.52919\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6904 - accuracy: 0.5119 - val_loss: 0.6929 - val_accuracy: 0.5121\n",
            "Epoch 8/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.5114\n",
            "Epoch 00008: accuracy did not improve from 0.52919\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6930 - accuracy: 0.5119 - val_loss: 0.6928 - val_accuracy: 0.5121\n",
            "Epoch 9/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6922 - accuracy: 0.5120\n",
            "Epoch 00009: accuracy did not improve from 0.52919\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6922 - accuracy: 0.5119 - val_loss: 0.6929 - val_accuracy: 0.5121\n",
            "Epoch 10/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6920 - accuracy: 0.5060\n",
            "Epoch 00010: accuracy did not improve from 0.52919\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6919 - accuracy: 0.5056 - val_loss: 0.6823 - val_accuracy: 0.5143\n",
            "Epoch 11/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6825 - accuracy: 0.5082\n",
            "Epoch 00011: accuracy did not improve from 0.52919\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6825 - accuracy: 0.5088 - val_loss: 0.6866 - val_accuracy: 0.5121\n",
            "Epoch 12/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6812 - accuracy: 0.5003\n",
            "Epoch 00012: accuracy did not improve from 0.52919\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6811 - accuracy: 0.5000 - val_loss: 0.6704 - val_accuracy: 0.5209\n",
            "Epoch 13/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6788 - accuracy: 0.5079\n",
            "Epoch 00013: accuracy did not improve from 0.52919\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6789 - accuracy: 0.5078 - val_loss: 0.6707 - val_accuracy: 0.5121\n",
            "Epoch 14/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6786 - accuracy: 0.5104\n",
            "Epoch 00014: accuracy did not improve from 0.52919\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6787 - accuracy: 0.5091 - val_loss: 0.6703 - val_accuracy: 0.4945\n",
            "Epoch 15/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6784 - accuracy: 0.5227\n",
            "Epoch 00015: accuracy did not improve from 0.52919\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6785 - accuracy: 0.5229 - val_loss: 0.6705 - val_accuracy: 0.5121\n",
            "\n",
            "Fold  3\n",
            "Train on 3186 samples, validate on 455 samples\n",
            "Epoch 1/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6779 - accuracy: 0.5139\n",
            "Epoch 00001: accuracy did not improve from 0.52919\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6780 - accuracy: 0.5141 - val_loss: 0.6746 - val_accuracy: 0.5319\n",
            "Epoch 2/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6780 - accuracy: 0.5110\n",
            "Epoch 00002: accuracy did not improve from 0.52919\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6780 - accuracy: 0.5116 - val_loss: 0.6749 - val_accuracy: 0.5121\n",
            "Epoch 3/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6779 - accuracy: 0.5063\n",
            "Epoch 00003: accuracy did not improve from 0.52919\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6777 - accuracy: 0.5072 - val_loss: 0.6749 - val_accuracy: 0.5121\n",
            "Epoch 4/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6784 - accuracy: 0.5120\n",
            "Epoch 00004: accuracy did not improve from 0.52919\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6785 - accuracy: 0.5119 - val_loss: 0.6811 - val_accuracy: 0.5121\n",
            "Epoch 5/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6784 - accuracy: 0.5060\n",
            "Epoch 00005: accuracy did not improve from 0.52919\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6783 - accuracy: 0.5066 - val_loss: 0.6748 - val_accuracy: 0.5121\n",
            "Epoch 6/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6776 - accuracy: 0.5057\n",
            "Epoch 00006: accuracy did not improve from 0.52919\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6775 - accuracy: 0.5066 - val_loss: 0.6733 - val_accuracy: 0.5121\n",
            "Epoch 7/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6784 - accuracy: 0.5145\n",
            "Epoch 00007: accuracy did not improve from 0.52919\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6783 - accuracy: 0.5141 - val_loss: 0.6754 - val_accuracy: 0.5121\n",
            "Epoch 8/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6773 - accuracy: 0.5306\n",
            "Epoch 00008: accuracy improved from 0.52919 to 0.53202, saving model to vgg-like-weights-improvement-08.hdf5\n",
            "3186/3186 [==============================] - 14s 4ms/sample - loss: 0.6765 - accuracy: 0.5320 - val_loss: 0.6746 - val_accuracy: 0.5319\n",
            "Epoch 9/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6756 - accuracy: 0.5312\n",
            "Epoch 00009: accuracy did not improve from 0.53202\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6757 - accuracy: 0.5308 - val_loss: 0.6758 - val_accuracy: 0.5187\n",
            "Epoch 10/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6758 - accuracy: 0.5319\n",
            "Epoch 00010: accuracy did not improve from 0.53202\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6759 - accuracy: 0.5320 - val_loss: 0.6741 - val_accuracy: 0.5209\n",
            "Epoch 11/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6737 - accuracy: 0.5477\n",
            "Epoch 00011: accuracy improved from 0.53202 to 0.54739, saving model to vgg-like-weights-improvement-11.hdf5\n",
            "3186/3186 [==============================] - 14s 4ms/sample - loss: 0.6736 - accuracy: 0.5474 - val_loss: 0.6719 - val_accuracy: 0.5407\n",
            "Epoch 12/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6759 - accuracy: 0.5284\n",
            "Epoch 00012: accuracy did not improve from 0.54739\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6758 - accuracy: 0.5289 - val_loss: 0.6745 - val_accuracy: 0.5187\n",
            "Epoch 13/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6734 - accuracy: 0.5518\n",
            "Epoch 00013: accuracy improved from 0.54739 to 0.55179, saving model to vgg-like-weights-improvement-13.hdf5\n",
            "3186/3186 [==============================] - 14s 4ms/sample - loss: 0.6735 - accuracy: 0.5518 - val_loss: 0.6748 - val_accuracy: 0.5209\n",
            "Epoch 14/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6779 - accuracy: 0.5243\n",
            "Epoch 00014: accuracy did not improve from 0.55179\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6776 - accuracy: 0.5254 - val_loss: 0.6755 - val_accuracy: 0.5231\n",
            "Epoch 15/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6762 - accuracy: 0.5401\n",
            "Epoch 00015: accuracy did not improve from 0.55179\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6762 - accuracy: 0.5402 - val_loss: 0.6763 - val_accuracy: 0.5165\n",
            "\n",
            "Fold  4\n",
            "Train on 3186 samples, validate on 455 samples\n",
            "Epoch 1/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6706 - accuracy: 0.5606\n",
            "Epoch 00001: accuracy improved from 0.55179 to 0.56026, saving model to vgg-like-weights-improvement-01.hdf5\n",
            "3186/3186 [==============================] - 14s 4ms/sample - loss: 0.6705 - accuracy: 0.5603 - val_loss: 0.6773 - val_accuracy: 0.5231\n",
            "Epoch 2/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6768 - accuracy: 0.5249\n",
            "Epoch 00002: accuracy did not improve from 0.56026\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6769 - accuracy: 0.5242 - val_loss: 0.6829 - val_accuracy: 0.5011\n",
            "Epoch 3/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6865 - accuracy: 0.5306\n",
            "Epoch 00003: accuracy did not improve from 0.56026\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6865 - accuracy: 0.5308 - val_loss: 0.6903 - val_accuracy: 0.5055\n",
            "Epoch 4/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.5120\n",
            "Epoch 00004: accuracy did not improve from 0.56026\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6930 - accuracy: 0.5122 - val_loss: 0.6907 - val_accuracy: 0.5121\n",
            "Epoch 5/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6832 - accuracy: 0.5073\n",
            "Epoch 00005: accuracy did not improve from 0.56026\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6831 - accuracy: 0.5063 - val_loss: 0.6813 - val_accuracy: 0.5121\n",
            "Epoch 6/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6773 - accuracy: 0.5101\n",
            "Epoch 00006: accuracy did not improve from 0.56026\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6774 - accuracy: 0.5100 - val_loss: 0.6822 - val_accuracy: 0.5121\n",
            "Epoch 7/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6767 - accuracy: 0.5107\n",
            "Epoch 00007: accuracy did not improve from 0.56026\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6768 - accuracy: 0.5107 - val_loss: 0.6825 - val_accuracy: 0.5121\n",
            "Epoch 8/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6779 - accuracy: 0.5054\n",
            "Epoch 00008: accuracy did not improve from 0.56026\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6778 - accuracy: 0.5053 - val_loss: 0.6835 - val_accuracy: 0.5209\n",
            "Epoch 9/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6769 - accuracy: 0.5117\n",
            "Epoch 00009: accuracy did not improve from 0.56026\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6770 - accuracy: 0.5113 - val_loss: 0.6839 - val_accuracy: 0.5297\n",
            "Epoch 10/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6765 - accuracy: 0.5372\n",
            "Epoch 00010: accuracy did not improve from 0.56026\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6766 - accuracy: 0.5370 - val_loss: 0.7228 - val_accuracy: 0.5121\n",
            "Epoch 11/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6790 - accuracy: 0.5167\n",
            "Epoch 00011: accuracy did not improve from 0.56026\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6791 - accuracy: 0.5160 - val_loss: 0.6809 - val_accuracy: 0.5582\n",
            "Epoch 12/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6775 - accuracy: 0.5379\n",
            "Epoch 00012: accuracy did not improve from 0.56026\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6776 - accuracy: 0.5370 - val_loss: 0.6807 - val_accuracy: 0.5165\n",
            "Epoch 13/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6765 - accuracy: 0.5186\n",
            "Epoch 00013: accuracy did not improve from 0.56026\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6764 - accuracy: 0.5198 - val_loss: 0.6803 - val_accuracy: 0.5385\n",
            "Epoch 14/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6732 - accuracy: 0.5546\n",
            "Epoch 00014: accuracy did not improve from 0.56026\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6735 - accuracy: 0.5546 - val_loss: 0.6829 - val_accuracy: 0.5451\n",
            "Epoch 15/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6751 - accuracy: 0.5404\n",
            "Epoch 00015: accuracy did not improve from 0.56026\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6752 - accuracy: 0.5402 - val_loss: 0.6803 - val_accuracy: 0.5253\n",
            "\n",
            "Fold  5\n",
            "Train on 3186 samples, validate on 455 samples\n",
            "Epoch 1/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6753 - accuracy: 0.5316\n",
            "Epoch 00001: accuracy did not improve from 0.56026\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6752 - accuracy: 0.5317 - val_loss: 0.6878 - val_accuracy: 0.5143\n",
            "Epoch 2/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6734 - accuracy: 0.5372\n",
            "Epoch 00002: accuracy did not improve from 0.56026\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6735 - accuracy: 0.5370 - val_loss: 0.6786 - val_accuracy: 0.5231\n",
            "Epoch 3/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6748 - accuracy: 0.5470\n",
            "Epoch 00003: accuracy did not improve from 0.56026\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6749 - accuracy: 0.5458 - val_loss: 0.6753 - val_accuracy: 0.5341\n",
            "Epoch 4/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6737 - accuracy: 0.5679\n",
            "Epoch 00004: accuracy improved from 0.56026 to 0.56780, saving model to vgg-like-weights-improvement-04.hdf5\n",
            "3186/3186 [==============================] - 14s 4ms/sample - loss: 0.6737 - accuracy: 0.5678 - val_loss: 0.6710 - val_accuracy: 0.5802\n",
            "Epoch 5/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6705 - accuracy: 0.5571\n",
            "Epoch 00005: accuracy did not improve from 0.56780\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6702 - accuracy: 0.5568 - val_loss: 0.6696 - val_accuracy: 0.5429\n",
            "Epoch 6/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6713 - accuracy: 0.5732\n",
            "Epoch 00006: accuracy improved from 0.56780 to 0.57250, saving model to vgg-like-weights-improvement-06.hdf5\n",
            "3186/3186 [==============================] - 15s 5ms/sample - loss: 0.6716 - accuracy: 0.5725 - val_loss: 0.6742 - val_accuracy: 0.5385\n",
            "Epoch 7/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6666 - accuracy: 0.5650\n",
            "Epoch 00007: accuracy did not improve from 0.57250\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6666 - accuracy: 0.5647 - val_loss: 0.6732 - val_accuracy: 0.5407\n",
            "Epoch 8/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6636 - accuracy: 0.5707\n",
            "Epoch 00008: accuracy did not improve from 0.57250\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6637 - accuracy: 0.5716 - val_loss: 0.6664 - val_accuracy: 0.5516\n",
            "Epoch 9/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6597 - accuracy: 0.5874\n",
            "Epoch 00009: accuracy improved from 0.57250 to 0.58788, saving model to vgg-like-weights-improvement-09.hdf5\n",
            "3186/3186 [==============================] - 14s 4ms/sample - loss: 0.6597 - accuracy: 0.5879 - val_loss: 0.6688 - val_accuracy: 0.5495\n",
            "Epoch 10/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6664 - accuracy: 0.5622\n",
            "Epoch 00010: accuracy did not improve from 0.58788\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6664 - accuracy: 0.5628 - val_loss: 0.6683 - val_accuracy: 0.5648\n",
            "Epoch 11/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6593 - accuracy: 0.5878\n",
            "Epoch 00011: accuracy improved from 0.58788 to 0.58851, saving model to vgg-like-weights-improvement-11.hdf5\n",
            "3186/3186 [==============================] - 14s 4ms/sample - loss: 0.6592 - accuracy: 0.5885 - val_loss: 0.6674 - val_accuracy: 0.5736\n",
            "Epoch 12/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6544 - accuracy: 0.5900\n",
            "Epoch 00012: accuracy improved from 0.58851 to 0.58945, saving model to vgg-like-weights-improvement-12.hdf5\n",
            "3186/3186 [==============================] - 15s 5ms/sample - loss: 0.6545 - accuracy: 0.5895 - val_loss: 0.6679 - val_accuracy: 0.5516\n",
            "Epoch 13/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6460 - accuracy: 0.6140\n",
            "Epoch 00013: accuracy improved from 0.58945 to 0.61299, saving model to vgg-like-weights-improvement-13.hdf5\n",
            "3186/3186 [==============================] - 15s 5ms/sample - loss: 0.6461 - accuracy: 0.6130 - val_loss: 0.6731 - val_accuracy: 0.5341\n",
            "Epoch 14/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6437 - accuracy: 0.6162\n",
            "Epoch 00014: accuracy improved from 0.61299 to 0.61645, saving model to vgg-like-weights-improvement-14.hdf5\n",
            "3186/3186 [==============================] - 19s 6ms/sample - loss: 0.6433 - accuracy: 0.6164 - val_loss: 0.6694 - val_accuracy: 0.5560\n",
            "Epoch 15/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6330 - accuracy: 0.6342\n",
            "Epoch 00015: accuracy improved from 0.61645 to 0.63434, saving model to vgg-like-weights-improvement-15.hdf5\n",
            "3186/3186 [==============================] - 15s 5ms/sample - loss: 0.6331 - accuracy: 0.6343 - val_loss: 0.6658 - val_accuracy: 0.5670\n",
            "\n",
            "Fold  6\n",
            "Train on 3186 samples, validate on 455 samples\n",
            "Epoch 1/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6276 - accuracy: 0.6373\n",
            "Epoch 00001: accuracy improved from 0.63434 to 0.63685, saving model to vgg-like-weights-improvement-01.hdf5\n",
            "3186/3186 [==============================] - 15s 5ms/sample - loss: 0.6276 - accuracy: 0.6368 - val_loss: 0.6148 - val_accuracy: 0.6725\n",
            "Epoch 2/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6316 - accuracy: 0.6326\n",
            "Epoch 00002: accuracy did not improve from 0.63685\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6318 - accuracy: 0.6325 - val_loss: 0.6428 - val_accuracy: 0.6176\n",
            "Epoch 3/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6464 - accuracy: 0.6575\n",
            "Epoch 00003: accuracy improved from 0.63685 to 0.65756, saving model to vgg-like-weights-improvement-03.hdf5\n",
            "3186/3186 [==============================] - 16s 5ms/sample - loss: 0.6464 - accuracy: 0.6576 - val_loss: 0.6693 - val_accuracy: 0.5956\n",
            "Epoch 4/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6482 - accuracy: 0.6070\n",
            "Epoch 00004: accuracy did not improve from 0.65756\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.6488 - accuracy: 0.6077 - val_loss: 0.6371 - val_accuracy: 0.6484\n",
            "Epoch 5/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.6077 - accuracy: 0.6670\n",
            "Epoch 00005: accuracy improved from 0.65756 to 0.66698, saving model to vgg-like-weights-improvement-05.hdf5\n",
            "3186/3186 [==============================] - 13s 4ms/sample - loss: 0.6078 - accuracy: 0.6670 - val_loss: 0.6256 - val_accuracy: 0.6462\n",
            "Epoch 6/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.5693 - accuracy: 0.7020\n",
            "Epoch 00006: accuracy improved from 0.66698 to 0.70182, saving model to vgg-like-weights-improvement-06.hdf5\n",
            "3186/3186 [==============================] - 17s 5ms/sample - loss: 0.5691 - accuracy: 0.7018 - val_loss: 0.6595 - val_accuracy: 0.6264\n",
            "Epoch 7/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.5341 - accuracy: 0.7273\n",
            "Epoch 00007: accuracy improved from 0.70182 to 0.72662, saving model to vgg-like-weights-improvement-07.hdf5\n",
            "3186/3186 [==============================] - 14s 4ms/sample - loss: 0.5344 - accuracy: 0.7266 - val_loss: 0.6969 - val_accuracy: 0.5736\n",
            "Epoch 8/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.4931 - accuracy: 0.7614\n",
            "Epoch 00008: accuracy improved from 0.72662 to 0.76146, saving model to vgg-like-weights-improvement-08.hdf5\n",
            "3186/3186 [==============================] - 14s 5ms/sample - loss: 0.4936 - accuracy: 0.7615 - val_loss: 0.6869 - val_accuracy: 0.5934\n",
            "Epoch 9/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.4549 - accuracy: 0.7835\n",
            "Epoch 00009: accuracy improved from 0.76146 to 0.78343, saving model to vgg-like-weights-improvement-09.hdf5\n",
            "3186/3186 [==============================] - 14s 4ms/sample - loss: 0.4550 - accuracy: 0.7834 - val_loss: 0.7220 - val_accuracy: 0.6264\n",
            "Epoch 10/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.3933 - accuracy: 0.8188\n",
            "Epoch 00010: accuracy improved from 0.78343 to 0.81921, saving model to vgg-like-weights-improvement-10.hdf5\n",
            "3186/3186 [==============================] - 14s 4ms/sample - loss: 0.3926 - accuracy: 0.8192 - val_loss: 1.0098 - val_accuracy: 0.6000\n",
            "Epoch 11/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.3368 - accuracy: 0.8526\n",
            "Epoch 00011: accuracy improved from 0.81921 to 0.85217, saving model to vgg-like-weights-improvement-11.hdf5\n",
            "3186/3186 [==============================] - 14s 4ms/sample - loss: 0.3372 - accuracy: 0.8522 - val_loss: 0.8846 - val_accuracy: 0.6220\n",
            "Epoch 12/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.2757 - accuracy: 0.8920\n",
            "Epoch 00012: accuracy improved from 0.85217 to 0.89140, saving model to vgg-like-weights-improvement-12.hdf5\n",
            "3186/3186 [==============================] - 15s 5ms/sample - loss: 0.2771 - accuracy: 0.8914 - val_loss: 0.9882 - val_accuracy: 0.5978\n",
            "Epoch 13/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.2163 - accuracy: 0.9141\n",
            "Epoch 00013: accuracy improved from 0.89140 to 0.91431, saving model to vgg-like-weights-improvement-13.hdf5\n",
            "3186/3186 [==============================] - 14s 4ms/sample - loss: 0.2157 - accuracy: 0.9143 - val_loss: 1.2751 - val_accuracy: 0.6264\n",
            "Epoch 14/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.1835 - accuracy: 0.9230\n",
            "Epoch 00014: accuracy improved from 0.91431 to 0.92279, saving model to vgg-like-weights-improvement-14.hdf5\n",
            "3186/3186 [==============================] - 15s 5ms/sample - loss: 0.1843 - accuracy: 0.9228 - val_loss: 1.1399 - val_accuracy: 0.6264\n",
            "Epoch 15/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.1485 - accuracy: 0.9457\n",
            "Epoch 00015: accuracy improved from 0.92279 to 0.94601, saving model to vgg-like-weights-improvement-15.hdf5\n",
            "3186/3186 [==============================] - 16s 5ms/sample - loss: 0.1480 - accuracy: 0.9460 - val_loss: 1.3414 - val_accuracy: 0.6132\n",
            "\n",
            "Fold  7\n",
            "Train on 3186 samples, validate on 455 samples\n",
            "Epoch 1/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.2426 - accuracy: 0.9189\n",
            "Epoch 00001: accuracy did not improve from 0.94601\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.2424 - accuracy: 0.9190 - val_loss: 0.1482 - val_accuracy: 0.9451\n",
            "Epoch 2/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.1649 - accuracy: 0.9331\n",
            "Epoch 00002: accuracy did not improve from 0.94601\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.1641 - accuracy: 0.9335 - val_loss: 0.1659 - val_accuracy: 0.9363\n",
            "Epoch 3/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.1172 - accuracy: 0.9599\n",
            "Epoch 00003: accuracy improved from 0.94601 to 0.95951, saving model to vgg-like-weights-improvement-03.hdf5\n",
            "3186/3186 [==============================] - 13s 4ms/sample - loss: 0.1179 - accuracy: 0.9595 - val_loss: 0.1762 - val_accuracy: 0.9429\n",
            "Epoch 4/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.1029 - accuracy: 0.9646\n",
            "Epoch 00004: accuracy improved from 0.95951 to 0.96422, saving model to vgg-like-weights-improvement-04.hdf5\n",
            "3186/3186 [==============================] - 15s 5ms/sample - loss: 0.1036 - accuracy: 0.9642 - val_loss: 0.2104 - val_accuracy: 0.9077\n",
            "Epoch 5/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.0594 - accuracy: 0.9792\n",
            "Epoch 00005: accuracy improved from 0.96422 to 0.97928, saving model to vgg-like-weights-improvement-05.hdf5\n",
            "3186/3186 [==============================] - 15s 5ms/sample - loss: 0.0591 - accuracy: 0.9793 - val_loss: 0.3755 - val_accuracy: 0.8835\n",
            "Epoch 6/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.0594 - accuracy: 0.9807\n",
            "Epoch 00006: accuracy improved from 0.97928 to 0.98085, saving model to vgg-like-weights-improvement-06.hdf5\n",
            "3186/3186 [==============================] - 14s 4ms/sample - loss: 0.0591 - accuracy: 0.9809 - val_loss: 0.3550 - val_accuracy: 0.8945\n",
            "Epoch 7/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.0567 - accuracy: 0.9795\n",
            "Epoch 00007: accuracy did not improve from 0.98085\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.0581 - accuracy: 0.9790 - val_loss: 0.3866 - val_accuracy: 0.8835\n",
            "Epoch 8/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.0589 - accuracy: 0.9785\n",
            "Epoch 00008: accuracy did not improve from 0.98085\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.0586 - accuracy: 0.9787 - val_loss: 0.4251 - val_accuracy: 0.8440\n",
            "Epoch 9/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.0451 - accuracy: 0.9842\n",
            "Epoch 00009: accuracy improved from 0.98085 to 0.98368, saving model to vgg-like-weights-improvement-09.hdf5\n",
            "3186/3186 [==============================] - 13s 4ms/sample - loss: 0.0460 - accuracy: 0.9837 - val_loss: 0.3177 - val_accuracy: 0.9011\n",
            "Epoch 10/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.0409 - accuracy: 0.9855\n",
            "Epoch 00010: accuracy improved from 0.98368 to 0.98556, saving model to vgg-like-weights-improvement-10.hdf5\n",
            "3186/3186 [==============================] - 13s 4ms/sample - loss: 0.0408 - accuracy: 0.9856 - val_loss: 0.3943 - val_accuracy: 0.8901\n",
            "Epoch 11/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 0.9905\n",
            "Epoch 00011: accuracy improved from 0.98556 to 0.99058, saving model to vgg-like-weights-improvement-11.hdf5\n",
            "3186/3186 [==============================] - 14s 4ms/sample - loss: 0.0318 - accuracy: 0.9906 - val_loss: 0.3419 - val_accuracy: 0.8857\n",
            "Epoch 12/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9905\n",
            "Epoch 00012: accuracy did not improve from 0.99058\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.0289 - accuracy: 0.9903 - val_loss: 0.5727 - val_accuracy: 0.8681\n",
            "Epoch 13/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.0313 - accuracy: 0.9890\n",
            "Epoch 00013: accuracy did not improve from 0.99058\n",
            "3186/3186 [==============================] - 10s 3ms/sample - loss: 0.0312 - accuracy: 0.9890 - val_loss: 0.5073 - val_accuracy: 0.8945\n",
            "Epoch 14/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9915\n",
            "Epoch 00014: accuracy improved from 0.99058 to 0.99153, saving model to vgg-like-weights-improvement-14.hdf5\n",
            "3186/3186 [==============================] - 14s 4ms/sample - loss: 0.0211 - accuracy: 0.9915 - val_loss: 0.5681 - val_accuracy: 0.8769\n",
            "Epoch 15/15\n",
            "3168/3186 [============================>.] - ETA: 0s - loss: 0.0222 - accuracy: 0.9937\n",
            "Epoch 00015: accuracy improved from 0.99153 to 0.99372, saving model to vgg-like-weights-improvement-15.hdf5\n",
            "3186/3186 [==============================] - 15s 5ms/sample - loss: 0.0221 - accuracy: 0.9937 - val_loss: 0.4851 - val_accuracy: 0.8615\n",
            "643/643 [==============================] - 1s 1ms/sample - loss: 2.5430 - accuracy: 0.5583\n",
            "Test set metrics: accuracy: 55.83%\n",
            "Saved model vgg-like to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvlFhrdphxaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load json and create model\n",
        "json_file = open(model_name+ '.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(model_name + \".h5\")\n",
        "print(\"Loaded model from disk\")\n",
        "\n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(X_test,y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtGPmLgHN1C-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}