{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG-like Model.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omkarpat/eeg-mood-classification/blob/master/Models/VGG_like_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_sCm971u4dS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "da239b71-3b72-473b-b1cd-030137cf90a5"
      },
      "source": [
        "# Colab settings/mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/My\\ Drive/CSE\\ 240/Project/Data/spectrogram_images/"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: 'gdrive/My Drive/CSE 240/Project/Data/spectrogram_images/'\n",
            "/content/gdrive/My Drive/CSE 240/Project/Data/spectrogram_images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEFSwnTevLwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Convolution2D, Conv2D, MaxPooling2D, Lambda, GlobalMaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Activation, AveragePooling2D, Concatenate, SeparableConv2D, MaxPooling3D, Conv3D, DepthwiseConv2D\n",
        "from tensorflow.keras.models import model_from_json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV0KFC7xvTHM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "edc06a7b-27fc-4465-de85-350ffe930359"
      },
      "source": [
        "base_path = \".\"\n",
        "concentration_data_array = None\n",
        "relaxed_data_array = None\n",
        "print(\"loading data from .npy files...\")\n",
        "for filename in os.listdir(base_path):\n",
        "  if \"concentration_array_updated_spectrograms\" in filename and \"final\" not in filename:\n",
        "    print(filename)\n",
        "    concentration_data_array = np.concatenate((concentration_data_array, np.load(filename))) if concentration_data_array is not None else np.load(filename)\n",
        "  if \"relaxed_array_updated_spectrograms\" in filename:\n",
        "    print(filename)\n",
        "    relaxed_data_array = np.concatenate((relaxed_data_array, np.load(filename))) if relaxed_data_array is not None else np.load(filename)\n",
        "print(concentration_data_array.shape, relaxed_data_array.shape)\n",
        "print(len(concentration_data_array), len(relaxed_data_array))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading data from .npy files...\n",
            "concentration_array_updated_spectrograms_1.npy\n",
            "concentration_array_updated_spectrograms_2.npy\n",
            "concentration_array_updated_spectrograms_3.npy\n",
            "concentration_array_updated_spectrograms_4.npy\n",
            "concentration_array_updated_spectrograms_5.npy\n",
            "concentration_array_updated_spectrograms_6.npy\n",
            "relaxed_array_updated_spectrograms_1.npy\n",
            "relaxed_array_updated_spectrograms_2.npy\n",
            "relaxed_array_updated_spectrograms_3.npy\n",
            "relaxed_array_updated_spectrograms_4.npy\n",
            "relaxed_array_updated_spectrograms_5.npy\n",
            "relaxed_array_updated_spectrograms_final.npy\n",
            "(2160, 29, 43, 42) (2124, 29, 43, 42)\n",
            "2160 2124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWjZwiYLypAV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "714867e7-b3df-452e-bae2-066d80909222"
      },
      "source": [
        "X = np.concatenate((relaxed_data_array, concentration_data_array))\n",
        "Y = np.concatenate((np.zeros((len(relaxed_data_array),1)),np.ones((len(concentration_data_array),1))))\n",
        "print(X.shape, Y.shape)\n",
        "relaxed_data_array, concentration_data_array = None, None"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4284, 29, 43, 42) (4284, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaQQIZAGy2ej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
        "X, Y = None, None\n",
        "folds = list(StratifiedKFold(n_splits=10, shuffle=True, random_state=1).split(X_train, y_train))\n",
        "#X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.15, random_state=42)\n",
        "#print(X_train.shape, X_test.shape, X_valid.shape, y_train.shape, y_test.shape, y_valid.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVt79b4tzKrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = \"vgg-like\"\n",
        "def get_model():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(input_shape=(29,43,42),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\", data_format='channels_first'))\n",
        "  model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "  #model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "  #model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "  #model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "  #model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "  #model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(units=4096,activation=\"relu\"))\n",
        "\n",
        "  model.add(Dense(units=4096,activation=\"relu\"))\n",
        "  model.add(Dense(units=2, activation=\"softmax\")) \n",
        "\n",
        "  # model.add(Conv2D(64, kernel_size=5, strides=(1,1), padding='valid', activation='relu', input_shape = (29, 43, 42)))\n",
        "  # model.add(Conv2D(128, kernel_size=3, activation='relu'))\n",
        "  # model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\n",
        "  # model.add(Conv2D(256, kernel_size=3, strides=(1,1), padding='valid', activation='relu'))\n",
        "  # model.add(Conv2D(512, kernel_size=2, activation='relu'))\n",
        "  # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  \n",
        "  # model.add(Flatten())\n",
        "  # model.add(Dense(100, activation='relu'))\n",
        "  # model.add(Dense(50, activation='relu'))\n",
        "  # model.add(Dense(1, activation='sigmoid'))\n",
        "  \n",
        "  #sgd = optimizers.SGD(lr=0.000001, momentum=0.7, decay=1e-6)\n",
        "  #model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "  adm = optimizers.Adam(lr=0.0001, decay=1e-6)\n",
        "  model.compile(optimizer=adm, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "  model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiqXkhrOZF7Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6a4c7ec5-3aae-4377-8ab2-b13f99d2cffa"
      },
      "source": [
        "filepath= model_name + \"-weights-improvement-{epoch:02d}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "model2 = get_model()\n",
        "for j, (train_idx, val_idx) in enumerate(folds):\n",
        "  print('\\nFold ',j)\n",
        "  X_train_cv = X_train[train_idx]\n",
        "  y_train_cv = y_train[train_idx]\n",
        "  X_valid_cv = X_train[val_idx]\n",
        "  y_valid_cv= y_train[val_idx]\n",
        "  # checkpoint\n",
        "  model2.fit(X_train_cv, y_train_cv, validation_data=(X_valid_cv, y_valid_cv), epochs=20, batch_size=32, callbacks=callbacks_list, shuffle=True)\n",
        "score = model2.evaluate(X_test,y_test)\n",
        "print(\"Test set metrics: %s: %.2f%%\" % (model2.metrics_names[1], score[1]*100))\n",
        "model2_json = model2.to_json()\n",
        "with open(model_name + \".json\", \"w\") as json_file:\n",
        "    json_file.write(model2_json)\n",
        "# serialize weights to HDF5\n",
        "model2.save_weights(model_name + \".h5\")\n",
        "print(\"Saved model %s to disk\" % (model_name))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold  0\n",
            "Train on 3276 samples, validate on 365 samples\n",
            "Epoch 1/20\n",
            "3264/3276 [============================>.] - ETA: 0s - loss: 0.7338 - accuracy: 0.4905\n",
            "Epoch 00001: accuracy improved from -inf to 0.48993, saving model to vgg-like-weights-improvement-01.hdf5\n",
            "3276/3276 [==============================] - 15s 5ms/sample - loss: 0.7337 - accuracy: 0.4899 - val_loss: 0.6916 - val_accuracy: 0.5123\n",
            "Epoch 2/20\n",
            "3264/3276 [============================>.] - ETA: 0s - loss: 0.6928 - accuracy: 0.5098\n",
            "Epoch 00002: accuracy improved from 0.48993 to 0.50977, saving model to vgg-like-weights-improvement-02.hdf5\n",
            "3276/3276 [==============================] - 15s 5ms/sample - loss: 0.6928 - accuracy: 0.5098 - val_loss: 0.6886 - val_accuracy: 0.5123\n",
            "Epoch 3/20\n",
            "3264/3276 [============================>.] - ETA: 0s - loss: 0.6925 - accuracy: 0.5034\n",
            "Epoch 00003: accuracy did not improve from 0.50977\n",
            "3276/3276 [==============================] - 11s 3ms/sample - loss: 0.6925 - accuracy: 0.5046 - val_loss: 0.6933 - val_accuracy: 0.4877\n",
            "Epoch 4/20\n",
            "3264/3276 [============================>.] - ETA: 0s - loss: 0.6923 - accuracy: 0.5040\n",
            "Epoch 00004: accuracy did not improve from 0.50977\n",
            "3276/3276 [==============================] - 11s 3ms/sample - loss: 0.6922 - accuracy: 0.5043 - val_loss: 0.6837 - val_accuracy: 0.5479\n",
            "Epoch 5/20\n",
            "3264/3276 [============================>.] - ETA: 0s - loss: 0.6837 - accuracy: 0.5132\n",
            "Epoch 00005: accuracy improved from 0.50977 to 0.51404, saving model to vgg-like-weights-improvement-05.hdf5\n",
            "3276/3276 [==============================] - 14s 4ms/sample - loss: 0.6835 - accuracy: 0.5140 - val_loss: 0.6697 - val_accuracy: 0.5178\n",
            "Epoch 6/20\n",
            "3264/3276 [============================>.] - ETA: 0s - loss: 0.6792 - accuracy: 0.5049\n",
            "Epoch 00006: accuracy did not improve from 0.51404\n",
            "3276/3276 [==============================] - 11s 3ms/sample - loss: 0.6793 - accuracy: 0.5049 - val_loss: 0.6721 - val_accuracy: 0.5205\n",
            "Epoch 7/20\n",
            "3264/3276 [============================>.] - ETA: 0s - loss: 0.6795 - accuracy: 0.5080\n",
            "Epoch 00007: accuracy did not improve from 0.51404\n",
            "3276/3276 [==============================] - 11s 3ms/sample - loss: 0.6796 - accuracy: 0.5073 - val_loss: 0.6792 - val_accuracy: 0.5123\n",
            "Epoch 8/20\n",
            "3264/3276 [============================>.] - ETA: 0s - loss: 0.6884 - accuracy: 0.5037\n",
            "Epoch 00008: accuracy did not improve from 0.51404\n",
            "3276/3276 [==============================] - 11s 3ms/sample - loss: 0.6884 - accuracy: 0.5049 - val_loss: 0.6929 - val_accuracy: 0.5123\n",
            "Epoch 9/20\n",
            "3264/3276 [============================>.] - ETA: 0s - loss: 0.6926 - accuracy: 0.5116\n",
            "Epoch 00009: accuracy did not improve from 0.51404\n",
            "3276/3276 [==============================] - 11s 3ms/sample - loss: 0.6926 - accuracy: 0.5113 - val_loss: 0.6849 - val_accuracy: 0.5479\n",
            "Epoch 10/20\n",
            "3264/3276 [============================>.] - ETA: 0s - loss: 0.7054 - accuracy: 0.5080\n",
            "Epoch 00010: accuracy did not improve from 0.51404\n",
            "3276/3276 [==============================] - 10s 3ms/sample - loss: 0.7054 - accuracy: 0.5067 - val_loss: 0.6930 - val_accuracy: 0.5123\n",
            "Epoch 11/20\n",
            "3264/3276 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.5058\n",
            "Epoch 00011: accuracy did not improve from 0.51404\n",
            "3276/3276 [==============================] - 10s 3ms/sample - loss: 0.6931 - accuracy: 0.5061 - val_loss: 0.6929 - val_accuracy: 0.5123\n",
            "Epoch 12/20\n",
            "3264/3276 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.5126\n",
            "Epoch 00012: accuracy did not improve from 0.51404\n",
            "3276/3276 [==============================] - 10s 3ms/sample - loss: 0.6931 - accuracy: 0.5116 - val_loss: 0.6930 - val_accuracy: 0.5123\n",
            "Epoch 13/20\n",
            "3264/3276 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.5110\n",
            "Epoch 00013: accuracy did not improve from 0.51404\n",
            "3276/3276 [==============================] - 10s 3ms/sample - loss: 0.6929 - accuracy: 0.5119 - val_loss: 0.6928 - val_accuracy: 0.5123\n",
            "Epoch 14/20\n",
            "3264/3276 [============================>.] - ETA: 0s - loss: 0.6929 - accuracy: 0.5119\n",
            "Epoch 00014: accuracy did not improve from 0.51404\n",
            "3276/3276 [==============================] - 10s 3ms/sample - loss: 0.6929 - accuracy: 0.5119 - val_loss: 0.6928 - val_accuracy: 0.5123\n",
            "Epoch 15/20\n",
            "3264/3276 [============================>.] - ETA: 0s - loss: 0.6929 - accuracy: 0.5123\n",
            "Epoch 00015: accuracy did not improve from 0.51404\n",
            "3276/3276 [==============================] - 11s 3ms/sample - loss: 0.6929 - accuracy: 0.5119 - val_loss: 0.6927 - val_accuracy: 0.5123\n",
            "Epoch 16/20\n",
            "3264/3276 [============================>.] - ETA: 0s - loss: 0.6929 - accuracy: 0.5113\n",
            "Epoch 00016: accuracy did not improve from 0.51404\n",
            "3276/3276 [==============================] - 10s 3ms/sample - loss: 0.6929 - accuracy: 0.5119 - val_loss: 0.6925 - val_accuracy: 0.5123\n",
            "Epoch 17/20\n",
            "3264/3276 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5169\n",
            "Epoch 00017: accuracy improved from 0.51404 to 0.51648, saving model to vgg-like-weights-improvement-17.hdf5\n",
            "3276/3276 [==============================] - 12s 4ms/sample - loss: 0.6932 - accuracy: 0.5165 - val_loss: 0.6928 - val_accuracy: 0.5123\n",
            "Epoch 18/20\n",
            "3264/3276 [============================>.] - ETA: 0s - loss: 0.6929 - accuracy: 0.5129\n",
            "Epoch 00018: accuracy did not improve from 0.51648\n",
            "3276/3276 [==============================] - 10s 3ms/sample - loss: 0.6929 - accuracy: 0.5119 - val_loss: 0.6928 - val_accuracy: 0.5123\n",
            "Epoch 19/20\n",
            "3264/3276 [============================>.] - ETA: 0s - loss: 0.6928 - accuracy: 0.5129\n",
            "Epoch 00019: accuracy did not improve from 0.51648\n",
            "3276/3276 [==============================] - 11s 3ms/sample - loss: 0.6928 - accuracy: 0.5119 - val_loss: 0.6925 - val_accuracy: 0.5123\n",
            "Epoch 20/20\n",
            "3264/3276 [============================>.] - ETA: 0s - loss: 0.6928 - accuracy: 0.5110\n",
            "Epoch 00020: accuracy did not improve from 0.51648\n",
            "3276/3276 [==============================] - 10s 3ms/sample - loss: 0.6928 - accuracy: 0.5119 - val_loss: 0.6917 - val_accuracy: 0.5123\n",
            "\n",
            "Fold  1\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "Epoch 1/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.4997\n",
            "Epoch 00001: accuracy did not improve from 0.51648\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6933 - accuracy: 0.5002 - val_loss: 0.6929 - val_accuracy: 0.5110\n",
            "Epoch 2/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.5116\n",
            "Epoch 00002: accuracy did not improve from 0.51648\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6930 - accuracy: 0.5121 - val_loss: 0.6929 - val_accuracy: 0.5110\n",
            "Epoch 3/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5107\n",
            "Epoch 00003: accuracy did not improve from 0.51648\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6931 - accuracy: 0.5114 - val_loss: 0.6929 - val_accuracy: 0.5110\n",
            "Epoch 4/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6928 - accuracy: 0.5132\n",
            "Epoch 00004: accuracy did not improve from 0.51648\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6929 - accuracy: 0.5121 - val_loss: 0.6927 - val_accuracy: 0.5110\n",
            "Epoch 5/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5113\n",
            "Epoch 00005: accuracy did not improve from 0.51648\n",
            "3277/3277 [==============================] - 11s 3ms/sample - loss: 0.6932 - accuracy: 0.5121 - val_loss: 0.6929 - val_accuracy: 0.5110\n",
            "Epoch 6/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6928 - accuracy: 0.5132\n",
            "Epoch 00006: accuracy did not improve from 0.51648\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6929 - accuracy: 0.5121 - val_loss: 0.6927 - val_accuracy: 0.5110\n",
            "Epoch 7/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6929 - accuracy: 0.5214\n",
            "Epoch 00007: accuracy improved from 0.51648 to 0.52121, saving model to vgg-like-weights-improvement-07.hdf5\n",
            "3277/3277 [==============================] - 18s 6ms/sample - loss: 0.6929 - accuracy: 0.5212 - val_loss: 0.6930 - val_accuracy: 0.5110\n",
            "Epoch 8/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.5095\n",
            "Epoch 00008: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 11s 3ms/sample - loss: 0.6930 - accuracy: 0.5099 - val_loss: 0.6929 - val_accuracy: 0.5110\n",
            "Epoch 9/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6929 - accuracy: 0.5126\n",
            "Epoch 00009: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6930 - accuracy: 0.5121 - val_loss: 0.6929 - val_accuracy: 0.5110\n",
            "Epoch 10/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.5058\n",
            "Epoch 00010: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6931 - accuracy: 0.5063 - val_loss: 0.6929 - val_accuracy: 0.5110\n",
            "Epoch 11/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6929 - accuracy: 0.5132\n",
            "Epoch 00011: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6929 - accuracy: 0.5121 - val_loss: 0.6927 - val_accuracy: 0.5110\n",
            "Epoch 12/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6929 - accuracy: 0.5110\n",
            "Epoch 00012: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6929 - accuracy: 0.5121 - val_loss: 0.6928 - val_accuracy: 0.5110\n",
            "Epoch 13/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6925 - accuracy: 0.5123\n",
            "Epoch 00013: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 11s 3ms/sample - loss: 0.6925 - accuracy: 0.5121 - val_loss: 0.6929 - val_accuracy: 0.5110\n",
            "Epoch 14/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5061\n",
            "Epoch 00014: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6933 - accuracy: 0.5050 - val_loss: 0.6929 - val_accuracy: 0.5110\n",
            "Epoch 15/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.5119\n",
            "Epoch 00015: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6927 - accuracy: 0.5121 - val_loss: 0.6942 - val_accuracy: 0.5110\n",
            "Epoch 16/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6936 - accuracy: 0.5110\n",
            "Epoch 00016: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6936 - accuracy: 0.5105 - val_loss: 0.6928 - val_accuracy: 0.5110\n",
            "Epoch 17/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6916 - accuracy: 0.5104\n",
            "Epoch 00017: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6916 - accuracy: 0.5102 - val_loss: 0.6929 - val_accuracy: 0.5110\n",
            "Epoch 18/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6928 - accuracy: 0.5043\n",
            "Epoch 00018: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6929 - accuracy: 0.5041 - val_loss: 0.6874 - val_accuracy: 0.5110\n",
            "Epoch 19/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6946 - accuracy: 0.5110\n",
            "Epoch 00019: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6946 - accuracy: 0.5105 - val_loss: 0.6930 - val_accuracy: 0.5110\n",
            "Epoch 20/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6924 - accuracy: 0.5116\n",
            "Epoch 00020: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6924 - accuracy: 0.5127 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
            "\n",
            "Fold  2\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "Epoch 1/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6928 - accuracy: 0.5089\n",
            "Epoch 00001: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6928 - accuracy: 0.5084 - val_loss: 0.6916 - val_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6898 - accuracy: 0.5107\n",
            "Epoch 00002: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6897 - accuracy: 0.5102 - val_loss: 0.6810 - val_accuracy: 0.5055\n",
            "Epoch 3/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6925 - accuracy: 0.5028\n",
            "Epoch 00003: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6925 - accuracy: 0.5029 - val_loss: 0.6928 - val_accuracy: 0.5110\n",
            "Epoch 4/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.5129\n",
            "Epoch 00004: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6930 - accuracy: 0.5133 - val_loss: 0.6925 - val_accuracy: 0.5330\n",
            "Epoch 5/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.5086\n",
            "Epoch 00005: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6934 - accuracy: 0.5078 - val_loss: 0.6928 - val_accuracy: 0.5110\n",
            "Epoch 6/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.5070\n",
            "Epoch 00006: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6931 - accuracy: 0.5066 - val_loss: 0.6927 - val_accuracy: 0.5110\n",
            "Epoch 7/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6917 - accuracy: 0.5116\n",
            "Epoch 00007: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6916 - accuracy: 0.5121 - val_loss: 0.8995 - val_accuracy: 0.5110\n",
            "Epoch 8/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5070\n",
            "Epoch 00008: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6932 - accuracy: 0.5060 - val_loss: 0.6874 - val_accuracy: 0.5110\n",
            "Epoch 9/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6943 - accuracy: 0.5092\n",
            "Epoch 00009: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6943 - accuracy: 0.5093 - val_loss: 0.6915 - val_accuracy: 0.5110\n",
            "Epoch 10/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6907 - accuracy: 0.5006\n",
            "Epoch 00010: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6907 - accuracy: 0.5014 - val_loss: 0.6893 - val_accuracy: 0.5110\n",
            "Epoch 11/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6921 - accuracy: 0.5095\n",
            "Epoch 00011: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6920 - accuracy: 0.5093 - val_loss: 0.6912 - val_accuracy: 0.5110\n",
            "Epoch 12/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6925 - accuracy: 0.5003\n",
            "Epoch 00012: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6925 - accuracy: 0.5008 - val_loss: 0.6919 - val_accuracy: 0.5110\n",
            "Epoch 13/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6898 - accuracy: 0.5119\n",
            "Epoch 00013: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6899 - accuracy: 0.5105 - val_loss: 0.6872 - val_accuracy: 0.5055\n",
            "Epoch 14/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6889 - accuracy: 0.5199\n",
            "Epoch 00014: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6889 - accuracy: 0.5200 - val_loss: 0.6901 - val_accuracy: 0.5082\n",
            "Epoch 15/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6845 - accuracy: 0.5037\n",
            "Epoch 00015: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6845 - accuracy: 0.5038 - val_loss: 0.6849 - val_accuracy: 0.5110\n",
            "Epoch 16/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.7101 - accuracy: 0.5175\n",
            "Epoch 00016: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.7100 - accuracy: 0.5175 - val_loss: 0.6872 - val_accuracy: 0.5110\n",
            "Epoch 17/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6818 - accuracy: 0.5126\n",
            "Epoch 00017: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6818 - accuracy: 0.5136 - val_loss: 0.6807 - val_accuracy: 0.5000\n",
            "Epoch 18/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6779 - accuracy: 0.5135\n",
            "Epoch 00018: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6780 - accuracy: 0.5139 - val_loss: 0.6862 - val_accuracy: 0.5467\n",
            "Epoch 19/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6777 - accuracy: 0.5162\n",
            "Epoch 00019: accuracy did not improve from 0.52121\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6778 - accuracy: 0.5166 - val_loss: 0.6793 - val_accuracy: 0.5137\n",
            "Epoch 20/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6774 - accuracy: 0.5251\n",
            "Epoch 00020: accuracy improved from 0.52121 to 0.52487, saving model to vgg-like-weights-improvement-20.hdf5\n",
            "3277/3277 [==============================] - 14s 4ms/sample - loss: 0.6773 - accuracy: 0.5249 - val_loss: 0.6792 - val_accuracy: 0.5440\n",
            "\n",
            "Fold  3\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "Epoch 1/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6777 - accuracy: 0.5411\n",
            "Epoch 00001: accuracy improved from 0.52487 to 0.54165, saving model to vgg-like-weights-improvement-01.hdf5\n",
            "3277/3277 [==============================] - 17s 5ms/sample - loss: 0.6774 - accuracy: 0.5417 - val_loss: 0.7382 - val_accuracy: 0.5110\n",
            "Epoch 2/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6796 - accuracy: 0.5205\n",
            "Epoch 00002: accuracy did not improve from 0.54165\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6796 - accuracy: 0.5203 - val_loss: 0.6655 - val_accuracy: 0.5192\n",
            "Epoch 3/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6773 - accuracy: 0.5328\n",
            "Epoch 00003: accuracy did not improve from 0.54165\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6774 - accuracy: 0.5325 - val_loss: 0.6640 - val_accuracy: 0.5165\n",
            "Epoch 4/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6775 - accuracy: 0.5447\n",
            "Epoch 00004: accuracy improved from 0.54165 to 0.54471, saving model to vgg-like-weights-improvement-04.hdf5\n",
            "3277/3277 [==============================] - 16s 5ms/sample - loss: 0.6776 - accuracy: 0.5447 - val_loss: 0.6650 - val_accuracy: 0.5824\n",
            "Epoch 5/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6730 - accuracy: 0.5558\n",
            "Epoch 00005: accuracy improved from 0.54471 to 0.55661, saving model to vgg-like-weights-improvement-05.hdf5\n",
            "3277/3277 [==============================] - 16s 5ms/sample - loss: 0.6730 - accuracy: 0.5566 - val_loss: 0.6620 - val_accuracy: 0.5659\n",
            "Epoch 6/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6724 - accuracy: 0.5561\n",
            "Epoch 00006: accuracy did not improve from 0.55661\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6720 - accuracy: 0.5560 - val_loss: 0.6611 - val_accuracy: 0.5467\n",
            "Epoch 7/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6681 - accuracy: 0.5671\n",
            "Epoch 00007: accuracy improved from 0.55661 to 0.56668, saving model to vgg-like-weights-improvement-07.hdf5\n",
            "3277/3277 [==============================] - 17s 5ms/sample - loss: 0.6682 - accuracy: 0.5667 - val_loss: 0.6690 - val_accuracy: 0.5522\n",
            "Epoch 8/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6684 - accuracy: 0.5591\n",
            "Epoch 00008: accuracy did not improve from 0.56668\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6682 - accuracy: 0.5590 - val_loss: 0.6603 - val_accuracy: 0.5962\n",
            "Epoch 9/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6680 - accuracy: 0.5778\n",
            "Epoch 00009: accuracy improved from 0.56668 to 0.57797, saving model to vgg-like-weights-improvement-09.hdf5\n",
            "3277/3277 [==============================] - 17s 5ms/sample - loss: 0.6680 - accuracy: 0.5780 - val_loss: 0.6614 - val_accuracy: 0.5549\n",
            "Epoch 10/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6615 - accuracy: 0.5818\n",
            "Epoch 00010: accuracy improved from 0.57797 to 0.58163, saving model to vgg-like-weights-improvement-10.hdf5\n",
            "3277/3277 [==============================] - 16s 5ms/sample - loss: 0.6615 - accuracy: 0.5816 - val_loss: 0.6629 - val_accuracy: 0.5632\n",
            "Epoch 11/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6702 - accuracy: 0.5683\n",
            "Epoch 00011: accuracy did not improve from 0.58163\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6704 - accuracy: 0.5679 - val_loss: 0.6737 - val_accuracy: 0.5659\n",
            "Epoch 12/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6678 - accuracy: 0.5738\n",
            "Epoch 00012: accuracy did not improve from 0.58163\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6676 - accuracy: 0.5746 - val_loss: 0.6573 - val_accuracy: 0.5852\n",
            "Epoch 13/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6567 - accuracy: 0.5934\n",
            "Epoch 00013: accuracy improved from 0.58163 to 0.59353, saving model to vgg-like-weights-improvement-13.hdf5\n",
            "3277/3277 [==============================] - 14s 4ms/sample - loss: 0.6565 - accuracy: 0.5935 - val_loss: 0.6732 - val_accuracy: 0.5385\n",
            "Epoch 14/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6525 - accuracy: 0.5956\n",
            "Epoch 00014: accuracy improved from 0.59353 to 0.59658, saving model to vgg-like-weights-improvement-14.hdf5\n",
            "3277/3277 [==============================] - 15s 4ms/sample - loss: 0.6523 - accuracy: 0.5966 - val_loss: 0.6629 - val_accuracy: 0.5907\n",
            "Epoch 15/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6416 - accuracy: 0.6143\n",
            "Epoch 00015: accuracy improved from 0.59658 to 0.61520, saving model to vgg-like-weights-improvement-15.hdf5\n",
            "3277/3277 [==============================] - 14s 4ms/sample - loss: 0.6411 - accuracy: 0.6152 - val_loss: 0.6912 - val_accuracy: 0.5879\n",
            "Epoch 16/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6439 - accuracy: 0.6072\n",
            "Epoch 00016: accuracy did not improve from 0.61520\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.6438 - accuracy: 0.6076 - val_loss: 0.6808 - val_accuracy: 0.5742\n",
            "Epoch 17/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6319 - accuracy: 0.6290\n",
            "Epoch 00017: accuracy improved from 0.61520 to 0.62862, saving model to vgg-like-weights-improvement-17.hdf5\n",
            "3277/3277 [==============================] - 13s 4ms/sample - loss: 0.6323 - accuracy: 0.6286 - val_loss: 0.6939 - val_accuracy: 0.5275\n",
            "Epoch 18/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6198 - accuracy: 0.6486\n",
            "Epoch 00018: accuracy improved from 0.62862 to 0.64907, saving model to vgg-like-weights-improvement-18.hdf5\n",
            "3277/3277 [==============================] - 15s 5ms/sample - loss: 0.6196 - accuracy: 0.6491 - val_loss: 0.7147 - val_accuracy: 0.5385\n",
            "Epoch 19/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6099 - accuracy: 0.6538\n",
            "Epoch 00019: accuracy improved from 0.64907 to 0.65365, saving model to vgg-like-weights-improvement-19.hdf5\n",
            "3277/3277 [==============================] - 14s 4ms/sample - loss: 0.6096 - accuracy: 0.6536 - val_loss: 0.6872 - val_accuracy: 0.5632\n",
            "Epoch 20/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.5933 - accuracy: 0.6798\n",
            "Epoch 00020: accuracy improved from 0.65365 to 0.67867, saving model to vgg-like-weights-improvement-20.hdf5\n",
            "3277/3277 [==============================] - 20s 6ms/sample - loss: 0.5941 - accuracy: 0.6787 - val_loss: 0.7200 - val_accuracy: 0.5440\n",
            "\n",
            "Fold  4\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "Epoch 1/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.5902 - accuracy: 0.6829\n",
            "Epoch 00001: accuracy improved from 0.67867 to 0.68233, saving model to vgg-like-weights-improvement-01.hdf5\n",
            "3277/3277 [==============================] - 15s 4ms/sample - loss: 0.5906 - accuracy: 0.6823 - val_loss: 0.5754 - val_accuracy: 0.6758\n",
            "Epoch 2/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.5604 - accuracy: 0.7096\n",
            "Epoch 00002: accuracy improved from 0.68233 to 0.70888, saving model to vgg-like-weights-improvement-02.hdf5\n",
            "3277/3277 [==============================] - 18s 5ms/sample - loss: 0.5609 - accuracy: 0.7089 - val_loss: 0.5975 - val_accuracy: 0.6593\n",
            "Epoch 3/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.5418 - accuracy: 0.7295\n",
            "Epoch 00003: accuracy improved from 0.70888 to 0.72933, saving model to vgg-like-weights-improvement-03.hdf5\n",
            "3277/3277 [==============================] - 21s 6ms/sample - loss: 0.5417 - accuracy: 0.7293 - val_loss: 0.5742 - val_accuracy: 0.7170\n",
            "Epoch 4/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.5070 - accuracy: 0.7549\n",
            "Epoch 00004: accuracy improved from 0.72933 to 0.75496, saving model to vgg-like-weights-improvement-04.hdf5\n",
            "3277/3277 [==============================] - 17s 5ms/sample - loss: 0.5066 - accuracy: 0.7550 - val_loss: 0.6305 - val_accuracy: 0.6374\n",
            "Epoch 5/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.4719 - accuracy: 0.7785\n",
            "Epoch 00005: accuracy improved from 0.75496 to 0.77846, saving model to vgg-like-weights-improvement-05.hdf5\n",
            "3277/3277 [==============================] - 14s 4ms/sample - loss: 0.4715 - accuracy: 0.7785 - val_loss: 0.6544 - val_accuracy: 0.6346\n",
            "Epoch 6/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.4164 - accuracy: 0.8085\n",
            "Epoch 00006: accuracy improved from 0.77846 to 0.80897, saving model to vgg-like-weights-improvement-06.hdf5\n",
            "3277/3277 [==============================] - 17s 5ms/sample - loss: 0.4158 - accuracy: 0.8090 - val_loss: 0.7084 - val_accuracy: 0.6429\n",
            "Epoch 7/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.3653 - accuracy: 0.8346\n",
            "Epoch 00007: accuracy improved from 0.80897 to 0.83460, saving model to vgg-like-weights-improvement-07.hdf5\n",
            "3277/3277 [==============================] - 25s 8ms/sample - loss: 0.3653 - accuracy: 0.8346 - val_loss: 0.6682 - val_accuracy: 0.6841\n",
            "Epoch 8/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.2941 - accuracy: 0.8738\n",
            "Epoch 00008: accuracy improved from 0.83460 to 0.87366, saving model to vgg-like-weights-improvement-08.hdf5\n",
            "3277/3277 [==============================] - 17s 5ms/sample - loss: 0.2951 - accuracy: 0.8737 - val_loss: 0.9097 - val_accuracy: 0.6648\n",
            "Epoch 9/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.2445 - accuracy: 0.8995\n",
            "Epoch 00009: accuracy improved from 0.87366 to 0.89930, saving model to vgg-like-weights-improvement-09.hdf5\n",
            "3277/3277 [==============================] - 15s 5ms/sample - loss: 0.2447 - accuracy: 0.8993 - val_loss: 1.0001 - val_accuracy: 0.6181\n",
            "Epoch 10/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.2180 - accuracy: 0.9066\n",
            "Epoch 00010: accuracy improved from 0.89930 to 0.90632, saving model to vgg-like-weights-improvement-10.hdf5\n",
            "3277/3277 [==============================] - 22s 7ms/sample - loss: 0.2192 - accuracy: 0.9063 - val_loss: 0.9753 - val_accuracy: 0.6676\n",
            "Epoch 11/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.1459 - accuracy: 0.9406\n",
            "Epoch 00011: accuracy improved from 0.90632 to 0.94049, saving model to vgg-like-weights-improvement-11.hdf5\n",
            "3277/3277 [==============================] - 14s 4ms/sample - loss: 0.1460 - accuracy: 0.9405 - val_loss: 1.1981 - val_accuracy: 0.6648\n",
            "Epoch 12/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.1323 - accuracy: 0.9449\n",
            "Epoch 00012: accuracy improved from 0.94049 to 0.94477, saving model to vgg-like-weights-improvement-12.hdf5\n",
            "3277/3277 [==============================] - 18s 5ms/sample - loss: 0.1331 - accuracy: 0.9448 - val_loss: 1.4724 - val_accuracy: 0.6731\n",
            "Epoch 13/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.1054 - accuracy: 0.9617\n",
            "Epoch 00013: accuracy improved from 0.94477 to 0.96155, saving model to vgg-like-weights-improvement-13.hdf5\n",
            "3277/3277 [==============================] - 25s 8ms/sample - loss: 0.1060 - accuracy: 0.9616 - val_loss: 1.6309 - val_accuracy: 0.6181\n",
            "Epoch 14/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.1785 - accuracy: 0.9344\n",
            "Epoch 00014: accuracy did not improve from 0.96155\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.1784 - accuracy: 0.9344 - val_loss: 0.8951 - val_accuracy: 0.6511\n",
            "Epoch 15/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.1238 - accuracy: 0.9583\n",
            "Epoch 00015: accuracy did not improve from 0.96155\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.1237 - accuracy: 0.9582 - val_loss: 1.3947 - val_accuracy: 0.6786\n",
            "Epoch 16/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0652 - accuracy: 0.9782\n",
            "Epoch 00016: accuracy improved from 0.96155 to 0.97833, saving model to vgg-like-weights-improvement-16.hdf5\n",
            "3277/3277 [==============================] - 14s 4ms/sample - loss: 0.0650 - accuracy: 0.9783 - val_loss: 1.5374 - val_accuracy: 0.6456\n",
            "Epoch 17/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0628 - accuracy: 0.9770\n",
            "Epoch 00017: accuracy did not improve from 0.97833\n",
            "3277/3277 [==============================] - 11s 3ms/sample - loss: 0.0626 - accuracy: 0.9771 - val_loss: 1.4145 - val_accuracy: 0.6648\n",
            "Epoch 18/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0614 - accuracy: 0.9822\n",
            "Epoch 00018: accuracy improved from 0.97833 to 0.98200, saving model to vgg-like-weights-improvement-18.hdf5\n",
            "3277/3277 [==============================] - 14s 4ms/sample - loss: 0.0617 - accuracy: 0.9820 - val_loss: 1.2414 - val_accuracy: 0.6401\n",
            "Epoch 19/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0265 - accuracy: 0.9920\n",
            "Epoch 00019: accuracy improved from 0.98200 to 0.99207, saving model to vgg-like-weights-improvement-19.hdf5\n",
            "3277/3277 [==============================] - 14s 4ms/sample - loss: 0.0264 - accuracy: 0.9921 - val_loss: 2.7700 - val_accuracy: 0.6648\n",
            "Epoch 20/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0513 - accuracy: 0.9859\n",
            "Epoch 00020: accuracy did not improve from 0.99207\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0511 - accuracy: 0.9860 - val_loss: 1.9662 - val_accuracy: 0.6566\n",
            "\n",
            "Fold  5\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "Epoch 1/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.1925 - accuracy: 0.9455\n",
            "Epoch 00001: accuracy did not improve from 0.99207\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.1921 - accuracy: 0.9457 - val_loss: 0.0909 - val_accuracy: 0.9835\n",
            "Epoch 2/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0938 - accuracy: 0.9700\n",
            "Epoch 00002: accuracy did not improve from 0.99207\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0935 - accuracy: 0.9701 - val_loss: 0.0591 - val_accuracy: 0.9863\n",
            "Epoch 3/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0520 - accuracy: 0.9822\n",
            "Epoch 00003: accuracy did not improve from 0.99207\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0518 - accuracy: 0.9823 - val_loss: 0.0713 - val_accuracy: 0.9835\n",
            "Epoch 4/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0569 - accuracy: 0.9825\n",
            "Epoch 00004: accuracy did not improve from 0.99207\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0567 - accuracy: 0.9826 - val_loss: 0.0639 - val_accuracy: 0.9835\n",
            "Epoch 5/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0556 - accuracy: 0.9828\n",
            "Epoch 00005: accuracy did not improve from 0.99207\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0554 - accuracy: 0.9829 - val_loss: 0.0600 - val_accuracy: 0.9753\n",
            "Epoch 6/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9930\n",
            "Epoch 00006: accuracy improved from 0.99207 to 0.99298, saving model to vgg-like-weights-improvement-06.hdf5\n",
            "3277/3277 [==============================] - 15s 5ms/sample - loss: 0.0269 - accuracy: 0.9930 - val_loss: 0.0931 - val_accuracy: 0.9643\n",
            "Epoch 7/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0759 - accuracy: 0.9761\n",
            "Epoch 00007: accuracy did not improve from 0.99298\n",
            "3277/3277 [==============================] - 11s 3ms/sample - loss: 0.0756 - accuracy: 0.9762 - val_loss: 0.1197 - val_accuracy: 0.9588\n",
            "Epoch 8/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9902\n",
            "Epoch 00008: accuracy did not improve from 0.99298\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0343 - accuracy: 0.9902 - val_loss: 0.0622 - val_accuracy: 0.9808\n",
            "Epoch 9/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0457 - accuracy: 0.9865\n",
            "Epoch 00009: accuracy did not improve from 0.99298\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0456 - accuracy: 0.9866 - val_loss: 0.1059 - val_accuracy: 0.9725\n",
            "Epoch 10/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0494 - accuracy: 0.9828\n",
            "Epoch 00010: accuracy did not improve from 0.99298\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0492 - accuracy: 0.9829 - val_loss: 0.0898 - val_accuracy: 0.9670\n",
            "Epoch 11/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0354 - accuracy: 0.9862\n",
            "Epoch 00011: accuracy did not improve from 0.99298\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0353 - accuracy: 0.9863 - val_loss: 0.0760 - val_accuracy: 0.9725\n",
            "Epoch 12/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0240 - accuracy: 0.9920\n",
            "Epoch 00012: accuracy did not improve from 0.99298\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.1950 - val_accuracy: 0.9423\n",
            "Epoch 13/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9960\n",
            "Epoch 00013: accuracy improved from 0.99298 to 0.99603, saving model to vgg-like-weights-improvement-13.hdf5\n",
            "3277/3277 [==============================] - 14s 4ms/sample - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.2452 - val_accuracy: 0.9451\n",
            "Epoch 14/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0427 - accuracy: 0.9835\n",
            "Epoch 00014: accuracy did not improve from 0.99603\n",
            "3277/3277 [==============================] - 11s 3ms/sample - loss: 0.0427 - accuracy: 0.9835 - val_loss: 0.1584 - val_accuracy: 0.9505\n",
            "Epoch 15/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 0.9914\n",
            "Epoch 00015: accuracy did not improve from 0.99603\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0269 - accuracy: 0.9915 - val_loss: 0.2003 - val_accuracy: 0.9533\n",
            "Epoch 16/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0256 - accuracy: 0.9911\n",
            "Epoch 00016: accuracy did not improve from 0.99603\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0255 - accuracy: 0.9912 - val_loss: 0.2517 - val_accuracy: 0.9423\n",
            "Epoch 17/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0469 - accuracy: 0.9847\n",
            "Epoch 00017: accuracy did not improve from 0.99603\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0468 - accuracy: 0.9847 - val_loss: 0.1299 - val_accuracy: 0.9560\n",
            "Epoch 18/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9905\n",
            "Epoch 00018: accuracy did not improve from 0.99603\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0244 - accuracy: 0.9905 - val_loss: 0.2032 - val_accuracy: 0.9423\n",
            "Epoch 19/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9994\n",
            "Epoch 00019: accuracy improved from 0.99603 to 0.99939, saving model to vgg-like-weights-improvement-19.hdf5\n",
            "3277/3277 [==============================] - 14s 4ms/sample - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.2095 - val_accuracy: 0.9560\n",
            "Epoch 20/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0230 - accuracy: 0.9923\n",
            "Epoch 00020: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 11s 3ms/sample - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.3668 - val_accuracy: 0.8984\n",
            "\n",
            "Fold  6\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "Epoch 1/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0521 - accuracy: 0.9819\n",
            "Epoch 00001: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 11s 3ms/sample - loss: 0.0525 - accuracy: 0.9817 - val_loss: 0.0607 - val_accuracy: 0.9835\n",
            "Epoch 2/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0523 - accuracy: 0.9838\n",
            "Epoch 00002: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0523 - accuracy: 0.9838 - val_loss: 0.0558 - val_accuracy: 0.9780\n",
            "Epoch 3/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.9930\n",
            "Epoch 00003: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0209 - accuracy: 0.9930 - val_loss: 0.0440 - val_accuracy: 0.9863\n",
            "Epoch 4/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9969\n",
            "Epoch 00004: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.0436 - val_accuracy: 0.9863\n",
            "Epoch 5/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\n",
            "Epoch 00005: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0560 - val_accuracy: 0.9973\n",
            "Epoch 6/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0526 - accuracy: 0.9813\n",
            "Epoch 00006: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0524 - accuracy: 0.9814 - val_loss: 0.0964 - val_accuracy: 0.9725\n",
            "Epoch 7/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0355 - accuracy: 0.9887\n",
            "Epoch 00007: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0353 - accuracy: 0.9887 - val_loss: 0.1105 - val_accuracy: 0.9698\n",
            "Epoch 8/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0200 - accuracy: 0.9939\n",
            "Epoch 00008: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0199 - accuracy: 0.9939 - val_loss: 0.0140 - val_accuracy: 0.9945\n",
            "Epoch 9/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9969\n",
            "Epoch 00009: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0085 - accuracy: 0.9969 - val_loss: 0.1106 - val_accuracy: 0.9698\n",
            "Epoch 10/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0398 - accuracy: 0.9856\n",
            "Epoch 00010: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0398 - accuracy: 0.9857 - val_loss: 0.0500 - val_accuracy: 0.9863\n",
            "Epoch 11/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0157 - accuracy: 0.9945\n",
            "Epoch 00011: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0156 - accuracy: 0.9945 - val_loss: 0.0262 - val_accuracy: 0.9918\n",
            "Epoch 12/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0483 - accuracy: 0.9850\n",
            "Epoch 00012: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0482 - accuracy: 0.9850 - val_loss: 0.0933 - val_accuracy: 0.9835\n",
            "Epoch 13/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9939\n",
            "Epoch 00013: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0244 - accuracy: 0.9939 - val_loss: 0.0201 - val_accuracy: 0.9945\n",
            "Epoch 14/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9994\n",
            "Epoch 00014: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0285 - val_accuracy: 0.9863\n",
            "Epoch 15/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9985\n",
            "Epoch 00015: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.2352 - val_accuracy: 0.9478\n",
            "Epoch 16/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0445 - accuracy: 0.9850\n",
            "Epoch 00016: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0451 - accuracy: 0.9847 - val_loss: 0.1272 - val_accuracy: 0.9670\n",
            "Epoch 17/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0373 - accuracy: 0.9850\n",
            "Epoch 00017: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0371 - accuracy: 0.9850 - val_loss: 0.0615 - val_accuracy: 0.9835\n",
            "Epoch 18/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0713 - accuracy: 0.9770\n",
            "Epoch 00018: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0711 - accuracy: 0.9771 - val_loss: 0.0986 - val_accuracy: 0.9725\n",
            "Epoch 19/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9945\n",
            "Epoch 00019: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.1014 - val_accuracy: 0.9780\n",
            "Epoch 20/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9991\n",
            "Epoch 00020: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0018 - accuracy: 0.9991 - val_loss: 0.0486 - val_accuracy: 0.9835\n",
            "\n",
            "Fold  7\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "Epoch 1/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0358 - accuracy: 0.9865\n",
            "Epoch 00001: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0356 - accuracy: 0.9866 - val_loss: 0.0104 - val_accuracy: 0.9973\n",
            "Epoch 2/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9951\n",
            "Epoch 00002: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0186 - accuracy: 0.9951 - val_loss: 0.0596 - val_accuracy: 0.9780\n",
            "Epoch 3/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0361 - accuracy: 0.9865\n",
            "Epoch 00003: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0359 - accuracy: 0.9866 - val_loss: 0.0101 - val_accuracy: 0.9918\n",
            "Epoch 4/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9963\n",
            "Epoch 00004: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0052 - val_accuracy: 0.9973\n",
            "Epoch 5/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9991\n",
            "Epoch 00005: accuracy did not improve from 0.99939\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0060 - val_accuracy: 0.9973\n",
            "Epoch 6/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 5.0463e-05 - accuracy: 1.0000\n",
            "Epoch 00006: accuracy improved from 0.99939 to 1.00000, saving model to vgg-like-weights-improvement-06.hdf5\n",
            "3277/3277 [==============================] - 14s 4ms/sample - loss: 5.0690e-05 - accuracy: 1.0000 - val_loss: 9.7833e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 1.2460e-05 - accuracy: 1.0000\n",
            "Epoch 00007: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 11s 3ms/sample - loss: 1.2417e-05 - accuracy: 1.0000 - val_loss: 5.6198e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 5.4763e-06 - accuracy: 1.0000\n",
            "Epoch 00008: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 5.6443e-06 - accuracy: 1.0000 - val_loss: 3.8346e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 2.9528e-06 - accuracy: 1.0000\n",
            "Epoch 00009: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 2.9412e-06 - accuracy: 1.0000 - val_loss: 2.8670e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 1.8081e-06 - accuracy: 1.0000\n",
            "Epoch 00010: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 1.8020e-06 - accuracy: 1.0000 - val_loss: 2.2791e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 1.1888e-06 - accuracy: 1.0000\n",
            "Epoch 00011: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 1.1842e-06 - accuracy: 1.0000 - val_loss: 1.9339e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 8.4338e-07 - accuracy: 1.0000\n",
            "Epoch 00012: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 8.4003e-07 - accuracy: 1.0000 - val_loss: 1.6805e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 6.0633e-07 - accuracy: 1.0000\n",
            "Epoch 00013: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 6.2073e-07 - accuracy: 1.0000 - val_loss: 1.4905e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 4.6824e-07 - accuracy: 1.0000\n",
            "Epoch 00014: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 4.6828e-07 - accuracy: 1.0000 - val_loss: 1.3234e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 3.6609e-07 - accuracy: 1.0000\n",
            "Epoch 00015: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 3.6464e-07 - accuracy: 1.0000 - val_loss: 1.2017e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 2.9217e-07 - accuracy: 1.0000\n",
            "Epoch 00016: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 2.9105e-07 - accuracy: 1.0000 - val_loss: 1.0908e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 2.3776e-07 - accuracy: 1.0000\n",
            "Epoch 00017: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 2.3736e-07 - accuracy: 1.0000 - val_loss: 1.0095e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 1.9689e-07 - accuracy: 1.0000\n",
            "Epoch 00018: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 1.9655e-07 - accuracy: 1.0000 - val_loss: 9.3576e-06 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 1.6618e-07 - accuracy: 1.0000\n",
            "Epoch 00019: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 1.6552e-07 - accuracy: 1.0000 - val_loss: 8.7750e-06 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 1.3667e-07 - accuracy: 1.0000\n",
            "Epoch 00020: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 1.4093e-07 - accuracy: 1.0000 - val_loss: 8.1442e-06 - val_accuracy: 1.0000\n",
            "\n",
            "Fold  8\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "Epoch 1/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 9.8386e-07 - accuracy: 1.0000\n",
            "Epoch 00001: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 9.7996e-07 - accuracy: 1.0000 - val_loss: 1.5785e-07 - val_accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 1.8585e-07 - accuracy: 1.0000\n",
            "Epoch 00002: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 1.8511e-07 - accuracy: 1.0000 - val_loss: 1.2772e-07 - val_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 1.3129e-07 - accuracy: 1.0000\n",
            "Epoch 00003: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 1.3197e-07 - accuracy: 1.0000 - val_loss: 1.0676e-07 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 1.0401e-07 - accuracy: 1.0000\n",
            "Epoch 00004: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 1.0360e-07 - accuracy: 1.0000 - val_loss: 9.6284e-08 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 8.5789e-08 - accuracy: 1.0000\n",
            "Epoch 00005: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 8.5449e-08 - accuracy: 1.0000 - val_loss: 8.0564e-08 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 7.2569e-08 - accuracy: 1.0000\n",
            "Epoch 00006: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 7.2317e-08 - accuracy: 1.0000 - val_loss: 7.2377e-08 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 6.2562e-08 - accuracy: 1.0000\n",
            "Epoch 00007: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 6.2350e-08 - accuracy: 1.0000 - val_loss: 6.4844e-08 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 5.3578e-08 - accuracy: 1.0000\n",
            "Epoch 00008: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 5.4857e-08 - accuracy: 1.0000 - val_loss: 5.8949e-08 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 4.8976e-08 - accuracy: 1.0000\n",
            "Epoch 00009: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 4.8782e-08 - accuracy: 1.0000 - val_loss: 5.4692e-08 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 4.3863e-08 - accuracy: 1.0000\n",
            "Epoch 00010: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 4.3689e-08 - accuracy: 1.0000 - val_loss: 4.9125e-08 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 3.8787e-08 - accuracy: 1.0000\n",
            "Epoch 00011: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 3.9579e-08 - accuracy: 1.0000 - val_loss: 4.4867e-08 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 3.5755e-08 - accuracy: 1.0000\n",
            "Epoch 00012: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 3.5613e-08 - accuracy: 1.0000 - val_loss: 4.1265e-08 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 3.2505e-08 - accuracy: 1.0000\n",
            "Epoch 00013: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 3.2376e-08 - accuracy: 1.0000 - val_loss: 3.7007e-08 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 2.9875e-08 - accuracy: 1.0000\n",
            "Epoch 00014: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 2.9757e-08 - accuracy: 1.0000 - val_loss: 3.5042e-08 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 2.7611e-08 - accuracy: 1.0000\n",
            "Epoch 00015: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 2.7501e-08 - accuracy: 1.0000 - val_loss: 3.2422e-08 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 2.5127e-08 - accuracy: 1.0000\n",
            "Epoch 00016: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 2.5028e-08 - accuracy: 1.0000 - val_loss: 3.0130e-08 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 2.2900e-08 - accuracy: 1.0000\n",
            "Epoch 00017: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 2.3245e-08 - accuracy: 1.0000 - val_loss: 2.8492e-08 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 2.1621e-08 - accuracy: 1.0000\n",
            "Epoch 00018: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 2.1535e-08 - accuracy: 1.0000 - val_loss: 2.6527e-08 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 2.0160e-08 - accuracy: 1.0000\n",
            "Epoch 00019: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 2.0117e-08 - accuracy: 1.0000 - val_loss: 2.4562e-08 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 1.8846e-08 - accuracy: 1.0000\n",
            "Epoch 00020: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 1.8807e-08 - accuracy: 1.0000 - val_loss: 2.3580e-08 - val_accuracy: 1.0000\n",
            "\n",
            "Fold  9\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "Epoch 1/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 1.9174e-08 - accuracy: 1.0000\n",
            "Epoch 00001: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 1.9098e-08 - accuracy: 1.0000 - val_loss: 7.5325e-09 - val_accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 1.7677e-08 - accuracy: 1.0000\n",
            "Epoch 00002: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 1.7607e-08 - accuracy: 1.0000 - val_loss: 7.5325e-09 - val_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 1.6216e-08 - accuracy: 1.0000\n",
            "Epoch 00003: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 1.6552e-08 - accuracy: 1.0000 - val_loss: 6.5500e-09 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 1.5412e-08 - accuracy: 1.0000\n",
            "Epoch 00004: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 1.5351e-08 - accuracy: 1.0000 - val_loss: 6.5500e-09 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 1.2162e-08 - accuracy: 1.0000\n",
            "Epoch 00005: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 1.4442e-08 - accuracy: 1.0000 - val_loss: 6.2225e-09 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 1.3294e-08 - accuracy: 1.0000\n",
            "Epoch 00006: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 1.3241e-08 - accuracy: 1.0000 - val_loss: 5.8950e-09 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 1.2235e-08 - accuracy: 1.0000\n",
            "Epoch 00007: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 1.2186e-08 - accuracy: 1.0000 - val_loss: 5.5675e-09 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 1.1578e-08 - accuracy: 1.0000\n",
            "Epoch 00008: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 1.1532e-08 - accuracy: 1.0000 - val_loss: 4.5850e-09 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 1.0811e-08 - accuracy: 1.0000\n",
            "Epoch 00009: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 1.0768e-08 - accuracy: 1.0000 - val_loss: 4.2575e-09 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 1.0263e-08 - accuracy: 1.0000\n",
            "Epoch 00010: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 1.0222e-08 - accuracy: 1.0000 - val_loss: 4.2575e-09 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 9.6784e-09 - accuracy: 1.0000\n",
            "Epoch 00011: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 9.6400e-09 - accuracy: 1.0000 - val_loss: 3.9300e-09 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 9.2037e-09 - accuracy: 1.0000\n",
            "Epoch 00012: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 9.1671e-09 - accuracy: 1.0000 - val_loss: 3.9300e-09 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 8.6193e-09 - accuracy: 1.0000\n",
            "Epoch 00013: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 8.5851e-09 - accuracy: 1.0000 - val_loss: 3.9300e-09 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 8.2175e-09 - accuracy: 1.0000\n",
            "Epoch 00014: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 8.1849e-09 - accuracy: 1.0000 - val_loss: 3.9300e-09 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 7.5967e-09 - accuracy: 1.0000\n",
            "Epoch 00015: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 7.6029e-09 - accuracy: 1.0000 - val_loss: 3.9300e-09 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 6.3184e-09 - accuracy: 1.0000\n",
            "Epoch 00016: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 7.2391e-09 - accuracy: 1.0000 - val_loss: 3.6025e-09 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 6.6106e-09 - accuracy: 1.0000\n",
            "Epoch 00017: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 6.5843e-09 - accuracy: 1.0000 - val_loss: 3.6025e-09 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 6.0262e-09 - accuracy: 1.0000\n",
            "Epoch 00018: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 6.1842e-09 - accuracy: 1.0000 - val_loss: 3.2750e-09 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 5.9897e-09 - accuracy: 1.0000\n",
            "Epoch 00019: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 5.9659e-09 - accuracy: 1.0000 - val_loss: 3.2750e-09 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 5.5514e-09 - accuracy: 1.0000\n",
            "Epoch 00020: accuracy did not improve from 1.00000\n",
            "3277/3277 [==============================] - 10s 3ms/sample - loss: 5.5294e-09 - accuracy: 1.0000 - val_loss: 2.9475e-09 - val_accuracy: 1.0000\n",
            "643/643 [==============================] - 1s 1ms/sample - loss: 9.4511 - accuracy: 0.5630\n",
            "Test set metrics: accuracy: 56.30%\n",
            "Saved model vgg-like to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvlFhrdphxaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load json and create model\n",
        "json_file = open(model_name+ '.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(model_name + \".h5\")\n",
        "print(\"Loaded model from disk\")\n",
        "\n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(X_test,y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtGPmLgHN1C-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}