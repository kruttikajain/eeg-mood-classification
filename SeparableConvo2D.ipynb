{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SeparableConvo2D.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMUbnvH3luCxzMJCJDLRH0o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omkarpat/eeg-mood-classification/blob/master/SeparableConvo2D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGqPLmdrKib2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "a28e7acb-e33b-42aa-a557-737084987064"
      },
      "source": [
        "# Colab settings/mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/My\\ Drive/CSE\\ 240/Project/Data/spectrogram_images/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/CSE 240/Project/Data/spectrogram_images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2TSh99fKqGP",
        "colab_type": "code",
        "outputId": "fce37435-a5cf-4d7a-d9dd-206931a07cb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Convolution2D, Conv2D, MaxPooling2D, Lambda, GlobalMaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Activation, AveragePooling2D, Concatenate, SeparableConv2D, MaxPooling3D, Conv3D, DepthwiseConv2D\n",
        "from tensorflow.keras.models import model_from_json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xkts4etIKqK-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "e30f55a2-e797-45f2-a8bc-4f2f51461bd1"
      },
      "source": [
        "base_path = \".\"\n",
        "concentration_data_array = None\n",
        "relaxed_data_array = None\n",
        "print(\"loading data from .npy files...\")\n",
        "for filename in os.listdir(base_path):\n",
        "  if \"concentration_array_updated_spectrograms\" in filename and \"final\" not in filename:\n",
        "    print(filename)\n",
        "    concentration_data_array = np.concatenate((concentration_data_array, np.load(filename))) if concentration_data_array is not None else np.load(filename)\n",
        "  if \"relaxed_array_updated_spectrograms\" in filename:\n",
        "    print(filename)\n",
        "    relaxed_data_array = np.concatenate((relaxed_data_array, np.load(filename))) if relaxed_data_array is not None else np.load(filename)\n",
        "print(concentration_data_array.shape, relaxed_data_array.shape)\n",
        "print(len(concentration_data_array), len(relaxed_data_array))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading data from .npy files...\n",
            "concentration_array_updated_spectrograms_1.npy\n",
            "concentration_array_updated_spectrograms_2.npy\n",
            "concentration_array_updated_spectrograms_3.npy\n",
            "concentration_array_updated_spectrograms_4.npy\n",
            "concentration_array_updated_spectrograms_5.npy\n",
            "concentration_array_updated_spectrograms_6.npy\n",
            "relaxed_array_updated_spectrograms_1.npy\n",
            "relaxed_array_updated_spectrograms_2.npy\n",
            "relaxed_array_updated_spectrograms_3.npy\n",
            "relaxed_array_updated_spectrograms_4.npy\n",
            "relaxed_array_updated_spectrograms_5.npy\n",
            "relaxed_array_updated_spectrograms_final.npy\n",
            "(2160, 29, 43, 42) (2124, 29, 43, 42)\n",
            "2160 2124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2HJE3B_KqNk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cab8417b-67e3-4e9b-f566-07fa201d64ee"
      },
      "source": [
        "X = np.concatenate((relaxed_data_array, concentration_data_array))\n",
        "Y = np.concatenate((np.zeros((len(relaxed_data_array),1)),np.ones((len(concentration_data_array),1))))\n",
        "print(X.shape, Y.shape)\n",
        "relaxed_data_array, concentration_data_array = None, None"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4284, 29, 43, 42) (4284, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r_BE44TKqbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
        "X, Y = None, None\n",
        "folds = list(StratifiedKFold(n_splits=10, shuffle=True, random_state=1).split(X_train, y_train))\n",
        "#X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.15, random_state=42)\n",
        "#print(X_train.shape, X_test.shape, X_valid.shape, y_train.shape, y_test.shape, y_valid.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNnV97njKqhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = \"Separableconvo2d_VGG-like\"\n",
        "def get_model():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(SeparableConv2D(input_shape=(29,43,42),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\", data_format='channels_first'))\n",
        "  model.add(SeparableConv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "  #model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(SeparableConv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(SeparableConv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "  #model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(SeparableConv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(SeparableConv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(SeparableConv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "  #model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(SeparableConv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(SeparableConv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(SeparableConv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "  #model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(SeparableConv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(SeparableConv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(SeparableConv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "  #model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(units=4096,activation=\"relu\"))\n",
        "\n",
        "  model.add(Dense(units=4096,activation=\"relu\"))\n",
        "  model.add(Dense(units=2, activation=\"softmax\")) \n",
        "\n",
        "  # model.add(Conv2D(64, kernel_size=5, strides=(1,1), padding='valid', activation='relu', input_shape = (29, 43, 42)))\n",
        "  # model.add(Conv2D(128, kernel_size=3, activation='relu'))\n",
        "  # model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\n",
        "  # model.add(Conv2D(256, kernel_size=3, strides=(1,1), padding='valid', activation='relu'))\n",
        "  # model.add(Conv2D(512, kernel_size=2, activation='relu'))\n",
        "  # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  \n",
        "  # model.add(Flatten())\n",
        "  # model.add(Dense(100, activation='relu'))\n",
        "  # model.add(Dense(50, activation='relu'))\n",
        "  # model.add(Dense(1, activation='sigmoid'))\n",
        "  \n",
        "  #sgd = optimizers.SGD(lr=0.000001, momentum=0.7, decay=1e-6)\n",
        "  #model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "  adm = optimizers.Adam(lr=0.0001, decay=1e-6)\n",
        "  model.compile(optimizer=adm, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "  model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3a5ZZlpKqkz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a70cd64f-ec5d-44a1-cecf-5f4879fd209e"
      },
      "source": [
        "filepath= model_name + \"-weights-improvement-{epoch:02d}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "model2 = get_model()\n",
        "for j, (train_idx, val_idx) in enumerate(folds):\n",
        "  print('\\nFold ',j)\n",
        "  X_train_cv = X_train[train_idx]\n",
        "  y_train_cv = y_train[train_idx]\n",
        "  X_valid_cv = X_train[val_idx]\n",
        "  y_valid_cv= y_train[val_idx]\n",
        "  # checkpoint\n",
        "  model2.fit(X_train_cv, y_train_cv, validation_data=(X_valid_cv, y_valid_cv), epochs=1, batch_size=32, callbacks=callbacks_list, shuffle=True)\n",
        "score = model2.evaluate(X_test,y_test)\n",
        "print(\"Test set metrics: %s: %.2f%%\" % (model2.metrics_names[1], score[1]*100))\n",
        "model2_json = model2.to_json()\n",
        "with open(model_name + \".json\", \"w\") as json_file:\n",
        "    json_file.write(model2_json)\n",
        "# serialize weights to HDF5\n",
        "model2.save_weights(model_name + \".h5\")\n",
        "print(\"Saved model %s to disk\" % (model_name))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold  0\n",
            "Train on 3276 samples, validate on 365 samples\n",
            "3264/3276 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.5061\n",
            "Epoch 00001: accuracy improved from -inf to 0.50580, saving model to Separableconvo2d_VGG-like-weights-improvement-01.hdf5\n",
            "3276/3276 [==============================] - 22s 7ms/sample - loss: 0.6931 - accuracy: 0.5058 - val_loss: 0.6929 - val_accuracy: 0.5123\n",
            "\n",
            "Fold  1\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.5126\n",
            "Epoch 00001: accuracy improved from 0.50580 to 0.51205, saving model to Separableconvo2d_VGG-like-weights-improvement-01.hdf5\n",
            "3277/3277 [==============================] - 9s 3ms/sample - loss: 0.6930 - accuracy: 0.5121 - val_loss: 0.6929 - val_accuracy: 0.5110\n",
            "\n",
            "Fold  2\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.5110\n",
            "Epoch 00001: accuracy did not improve from 0.51205\n",
            "3277/3277 [==============================] - 7s 2ms/sample - loss: 0.6930 - accuracy: 0.5121 - val_loss: 0.6929 - val_accuracy: 0.5110\n",
            "\n",
            "Fold  3\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6929 - accuracy: 0.5126\n",
            "Epoch 00001: accuracy did not improve from 0.51205\n",
            "3277/3277 [==============================] - 7s 2ms/sample - loss: 0.6929 - accuracy: 0.5121 - val_loss: 0.6929 - val_accuracy: 0.5110\n",
            "\n",
            "Fold  4\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.5119\n",
            "Epoch 00001: accuracy did not improve from 0.51205\n",
            "3277/3277 [==============================] - 7s 2ms/sample - loss: 0.6930 - accuracy: 0.5121 - val_loss: 0.6929 - val_accuracy: 0.5110\n",
            "\n",
            "Fold  5\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6929 - accuracy: 0.5123\n",
            "Epoch 00001: accuracy did not improve from 0.51205\n",
            "3277/3277 [==============================] - 7s 2ms/sample - loss: 0.6929 - accuracy: 0.5121 - val_loss: 0.6929 - val_accuracy: 0.5110\n",
            "\n",
            "Fold  6\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.5126\n",
            "Epoch 00001: accuracy did not improve from 0.51205\n",
            "3277/3277 [==============================] - 7s 2ms/sample - loss: 0.6930 - accuracy: 0.5121 - val_loss: 0.6929 - val_accuracy: 0.5110\n",
            "\n",
            "Fold  7\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.5116\n",
            "Epoch 00001: accuracy did not improve from 0.51205\n",
            "3277/3277 [==============================] - 7s 2ms/sample - loss: 0.6930 - accuracy: 0.5117 - val_loss: 0.6928 - val_accuracy: 0.5137\n",
            "\n",
            "Fold  8\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.5129\n",
            "Epoch 00001: accuracy did not improve from 0.51205\n",
            "3277/3277 [==============================] - 7s 2ms/sample - loss: 0.6930 - accuracy: 0.5117 - val_loss: 0.6928 - val_accuracy: 0.5137\n",
            "\n",
            "Fold  9\n",
            "Train on 3277 samples, validate on 364 samples\n",
            "3264/3277 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.5110\n",
            "Epoch 00001: accuracy did not improve from 0.51205\n",
            "3277/3277 [==============================] - 7s 2ms/sample - loss: 0.6929 - accuracy: 0.5117 - val_loss: 0.6928 - val_accuracy: 0.5137\n",
            "643/643 [==============================] - 0s 760us/sample - loss: 0.6947 - accuracy: 0.4603\n",
            "Test set metrics: accuracy: 46.03%\n",
            "Saved model Separableconvo2d_VGG-like to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke2hTbPWKqf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOynjM4zKqeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxnY5NYQKqYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b6MLXk3KqWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJOTZ5QmKqTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aixQ092TKqI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}